# 1 计算机网络基础

## 1. 网络结构模式 

### (1) C/S结构

​		**服务器**负责数据的管理，**客户机**负责完成与用户的交互任务。客户机是因特网上访问别人信息的机器，服务器则是提供信息供人访问的计算机。

​				**优点：**很多工作可以在客户端处理后再提交给服务器，所以 **C/S 结构客户端响应速度快**；满足个性化要求；有较强的事务处理能力；安全性较高

​				**缺点：**客户端需要安装专用的客户端软件，其维护和升级成本非常高；不能够跨平台。

### (2) B/S结构

​		浏览器/服务器模式，这种模式**统一了客户端**，将系统功能实现的核心部分集中到服务器上，**简化了系统的开发、维护和使用**。

​		**优点：**成本低、维护方便、 分布性强、开发简单，客户端零维护

​		**缺点：**通信开销大、系统和数据的安全性较难保障；无法实现个性化；协议一般是固定的：http/https；**请求-响应**模式，**动态刷新页面，响应速度明显降低**。

## 2. 地址信息

### (1) MAC 地址

​		MAC 地址指的是物理地址，用来**确认网络设备位置**。每一个网卡都有一个被称为 MAC 地址的独一无二的 48 位串行号， **48 位（6个字节）**。

​		网卡的**主要功能**：1. 数据的封装与解封装、2. 链路管理、3. 数据编码与译码。

### (2) IP 地址

​		IP 地址是 IP协议提供的一种统一的地址格式，**它为互联网上的每一个网络和每一台主机分配一个逻辑地址**，以此来屏蔽物理地址的差异。 **32 位**

​		每个 IP 地址包括**两个标识码（ID）**，即**网络ID** 和**主机 ID**。Internet 委员会定义了 5 种 IP 地址类型以适合不同容量的网络，即 A 类~ E 类。

​		子网掩码将某个 IP 地址划分成网络地址和主机地址两部分。 D类多播地址

​		IP地址的分配是**根据网络的拓扑结构**。

### (3) 端口

​		端口可分为**虚拟端口和物理端口**，其中虚拟端口指计算机内部或交换机路由器内的端口，不可见，是特指TCP/IP协议中的端口，是逻辑意义上的端口。

​		端口号从  **0 到 1023**是周知端口； 从 **1024 到 49151**，分配给用户进程或应用程序；从 **49152 到 65535**是动态端口 / 私有端口。

#### ① 端口有效范围

​		0-1023为知名端口号，比如其中HTTP是80，FTP是20（数据端口）、21（控制端口）

​		UDP和TCP报头使用两个字节存放端口号，所以端口号的有效范围是从0到65535。动态端口的范围是从1024到65535

####  ② 一台机器可使用端口号上限

​		65536.因为TCP的报文头部中源端口号和目的端口号的长度是16位，也就是可以表示2^16=65536个不同端口号，因此TCP可供识别的端口号最多只有65536个。但是由于0到1023是知名服务端口，所以实际上还要少1024个端口号。

​		而对于服务器来说，可以开的端口号与65536无关，其实是**受限于Linux可以打开的文件数量**，并且可以通过MaxUserPort来进行配置。

## 3. 计算机网络体系结构

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312194916849.png" alt="image-20220312194916849" style="zoom:50%;" />

### (1) OSI七层模型

- **物理层**：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。                                                                      物理层数据被称为**比特流**
- **数据链路层**：建立逻辑连接、数据的封帧和差错检测，以及 MAC 寻址；                                                                               数据链路层数据被称为**帧**
- **网络层**：进行逻辑地址寻址，定义IP编址，定义路由功能；负责数据的路由、转发、分片；                                                网络层数据被称做**包**
- **传输层**：定义了一些传输数据的协议和端口号，在端到端之间提供可靠的透明数据传输；如 TCP、UDP。                        传输层数据被称作**段**     (TCP段)   
- 会话层：负责在网络中的两节点之间建立、维持和终止通信。  负责建立、管理和终止表示层实体之间的通信会话；
- 表示层：处理用户信息的表示问题，数据的编码，压缩和解压缩，数据的加密和解密.。负责把数据转换成兼容另一个系统能识别的格式；
- 应用层：各种应用软件，包括 Web 应用。        负责给应用程序提供统一的接口；

### (2) TCP/IP四层模型

​		**TCP/IP协议族**是现在 Internet（因特网）使用的主流协议族，**是一个分层、多协议的通信体系**，一个四层协议系统，自底而上分别是数据链路层、网络层、传输层和应用层。每一层完成不同的功能，且通过若干协议来实现，**上层协议使用下层协议提供的服务**。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312194850754.png" alt="image-20220312194850754" style="zoom:50%;" />

​		**1. 应用层**：直接为应用进程提供服务的。负责向用户提供一组应用程序

​				（1）对不同种类的应用程序不同协议，邮件传输应用使用了 SMTP 协议、万维网应用使用了 HTTP 协议、远程登录服务应用使用了有 TELNET 协议。

​				（2）应用层还能加密、解密、格式化数据。

​				（3）应用层可以建立或解除与其他节点的联系，这样可以充分节省网络资源。

​		**2. 传输层**： **TCP 和 UDP** 起到了中流砥柱的作用，负责端到端的通信

​		**3. 网络层**：可以进行网络连接的建立和终止以及 **IP 地址**的寻找等功能。负责网络包的封装、分片、路由、转发

​		**4. 网络接口层**：由于网络接口层兼并了物理层和数据链路层，网络接口层是传输数据的物理媒介。负责网络包在物理网络中的传输

### (3) 介绍网络七层参考模型

| OSI七层模型 | 功能                                                         | 对应的网络协议                                               | TCP/IP四层概念模型 |
| :---------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------: |
| 应用层      | 文件传输，文件管理，电子邮件的信息处理                       | HTTP、TFTP, FTP, NFS, WAIS、SMTP                             |       应用层       |
| 表示层      | 确保一个系统的应用层发送的消息可以被另一个系统的应用层读取，编码转换，数据解析，管理数据的解密和加密。 | Telnet, Rlogin, SNMP, Gopher                                 |       应用层       |
| 会话层      | 负责在网络中的两节点建立，维持和终止通信。                   | SMTP, DNS                                                    |       应用层       |
| 传输层      | 定义一些传输数据的协议和端口。                               | TCP, UDP                                                     |       传输层       |
| 网络层      | 控制子网的运行，如逻辑编址，分组传输，路由选择               | IP, ICMP, ARP, RARP, AKP, UUCP                               |       网络层       |
| 数据链路层  | 主要是对物理层传输的比特流包装，检测保证数据传输的可靠性，将物理层接收的数据进行MAC（媒体访问控制）地址的封装和解封装 | FDDI, Ethernet, Arpanet, PDN, SLIP, PPP，STP。HDLC,SDLC,帧中继 |     数据链路层     |
| 物理层      | 定义物理设备的标准，主要对物理连接方式，电气特性，机械特性等制定统一标准。 | IEEE 802.1A, IEEE 802.2到IEEE 802.                           |     数据链路层     |

## 4. 协议

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312195440683.png" alt="image-20220312195440683" style="zoom: 50%;" />

<img src="E:\06  研究生_1\06  实习\开发资料\项目\牛客项目\04  网络编程\4.6\网络通信的过程.png" alt="网络通信的过程" style="zoom: 67%;" />

**常见协议**

​		**应用层**常见的协议有：**FTP协议**（文件传输协议）、**HTTP协议**（超文本传输协议）、**NFS**（网络文件系统）、**TELNET** （远程登录服务应用）

​		**传输层**常见协议有：**TCP协议**（传输控制协议）、**UDP协议**（ 用户数据报协议）。

​		**网络层**常见协议有：**IP 协议**（因特网互联协议）、**ICMP 协议**（因特网控制报文协议）、**IGMP 协议**（因特网组管理协议）、**RIP** （路由信息协议）

​		**网络接口层**常见协议有：**ARP协议**（地址解析协议）、**RARP协议**（反向地址解析协议）。

### (1) UDP协议 

​		UDP（用户数据报协议）是一种**无连接**的，**尽最大努力的数据传输服务**的传输层通信协议（**不保证数据传输的可靠性**）。

​		**头部结构：**16位源端口号、16位目的端口号、16位UDP长度、16位UDP检验和

### (2) TCP协议

​		TCP（传输控制协议）是一种**面向连接的、可靠的、基于字节流**的传输层通信协议。

​		**头部结构：**16位源端口号、16位目的端口号、32位序号、32位确认号、4位头部长度、6位保留、URG、ACK、PSH、RST、SYN、FIN、16位窗口大小、16位检验和、16位紧急指针、选项（最多40字节）

### (3) IP协议

​		**头部结构：**4位版本号、4位头部长度、8位服务类型、16位总长度（字节数）、16位标识、3位标志、13位片偏移、8位生存时间（TTL）、8位协议、16位头部校验和、32位源端IP地址、32位目的源IP地址、选项（最多40字节）

#### ① 网络层常见协议

| 协议 | 名称                 | 作用                                                         |
| ---- | -------------------- | ------------------------------------------------------------ |
| IP   | 网际协议             | IP协议不但定义了数据传输时的基本单元和格式，还定义了数据报的递交方法和路由选择 |
| ICMP | Internet控制报文协议 | ICMP就是一个“错误侦测与回报机制”，其目的就是让我们能够检测网路的连线状况﹐也能确保连线的准确性，是ping和traceroute的工作协议 |
| RIP  | 路由信息协议         | 使用“跳数”(即metric)来衡量到达目标地址的路由距离             |
| IGMP | Internet组管理协议   | 用于实现组播、广播等通信                                     |

#### ② Ping命令基于哪一层协议

​		ping命令基于网络层的命令，是基于ICMP协议工作的。

### (4) 以太网帧协议 (MAC地址)

​		**头部结构：**6字节目的物理地址、6字节源物理地址、2字节类型、数据（46-1500字节）、4字节CRC

### (5) ARP协议

#### ① 什么是ARP

​		ARP：根据IP地址获取物理地址。  （已知自己地址  但 不知道对方MAC地址）

​		ARP 协议会在以太网中以**广播**的形式，对以太网所有的设备喊出：“这个 IP 是谁的？请把你的 MAC 地址告诉我”。然后有人回答：“这个 IP 是我的，我的 MAC 地址是 XX”。如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。

​		在后续操作系统会把本次查询结果放到一块叫做 **ARP 缓存**的内存空间留着以后用，不过缓存的时间就几分钟。

​		也就是说，在发包时： 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。

​												而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。

​		**头部结构：**

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312195349663.png" alt="image-20220312195349663" style="zoom:67%;" />

#### ② 什么是RARP

​		反向地址转换协议，使只知道自己硬件地址的主机能够知道其IP地址。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所需信息的RARP服务器发出的IP地址。

**原理：**
​		(1) 网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。主机从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址。

​		(2) RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给主机。

​		(3) PC1收到RARP回应后，就使用得到的IP地址进行通讯。

#### ② 数据链路层常见协议

| 协议 | 名称             | 作用                                                         |
| ---- | ---------------- | ------------------------------------------------------------ |
| ARP  | 地址解析协议     | 根据IP地址获取物理地址                                       |
| RARP | 反向地址转换协议 | 根据物理地址获取IP地址                                       |
| PPP  | 点对点协议       | 用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主机、网桥和路由器之间简单连接的一种共通的解决方案 |

### (6) 封装

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312195424411.png" alt="image-20220312195424411" style="zoom:50%;" />

##### 上层协议是如何使用下层协议提供的服务的呢？

​				通过封装实现的。应用程序数据在发送到物理网络上之前，将沿着协议栈从上往下依次传递。每层协议都将在上层数据的基础上加上自己的头部信息（有时还包括尾部信息），以实现该层的功能，这个过程就称为**封装**。

### (7) 分用

​		当帧到达目的主机时，将沿着协议栈自底向上依次传递。各层协议依次处理帧中本层负责的头部数据，以获取所需的信息，并最终将处理后的帧交给目标应用程序。这个过程称为**分用**。分用是依靠头部信息中的类型字段实现的。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312195433078.png" alt="image-20220312195433078" style="zoom: 50%;" />

## 5. 静态路由和动态路由

1. 静态路由是由**系统管理员设计与构建的路由表规定的路由**。适用于网关数量有限的场合，且网络拓朴结构不经常变化的网络。其缺点是不能动态地适用网络状况的变化，当网络状况变化后必须由网络管理员修改路由表。
2. 动态路由是**由路由选择协议而动态构建的**，路由协议之间通过交换各自所拥有的路由信息实时更新路由表的内容。动态路由可以自动学习网络的拓朴结构，并更新路由表。其缺点是路由广播更新信息将占据大量的网络带宽。

**哪些路由协议，都是如何更新的**

​		路由可分为静态&动态路由。静态路由由管理员手动维护；动态路由由路由协议自动维护。

​		路由选择算法的必要步骤：

​			1）向其它路由器传递路由信息；

​			2）接收其它路由器的路由信息；

​			3）根据收到的路由信息计算出到每个目的网络的最优路径，并由此生成路由选择表；

​			4）根据网络拓扑的变化及时的做出反应，调整路由生成新的路由选择表，同时把拓扑变化以路由 信息的形式向其它路由器宣告。

​		两种主要算法：距离向量法（Distance Vector Routing）和链路状态算法（Link-State Routing）。

​		路由协议：RIP 路由协议(距离向量协议)、OSPF 路由协议(基于链路状态)、BGP 和 BGP4 路由协议(外部网关协议)、IGRP 和 EIGRP 协议(动态路由协议)

# 2 TCP/UDP通信

## 1. 字节序

​		**字节序**：字节在内存中存储的顺序。

​		**小端字节序**：数据的高位字节存储在内存的高位地址，低位字节存储在内存的低位地址

​		**大端字节序**：数据的低位字节存储在内存的高位地址，高位字节存储在内存的低位地址

​		发送端总是把要发送的数据转换成**大端字节序数据**后再发送，而接收端知道对方传送过来的数据总是采用大端字节序。

## 2. socket介绍

​		socket 可以看成是两个网络应用程序进行通信时，各自通信连接中的端点，**socket 是由 IP 地址和端口结合的**，提供向应用层进程传送数据包的机制。

​		socket是一套通信的接口，套接字通信分两部分： - 服务器端：被动接受连接，一般不会主动发起连接 ；- 客户端：主动向服务器发起连接 

**socket地址**

​		socket地址其实是一个结构体，**封装端口号和IP等信息**。后面的socket相关的api中需要使用到这个 socket地址。 

**本地套接字**

​		本地套接字的作用：本地的进程间通信

​				有关系的进程间的通信

​				没有关系的进程间的通信

​		本地套接字实现流程和网络套接字类似，一般呢采用TCP的通信流程。

## 3. TCP通信流程

### (1) TCP 和 UDP

**传输层的协议** 
		UDP：用户数据报协议，面向无连接，可以单播，多播，广播， 面向数据报，不可靠 
		TCP：传输控制协议，面向连接的，可靠的，基于字节流，仅支持单播传输 

#### TCP 和 UDP 的区别

- 是否创建连接：TCP协议是有连接的，UDP是无连接的
- 是否可靠：TCP协议是可靠的（保证数据无差错、不丢失、不重复、按序到达），UDP是不可靠的（尽最大努力交付，不保证可靠交付）
- 连接的对象个数：TCP是一对一的连接，UDP支持一对一，多对多，一对多，多对一的通信
- 传输的方式：TCP面向字节流，没有边界， UDP面向数据报，有边界
- 首部开销：TCP首部最少需20个字节，UDP首部8个字节
- 适用场景：TCP适用可靠性高的应用（FTP文件传输、HTTP/HTTPS），UDP适用实时应用（视频会议，直播，广播通信）
- 发送速率：TCP有流量控制和拥塞控制，保证数据传输的安全性；UDP没有，网络拥堵不会影响发送端的发送速率；TCP速度慢，UDP速度快

​		上层使用的协议：基于TCP协议的：Telnet，FTP以及SMTP协议；基于UDP协议的：DHCP、DNS、SNMP、TFTP、BOOTP。

### (2) TCP通信流程

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312201250423.png" alt="image-20220312201250423" style="zoom: 80%;" />

<img src="https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789189940/1C7CCCBB618E2A4F2C7DAFF81A9E9884" alt="img" style="zoom: 50%;" />

#### TCP 通信的流程 

**服务器端 （被动接受连接的角色）** 

1. 创建一个用于监听的套接字 
    - 监听：监听有客户端的连接 
    - 套接字：这个套接字其实就是一个文件描述符 
2. 将这个监听文件描述符和本地的IP和端口绑定（IP和端口就是服务器的地址信息） 
    - 客户端连接服务器的时候使用的就是这个IP和端口 
3. 设置监听，监听的fd开始工作 
4. 阻塞等待，当有客户端发起连接，解除阻塞，接受客户端的连接，会得到一个和客户端通信的套接字 （fd） 
5. 通信 
    - 接收数据 
    - 发送数据 
6. 通信结束，断开连接

**客户端** 

1. 创建一个用于通信的套接字（fd） 
2. 连接服务器，需要指定连接的服务器的 IP 和 端口 
3. 连接成功了，客户端可以直接和服务器通信 - 接收数据 - 发送数据 
4. 通信结束，断开连接

#### 本地套接字通信的流程

**服务器端** 

1. 创建监听的套接字 
	int lfd = socket(AF_UNIX/AF_LOCAL, SOCK_STREAM, 0); 
2. 监听的套接字绑定本地的套接字文件 -> server端 
	struct sockaddr_un addr; 
	// 绑定成功之后，指定的sun_path中的套接字文件会自动生成。 
	bind(lfd, addr, len); 
3. 监听
	listen(lfd, 100); 
4. 等待并接受连接请求 
	struct sockaddr_un cliaddr; 
	int cfd = accept(lfd, &cliaddr, len); 
5. 通信
	接收数据：read/recv 
	发送数据：write/send 
6. 关闭连接 
	close(); 

**客户端**

1. 创建通信的套接字 
	int fd = socket(AF_UNIX/AF_LOCAL, SOCK_STREAM, 0); 
2. 监听的套接字绑定本地的IP 端口 
	struct sockaddr_un addr; 
	// 绑定成功之后，指定的sun_path中的套接字文件会自动生成。 
	bind(lfd, addr, len); 
3. 连接服务器 
	struct sockaddr_un serveraddr; 
	connect(fd, &serveraddr, sizeof(serveraddr)); 
4. 通信
	接收数据：read/recv 
	发送数据：write/send 
5. 关闭连接 
	close(); 

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312202218235.png" alt="image-20220312202218235" style="zoom: 80%;" />

### (3) TCP三次握手

​		三次握手的目的是为了保证双方之间建立了连接   //    初始化Socket、序列号和窗口大小并建立 TCP 连接。

​		三次握手发生在客户端连接的时候，当调用connect()，底层会通过TCP协议进行三次握手。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312202007088.png" alt="image-20220312202007088" style="zoom: 80%;" />

​		一开始客户端和服务器都处于CLOSED状态，服务器主动监听某个端口，处于LISTEN状态。

​		**第一次握手：**客户端给服务器端发送一个TCP首部 SYN置1，序号置一个随机初始化数字（ISN）的SYN报文，然后处于SYN_SEND状态。
​		**第二次握手：**服务器收到客户端的SYN报文，给客户端发送一个TCP首部 ACK置1，确认号置客户端的ISN+1，SYN置1，序号置随机化数字的ACK-SYN报文，然后处于SYN_RCVD状态
​		**第三次握手：**客户端收到服务器的报文后，给服务器发送一个TCP首部ACK置1，确认号置服务器的ISN+1的报文，然后处于ESTABLISHED状态，服务器收到后也处于ESTABLISHED状态。

#### ① TCP为什么握手需要3次

​		**因为三次握手才能保证双方具有接收和发送的能力**

​		为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接。

​				(1) 三次握手才可以阻止重复历史连接的初始化（主要原因）（两次握手可能建立一个历史连接，造成资源浪费）

​				(2) 三次握手才可以避免资源浪费（两次握手会造成客户端的 `SYN` 阻塞了，重复发送多次 `SYN` 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。）

​				(3) 三次握手才可以同步双方的初始序列号（两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。）

**不使用「两次握手」和「四次握手」的原因：**

- 「两次握手」：**无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；**
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

#### ② 三次握手消息丢失

1. 第一次握手消息丢失：客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，最大重传次数内核参数控制

2. 第二次握手消息丢失：客户端和服务端都会重传报文，客户端会重传 SYN 报文（第一次握手），服务端会重传 SYN-ACK 报文（第二次握手）

3. 第三次握手消息丢失：服务端重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

   ​	**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。**

##### 超时重传次数和时间

​		在 Linux 里，**最大重传次数**由**内核参数控制** SYN报文是`tcp_syn_retries`，SYN_ACK是`tcp_synack_retries`，这个参数可以自定义的，默认值一般是 5。

​		通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，**每次超时的时间是上一次的 2 倍**。第五次超时重传后，会继续等待 32 秒，若服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，断开 TCP 连接。

​	所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。

#### ③ 三次握手可以携带数据吗

​		其实第三次握手的时候，是可以携带数据的。但是，**第一次、第二次握手不可以携带数据**

​		**第一次**握手不可以放数据，其中一个简单的原因就是会**让服务器更加容易受到攻击了**。而对于**第三次**的话，此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，他已经建立起连接了，并且也**已经知道服务器的接收、发送能力是正常的**了，所以能携带数据也没啥毛病。

#### ④ 序号的作用

- 接收方可以**去除重复的数据**；
- 接收方可以根据数据包的序列号**按序接收**；
- 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

##### 为什么要求随机生成ISN

- 为了防止历史报文被服务器进程重启的连接接收，造成数据错乱（主要方面）；防止在网络中被延迟的分组在以后又被传送，而导致数据错乱。
- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；如果 ISN 是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。

##### ISN 是如何随机产生的

​		起始 `ISN` 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时。

​		**ISN随时间而变化，因此每个连接都将具有不同的ISN，ISN是一个有可以看作是一个32比特的计数器，但并不是简单的计数器，大概每4毫秒/微妙加1 。**

​		RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。

- `M` 是一个计时器，这个计时器每隔 **4 微秒加 1**。
- `F` 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。

#### ⑤ MSS 和 MTU

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzIzLmpwZw?x-oss-process=image/format,png" alt="MTU 与 MSS" style="zoom:50%;" />

- `MTU`：**一个网络包的最大长度**，以太网中一般为 `1500` 字节；
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 **TCP 数据的最大长度**；

##### 为什么IP层可以分片，还需要MSS？

​		因为IP层是不可靠传输，如果在 TCP 的整个报文交给 IP 层进行分片，一个 IP 分片丢失，整个 IP 报文的所有分片都得重传，所以，为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。

#### ⑥ 什么是半连接队列

​		服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个**队列**里，我们把这种队列称之为**半连接队列**。

​		当然还有一个**全连接队列**，就是已经完成三次握手，建立起连接的就会从半连接队列转移到全连接队列中。如果队列满了就有可能会出现丢包现象。

#### ⑦ SYN 攻击

##### 什么是SYN攻击

​	**SYN攻击就是攻击者在短时间内伪造大量不存在IP地址的`SYN` 报文，并向服务器端不断地发送SYN包**，Server则回复确认包，并等待确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用半连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

​	如果不断受到 SYN 攻击，就会导致 SYN 队列（半连接队列）被占满，从而导致无法在建立新的连接。

##### 怎样防御SYN攻击

- 缩短超时（SYN Timeout）时间
- 增加最大半连接数
- 过滤网关防护
- **SYN cookies技术**
  - 当半连接队列满之后，后续服务器收到 SYN 包，不进入半连接队列；
  - 计算出一个 `cookie` 值，再以 SYN + ACK 中的「序列号」返回客户端，
  - 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到全连接队列。

##### 如何调整 SYN 半连接队列大小？

​		要想增大半连接队列，不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大 accept 队列。否则，只单纯增大 tcp_max_syn_backlog 是无效的。增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数。最后，改变了如上这些参数后，要重启 Nginx 服务，因为 SYN 半连接队列和 accept 队列都是在 `listen()` 初始化的。

##### 如果 SYN 半连接队列已满，只能丢弃连接吗？

​		开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接。

​		syncookies 的工作原理：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功

##### SYN 报文被丢弃的两种场景

- 开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃
  - 如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包
  - 开启PAWS 机制，防止 TCP 包中的序列号发生绕回
- TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃

### (4) TCP 四次挥手

​		四次挥手发生在断开连接的时候，在程序中当调用了close()会使用TCP协议进行四次挥手。 
​		客户端和服务器端都可以主动发起断开连接，谁先调用close()谁就是发起。 
​		因为在TCP连接的时候，采用三次握手建立的的连接是双向的，在断开的时候需要双向断开。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312202129663.png" alt="image-20220312202129663" style="zoom:67%;" />

第一次挥手：客户端给服务器端发送一个FIN置1的报文，然后进入`FIN_WAIT_1`状态（若close关闭表示不发不收，若shutdown关闭有可能表示不发能收）。

第二次挥手：服务器端收到报文后，给客户端发送一个ACK置1的回应报文，然后进入`CLOSED_WAIT`状态。(表示自己接收到关闭消息，但还有数据没有处理完)；

​						客户端收到服务器端的回应报文后，进入FIN_WAIT_2状态。

第三次挥手：服务器端处理完数据后，给客户端发送FIN置1的报文，然后进入`LAST_ACK`状态（表示数据处理完了，请求关闭）

第四次挥手：客户端收到服务器的FIN报文后，给服务器发送ACK置1的回应报文，然后进入`TIME_WAIT`状态，经过2MSL时间后，自动给进入`CLOSED`状态。

​						服务器收到客户端的回应报文后，进入`CLOSED`关闭状态。

**注意**

- **关闭连接**
  - 对于 close 函数关闭的连接，无法再发送和接收数据，所以`FIN_WAIT2` 状态不可以持续太久，而 `tcp_fin_timeout` 控制了这个状态下连接的持续时长，默认值是 60 秒。
  - 对于 shutdown 函数关闭连接且指定只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 `FIN_WAIT2` 状态（`tcp_fin_timeout` 无法控制 shutdown 关闭的连接）。
  - 当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 `CLOSE_WAIT` 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。
- **在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文**
  - 在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态。等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。
- **在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？**
  - **如果双方开启了时间戳机制：**
    - 如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**大**，**并且**SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**大**。那么就会重用该四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。
    - 如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**小**，**或者**SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**小**。那么就会**再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端**。
- **在 TIME_WAIT 状态，收到 RST 会断开连接吗？**
  - 如果 `net.ipv4.tcp_rfc1337` 参数为 0，则提前结束 TIME_WAIT 状态，释放连接。
  - 如果 `net.ipv4.tcp_rfc1337` 参数为 1，则会丢掉该 RST 报文。

#### ① 为什么挥手需要四次？

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

#### ② 四次挥手信息丢失

​		第一次挥手丢失：触发超时重传机制，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

​		第二次挥手丢失：服务器不会重传ACK 报文的，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。

​		第三次挥手丢失：服务器收不到ACK，就会重发 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

​		第四次挥手丢失：服务器收不到ACK，就会重发 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

#### ③ 为什么需要TIME_WAIT

- **保证客户端发送的最后一个ACK报文段能够到达服务端。**（保证「被动关闭连接」的一方，能被正确的关闭；）（用来重发可能丢失的ACK报文）

  ​		因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。

- **防止“已失效的连接请求报文段”出现在本连接中。**（防止历史连接中的数据，被后面重新连接的服务器错误的接收）(定义这个连接的socked不能再被使用)

  ​		客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。

##### 为什么等待的是 2MSL

​		`MSL` 是 **报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

​		若没有收到 ACK 报文，触发超时重发 `FIN` 报文，会重发 ACK 给被动关闭方，所以**一来一回需要等待 2 倍的时间**。可以看到 **2MSL时长** 这其实是相当于**至少允ACK许报文丢失一次**。若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

​		为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。

​		`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。

​		在 Linux 系统里 `2MSL` 默认是 `60` 秒，那么一个 `MSL` 也就是 `30` 秒。**Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒**。

##### MSL 与 TTL 的区别

​		因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

​		 MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

​		TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了。

##### TIME_WAIT 过多的危害

- 第一是**内存资源**占用；     客户端受端口资源限制：服务端受系统资源（比如文件描述符、内存资源、CPU 资源、线程资源等）限制：
- 第二是对**端口资源**的占用，一个 TCP 连接至少消耗「发起连接方」的一个本地端口；

##### 如何优化 TIME_WAIT

- 打开选项 net.ipv4.tcp_tw_reuse（=1：在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用） 和

  ​		        net.ipv4.tcp_timestamps （=1：打开对 TCP 时间戳的支持，时间戳的字段是在 TCP 头部的「选项」里，8 个字节，第一个 4 字节字段用来保存发送该数据包的时间，第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。由于引入了时间戳，我们在前面提到的 `2MSL` 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。）；

- net.ipv4.tcp_max_tw_buckets（这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置）

- 程序中使用 SO_LINGER ，应用强制使用 RST 关闭。

#### ④ 若建立了连接，但是客户端突然出现故障了怎么办？

​		TCP 有一个机制是**保活机制**。这个机制的原理是这样的：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

**原理：**如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

- 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。
- 所以，TCP 保活机制可以在双方没有数据交互的情况，**通过探测报文，来确定对方的 TCP 连接是否存活**。

##### 1)  在「**没有数据传输**」的场景下的一些异常情况：

- **若建立了连接，但是客户端突然出现故障了怎么办？**
  - TCP 有一个机制是保活机制，通过探测报文，来确定对方的 TCP 连接是否存活。
- **在没有开启 TCP keepalive，如果客户端的「主机崩溃」了，会发生什么？**
  - 客户端主机崩溃了，服务端是无法感知到的，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态，直到服务端重启进程。
  - 所以一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。
- **若建立了连接，但是客户端的进程崩溃会发生什么？**
  - 使用 kill -9 来模拟进程崩溃的情况，发现在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手。
- **拔掉网线后， 原本的 TCP 连接还存在吗？**
  - 双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
  - 双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。

##### 2)  在「**有数据传输**」的场景下的一些异常情况：

- **客户端主机宕机，又迅速重启，会发生什么？**
  - 在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发**超时重传**机制，重传未得到响应的报文。
  - 服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：
    - 如果客户端主机上**没有**进程监听该 TCP 报文的目标端口号，那么客户端内核就会回复 RST 报文，重置该 TCP 连接；
    - 如果客户端主机上**有**进程监听该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会**回复 RST 报文，重置该 TCP 连接**。
  - 所以，只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接。
- **客户端主机宕机，一直没有重启，会发生什么？**
  - 服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，一般就是 ETIMEOUT 状态码。
  - 在重传报文且一直没有收到对方响应的情况时，先达到「最大重传次数」或者「最大超时时间」这两个的其中一个条件后，就会停止重传。
- **拔掉网线后， 原本的 TCP 连接还存在吗？**
  - 在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。
  - 在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。

![image-20220413104344582](C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413104344582.png)

#### ⑤ FIN_WAIT_2，CLOSE_WAIT和TIME_WAIT

- FIN_WAIT_2：
  - 半关闭状态。

  - 发送断开请求一方还有接收数据能力，但已经没有发送数据能力。

- CLOSE_WAIT状态：
  - 被动关闭连接一方接收到FIN包会立即回应ACK包表示已接收到断开请求。

  - 被动关闭连接一方如果还有剩余数据要发送就会进入CLOSE_WAIT状态。

- TIME_WAIT状态：
  - 又叫2MSL等待状态。
  - 如果客户端直接进入CLOSED状态，如果服务端没有接收到最后一次ACK包会在超时之后重新再发FIN包，此时因为客户端已经CLOSED，所以服务端就不会收到ACK而是收到RST。所以TIME_WAIT状态目的是防止最后一次握手数据没有到达对方而触发重传FIN准备的。
  - 在2MSL时间内，同一个socket不能再被使用，否则有可能会和旧连接数据混淆（如果新连接和旧连接的socket相同的话）。

### (6) TCP 可靠性保证

​		TCP主要提供了检验和、序列号/确认应答、重传机制、最大消息长度、滑动窗口控制、连接管理等方法实现了可靠性传输。

#### ① 检验和

- 通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。TCP在计算检验和时，会在TCP首部加上一个12字节的伪首部。检验和总共计算3部分：TCP首部、TCP数据、TCP伪首部

#### ② 序列号/确认应答

- 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。
- 只要接收端没有回应确认包（ACK包），都会重发。或者接收端的应答包，发送端没有收到也会重发数据。这就可以保证数据的完整性。
- **累计应答**指的是：为了保证**顺序性**，每一个包都有一个**ID**（序号），在建立连接的时候，会商定起始的ID是多少，然后按照ID一个个发送。而为了保证不丢包，对应发送的包都要进行应答，但不是一个个应答，而是会**应答某个之前的ID**，该模式称为**累计应答**

#### ③ 最大消息长度

- 在建立TCP连接的时候，双方约定一个最大的长度（MSS）作为发送的单位，重传的时候也是以这个单位来进行重传。理想的情况下是该长度的数据刚好不被网络层分块。

#### ④ 重传机制

##### 超时重传

- 超时重传是指就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据。
- TCP 会在以下两种情况发生超时重传：
  - 数据包丢失
  - 确认应答丢失
- 超时时间`RTO` （Retransmission Timeout 超时重传时间）应该设置为多少呢？
  - `RTT` （Round-Trip Time 往返时延）就是**数据从网络一端传送到另一端所需的时间**，也就是包的往返时间。
  - 超时重传时间 RTO 的值应该**略大于报文往返 RTT 的值**
  - 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**
  - 超时触发重传存在的问题是，超时周期可能相对较长。

###### 可以解释一下RTO，RTT和超时重传分别是什么吗？

- 超时重传：发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况：

  - 发送的数据没能到达接收端，所以对方没有响应。

  - 接收端接收到数据，但是ACK报文在返回过程中丢失。

  - 接收端拒绝或丢弃数据。

- RTO：从上一次发送数据，因为长期没有收到ACK响应，到下一次重发之间的时间。就是重传间隔。
  - 通常每次重传RTO是前一次重传间隔的两倍，计量单位通常是RTT。例：1RTT，2RTT，4RTT，8RTT......

  - 重传次数到达上限之后停止重传。

- RTT：数据从发送到接收到对方响应之间的时间间隔，即数据报在网络中一个往返用时。大小不稳定。

##### 快速重传

- 它不以时间为驱动，而是以数据驱动重传
- 当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
- 问题：重传的时候，不清楚这连续的三个 ACK 是谁传回来的，是重传之前的一个，还是重传三个所有的问题。

###### 为何快速重传是选择3次ACK？

​		主要的考虑还是要区分包的丢失是由于链路故障还是乱序等其他因素引发。因为两次有可能是乱序。

​		如果接受到三次重复ACK，重传如果接收到正确的ACK，就是丢包；若依然收到重复ACK。则认为网络拥塞，将发送速率减半。

##### SACK 方法

​		`SACK`（ Selective Acknowledgment 选择性确认）。

​		这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。如果要支持 `SACK`，必须双方都要支持。

##### Duplicate SACK

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

可见，`D-SACK` 有这么几个好处：

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

在 Linux 下可以通过 `net.ipv4.tcp_dsack` 参数开启/关闭这个功能（Linux 2.4 后默认打开）。

#### ⑤ 滑动窗口

​		TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着**接收端告诉发送端自己还有多少缓冲区可以接收数据**。

​		发送方可以通过接收方滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0时，发送方一般不能再发送数据报。

​		通信双方都有发送的缓冲区和接收的缓冲区

​			服务器：发送缓冲区、接收缓冲区

​			客户端：发送缓冲区、接收缓冲区		

##### 窗口大小由哪一方决定？

​		**窗口的大小是由接收方的窗口大小来决定的**。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

##### 滑动窗口过小怎么办

​		我们可以假设窗口的大小是1，也是就每次只能发送一个数据，并且发送方只有接受方对这个数据进行确认了以后才能发送下一个数据。如果说窗口过小，那么当传输比较大的数据的时候需要不停的对数据进行确认，这个时候就会**造成很大的延迟**。

#### ⑥ 流量控制

​		流量控制是为了控制发送方发送速率，保证接收方来得及接收，允许接受方对传输进行限制，直到它拥有足够的缓冲空间来容纳更多的数据。

**原理：**

- 目的是接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题。所以流量控制是点对点控制。
- TCP是双工协议，双方可以同时通信，所以发送方接收方各自维护一个发送窗和接收窗。

  - 发送窗：用来限制发送方可以发送的数据大小，其中发送窗口的大小由接收端返回的TCP报文段中窗口字段来控制，接收方通过此字段告知发送方自己的缓冲（受系统、硬件等限制）大小。

  - 接收窗：用来标记可以接收的数据大小。
- TCP是流数据，发送出去的数据流可以被分为以下四部分：已发送且被确认部分 | 已发送未被确认部分 | 未发送但可发送部分 | 不可发送部分，其中发送窗 = 已发送未确认部分 + 未发但可发送部分。接收到的数据流可分为：已接收 | 未接收但准备接收 | 未接收不准备接收。接收窗 = 未接收但准备接收部分。
- 发送窗内数据只有当接收到接收端某段发送数据的ACK响应时才移动发送窗，左边缘紧贴刚被确认的数据。接收窗也只有接收到数据且最左侧连续时才移动接收窗口。

##### 操心系统的缓冲区，是如何影响发送窗口和接收窗口的呢？

​		发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会**被操作系统调整**。

​		如果发生了**先减少缓存，再收缩窗口，就会出现丢包的现象**，为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。

##### 窗口关闭—死锁

​		如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是**窗口关闭**。

​		接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。

​		当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。

**TCP 是如何解决窗口关闭时，潜在的死锁现象呢？**

​		TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

- 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
- 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。

##### 糊涂窗口综合症

​		如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。

糊涂窗口综合症的现象是可以发生在发送方和接收方：

- 接收方可以通告一个小的窗口
- 而发送方可以发送小数据

于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了

- 让接收方不通告小窗口给发送方
- 让发送方避免发送小数据

##### 不通告小窗口的方法

​	当「窗口大小」小于 min( MSS，缓存空间/2 ) ，就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`，也就阻止了发送方再发数据过来。

​		等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。

##### 避免发送小数据的方法

发送方通常的策略:

使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：

- 要等到窗口大小 >= `MSS` 或是 数据大小 >= `MSS`
- 收到之前发送数据的 `ack` 回包

只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。

另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。

可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）

##### 延迟确认与 Nagle 算法

那么就出现了常见的两种策略，来减少小报文的传输，分别是：

- **Nagle 算法**

  - Nagle 算法的策略：
    - 没有已发送未确认报文时，立刻发送数据。
    - 存在未确认报文时，直到「没有已发送未确认报文」或「数据长度达到 MSS 大小」时，再发送数据。
  - Nagle 算法一定会有一个小报文，也就是在最开始的时候。
  - Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。

- **延迟确认**

  - TCP 延迟确认的策略：

    - 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
    - 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送
    - 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK

  - 延迟确认 和 Nagle 算法混合使用时，会导致时耗增长，要解决这个问题

    - 要不发送方关闭 Nagle 算法
    - 要不接收方关闭 TCP 延迟确认

  - **延迟应答**指的是：TCP在接收到对端的报文后，并不会立即发送ack，而是等待一段时间发送ack，以便将ack和要发送的数据一块发送。当然ack不能无限延长，否则对端会认为包超时而造成报文重传。linux采用动态调节算法来确定延时的时间。

#### ⑦ 拥塞控制

​		目的就是**避免「发送方」的数据填满整个网络。**

​		拥塞控制目的是防止数据被过多注网络中导致网络资源（路由器、交换机等）过载。因为拥塞控制涉及网络链路全局，所以属于全局控制。

##### 拥塞窗口

​		**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

​		我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。

拥塞窗口 `cwnd` 变化的规则：

- 只要网络中没有出现拥塞，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；

##### 怎么知道出现了拥塞

​		其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了用拥塞。**

##### 拥塞控制的控制算法

- **慢启动**
  - TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，试探一下网络的承受能力，以免直接扰乱了网络通道的秩序。
  - 连接建好的开始，先初始化拥塞窗口cwnd大小为1，表明可以传一个MSS大小的数据。
  - 当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1，发包的个数是**指数性的增长**。
  - 每当过了一个往返延迟时间RTT(Round-Trip Time)，cwnd大小直接翻倍，乘以2，呈指数让升。
  - 有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。（一般来说 `ssthresh` 的大小是 `65535` 字节。）
    - 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
    - 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」
- **拥塞避免**
  - 每当收到一个 ACK 时，cwnd 增加 1/cwnd
  - 每当过了一个往返延迟时间RTT，cwnd大小加一。
  - 拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。
  - 网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传，当触发了重传机制，也就进入了「拥塞发生算法」
- **拥塞发生**
  - 发生**超时重传**的拥塞发生算法：这个时候，ssthresh 和 cwnd 的值会发生变化：
    - `ssthresh` 设为 `cwnd/2`，
    - `cwnd` 重置为 `1`
    - 重新开始慢启动，慢启动是会突然减少数据流的，这种方式太激进了，反应也很强烈，会造成网络卡顿
  - 发生**快速重传**的拥塞发生算法：这个时候，ssthresh 和 cwnd 的值会发生变化：
    - `cwnd = cwnd/2` ，也就是设置为原来的一半;
    - `ssthresh = cwnd`;
    - 进入快速恢复算法
- **快速恢复**
  - 快速重传和快速恢复算法一般同时使用，进入快速恢复算法如下：
    - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
    - 重传丢失的数据包；
    - 如果再收到重复的 ACK，那么 cwnd 增加 1；
    - 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

**发生超时重传的拥塞发生算法**

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/29.jpg" alt="拥塞发送 —— 超时重传" style="zoom:50%;" />

**发生快速重传的拥塞发生算法**

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/30.jpg" alt="快速重传和快速恢复" style="zoom:50%;" />



##### 流量控制和拥塞控制

- 流量控制属于通信双方协商；拥塞控制涉及通信链路全局。
- 流量控制需要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的TCP报文段中窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。
- 实际最终发送窗口 = min{流控发送窗口，拥塞窗口}。

####  TCP 如何保证有序

（1）为了保证数据包的可靠传递，**发送方**必须把**已发送的数据包保留在缓冲区**，并为每个已发送的数据包启动一个**超时定时器**；

（2）如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答，也可以是对本包后续包的应答），则**释放该数据包占用的缓冲区**;

（3）否则，**重传该数据包**，直到收到应答或重传次数超过规定的最大次数为止。

（4）**接收方**收到数据包后，先**进行CRC校验**，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去。

#### TCP 协议如何保证可靠传输

- **确认和重传**：接收方收到报文就会确认，发送方没有收到确认就会重传。标志位确保通信实体的存在，序号和确认号确保了数据是按序、完整到达。
- **数据校验**：TCP报文头有校验和，用于校验报文是否损坏。
- **数据合理分片和排序**：tcp会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层。而UDP：IP数据报大于1500字节，大于MTU。这个时候发送方的IP层就需要分片，把数据报分成若干片，是的每一片都小于MTU。而接收方IP层则需要进行数据报的重组。由于UDP的特性，某一片数据丢失时，接收方便无法重组数据报，导致丢弃整个UDP数据报。
- **流量控制**：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，避免过量发送，防止包丢失。
- **拥塞控制**：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

### (8) TCP 通信并发

​		要实现TCP通信服务器处理并发的任务，使用**多线程或者多进程**来解决。 

​		**多进程：**一个父进程，多个子进程 ；父进程负责等待并接受客户端的连接 ；子进程：完成通信，接受一个客户端连接，就创建一个子进程用于通信。

### (8) 端口复用

​		端口复用最常用的用途是: 防止服务器重启时之前绑定的端口还未释放；程序突然退出而系统没有释放端口

​		设置的时机是在服务器绑定端口之前。 

### (9) UDP通信

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312202910848.png" alt="image-20220312202910848" style="zoom:50%;" />

#### UDP 如何保证尽量可靠

1. UDP仅提供了最基本的数据传输功能，至于传输时连接的建立和断开、传输可靠性的保证这些UDP统统不关心，而是把这些问题抛给了UDP上层的应用层程序去处理，自己仅提供传输层协议的最基本功能。
2. 最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。
   - 添加seq/ack机制，确保数据发送到对端
   - 添加发送和接收缓冲区，主要是用户超时重传。
   - 添加超时重传机制。

### (10) 如何优化 TCP

#### ① TCP 三次握手的性能提升

- **客户端优化：**当客户端发起 SYN 包时，可以通过 `tcp_syn_retries` 控制其重传的次数。
  - 可以根据网络的稳定性和目标服务器的繁忙程度修改 SYN 的重传次数，调整客户端的三次握手时间上限。比如内网中通讯时，就可以适当调低重试次数，尽快把错误暴露给应用程序。
- **服务端优化：**
  - 防止SYN攻击，增大半连接队列；
    - 当服务端 SYN 半连接队列溢出后，会导致后续连接被丢弃，可以通过 `netstat -s` 观察半连接队列溢出的情况；
    - 如果 SYN 半连接队列溢出情况比较严重，可以通过 `tcp_max_syn_backlog、somaxconn、backlog` 参数来调整 SYN 半连接队列的大小。
  - 服务端回复 SYN+ACK 的重传次数由 `tcp_synack_retries` 参数控制；
    - 如果服务器没有收到 ACK，就会重发 SYN+ACK 报文，当网络繁忙、不稳定时，报文丢失就会变严重，此时应该调大重发次数。
    - 如果遭受 SYN 攻击，应把 `tcp_syncookies` 参数设置为 1，表示仅在 SYN 队列满后开启 syncookie 功能，可以保证正常的连接成功建立。
  - 服务端收到客户端返回的 ACK，会把连接移入 accpet 队列，等待进行调用 accpet() 函数取出连接。
    - 可以通过 `ss -lnt` 查看服务端进程的 accept 队列长度；
    - 如果 accept 队列溢出，系统默认丢弃 ACK，如果可以把 `tcp_abort_on_overflow` 设置为 1 ，表示用 RST 通知客户端连接建立失败。
    - 如果 accpet 队列溢出严重，通过 listen 函数的 `backlog` 参数和 `somaxconn` 系统参数提高队列大小，队列长度取决于 min(backlog, somaxconn)。
- **如何绕过三次握手：**三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送。
  - 在 Linux 3.7 内核版本之后，提供了 **TCP Fast Open** 功能，这个功能可以减少 TCP 连接建立的时延。
  - 第一次发起 HTTP GET 请求的时候，生成 Cookie，还是需要正常的三次握手流程，之后发起 HTTP GET 请求的时候，对收到 Cookie 进行校验，可以绕过三次握手，这就减少了握手带来的 1 个 RTT 的时间消耗。
  - 必须保证服务端和客户端同时支持

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/24.jpg" alt="三次握手优化策略" style="zoom:50%;" />

#### ② TCP 四次挥手的性能提升

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/39.jpg" alt="四次挥手的优化策略" style="zoom:50%;" />

- **主动方的优化：**
  - 主动发起 FIN 报文断开连接的一方，如果迟迟没收到对方的 ACK 回复，则会重传 FIN 报文，重传的次数由 `tcp_orphan_retries` 参数决定。
    - 如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 tcp_orphan_retries 的值，当重传次数超过 tcp_orphan_retries 时，连接就会直接关闭掉。
  - 当主动方收到 ACK 报文后，连接就进入 FIN_WAIT2 状态，根据关闭的方式不同，优化的方式也不同：
    - 如果这是 close 函数关闭的连接，那么它就是孤儿连接。如果 `tcp_fin_timeout` 秒内没有收到对方的 FIN 报文，连接就直接关闭。同时，为了应对孤儿连接占用太多的资源，`tcp_max_orphans` 定义了最大孤儿连接的数量，超过时连接就会直接释放。
    - 反之是 shutdown 函数关闭的连接，则不受此参数限制；
  - 当主动方接收到 FIN 报文，并返回 ACK 后，主动方的连接进入 TIME_WAIT 状态。这一状态会持续 1 分钟，为了防止 TIME_WAIT 状态占用太多的资源，`tcp_max_tw_buckets` 定义了最大数量，超过时连接也会直接释放。
  - 当 TIME_WAIT 状态过多时，还可以通过设置 `tcp_tw_reuse` 和 `tcp_timestamps` 为 1 ，将 TIME_WAIT 状态的端口复用于作为客户端的新连接，注意该参数只适用于客户端。
- **被动方的优化：**
  - 被动关闭的连接方应对非常简单，它在回复 ACK 后就进入了 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连接。因此，出现大量 CLOSE_WAIT 状态的连接时，应当从应用程序中找问题。
  - 当被动方发送 FIN 报文后，连接就进入 LAST_ACK 状态，在未等到 ACK 时，会在 `tcp_orphan_retries` 参数的控制下重发 FIN 报文。

#### ③ TCP 数据传输的性能提升

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/49.jpg" alt="数据传输的优化策略" style="zoom:50%;" />

- TCP 可靠性是通过 ACK 确认报文实现的，又依赖滑动窗口提升了发送速度也兼顾了接收方的处理能力。
- 可是，默认的滑动窗口最大值只有 64 KB，不满足当今的高速网络的要求，要想**提升发送速度必须提升滑动窗口的上限**，在 Linux 下是通过设置 `tcp_window_scaling` 为 1 做到的，此时最大值可高达 1GB。
- 滑动窗口定义了网络中飞行报文的最大字节数，当它超过带宽时延积时，网络过载，就会发生丢包。而当它小于带宽时延积时，就无法充分利用网络带宽。因此，滑动窗口的设置，必须参考带宽时延积。**发送缓冲区的大小最好是往带宽时延积靠近**
- 内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 tcp_wmem 和接收缓冲区 tcp_rmem。
- **Linux 会对缓冲区动态调节**，**我们应该把缓冲区的上限设置为带宽时延积**，而最小值保持默认的 4K 不变即可；内存紧张的服务调低默认值能提高并发。
- 发送缓冲区的调节功能是自动打开的，而接收缓冲区需要把 tcp_moderate_rcvbuf 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 tcp_mem。**调大 tcp_mem 的上限可以让 TCP 连接使用更多的系统内存，这有利于提升并发能力**
- 但需要注意的是，如果程序中的 socket 设置 SO_SNDBUF 和 SO_RCVBUF，则会关闭缓冲区的动态整功能，所以不建议在程序设置它俩，而是交给内核自动调整比较好。
- 有效配置这些参数后，既能够最大程度地保持并发性，也能让资源充裕时连接传输速度达到最大值。

### (11) TCP 粘包和拆包

​		TCP是个“流”协议，所谓流，就是没有界限的一串数据。大家可以想想河里的流水，是连成一片的，其间并没有分界线。

​		一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，**这就是所谓的TCP粘包和拆包问题**。

​		粘包的问题出现是因为**不知道一个用户消息的边界在哪**，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种方式分包的方式：

- **固定长度的消息；**
  - 每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
  - 这种方式灵活性不高，实际中很少用。
- **特殊字符作为边界；**
  - 我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。
  - HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。
  - 如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。
- **自定义消息结构。**
  - 我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

#### ① TCP粘包问题出现原因

**TCP粘包**是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

- 由TCP**连接复用**造成的粘包问题。
- 因为TCP默认会使用**Nagle算法**，此算法会导致粘包问题。
  - 只有上一个分组得到确认，才会发送下一个分组；
  - 收集多个小分组，在一个确认到来时一起发送。
- **数据包过大**造成的粘包问题。
- 流量控制，**拥塞控制**也可能导致粘包。
- **接收方不及时接收缓冲区的包，造成多个包接收**

#### ② 封包和拆包，它是基于TCP还是UDP的

封包和拆包都是基于TCP的概念。因为TCP是无边界的流传输，所以需要对TCP进行封包和拆包，确保发送和接收的数据不粘连。

* 封包：封包就是在发送数据报的时候为每个TCP数据包加上一个包头，将数据报分为包头和包体两个部分。包头是一个固定长度的结构体，里面包含该数据包的总长度。
* 拆包：接收方在接收到报文后提取包头中的长度信息进行截取。



## 4. I/O多路复用

​		I/O 多路复用使得程序能同时监听多个文件描述符，能够提高程序的性能

### (1) select

**主旨思想：**

​			(1) 首先要构造一个关于文件描述符的列表，将要监听的文件描述符添加到该列表中。

​			(2) 调用一个系统函数，监听该列表中的文件描述符，直到这些描述符中的一个或者多个进行I/O操作时，该函数才返回。

​					a.这个函数是阻塞

​					b.函数对文件描述符的检测的操作是由内核完成的

​			(3) 在返回时，它会告诉进程有多少（哪些）描述符要进行I/O操作。

**缺点：**

​			(1) 每次调用都需要把fd合集从用户态拷贝到内核态，这个开销在fd很多时会很大。

​			(2) 需要在内核遍历传进来的所有fd，开销大

​			(3) 支持的fd描述符的数量太少了，默认1024

​			(4) fds合集不能重用，每次都要重置

### (2) poll

​		用结构体解决了select的(3) (4) 缺点。

### (3) epoll

​		创建一个新的epoll实例。在内核中创建了一个数据，这个数据中有两个比较重要的数据，一个是需要检测的文件描述符的信息（红黑树），还有一个是就绪列表，存放检测到数据发送改变的文件描述符信息（双向链表）。 

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313145118525.png" alt="image-20220313145118525" style="zoom:33%;" />

**Epoll 的工作模式：**

​	**LT 模式 （水平触发）**

​		假设委托内核检测读事件，检测fd的读缓冲区，读缓冲区有数据 ，epoll检测到了会给用户通知，同时支持 block 和 no-block socket

​				a.用户不读数据，数据一直在缓冲区，epoll 会一直通知

​				b.用户只读了一部分数据，epoll会通知

​				c.缓冲区的数据读完了，不通知

​		在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的 fd 进行 IO 操作。如果你不作任何操作，内核还是会继续通知你的。

​	**ET 模式（边沿触发）**

​		假设委托内核检测读事件，检测fd的读缓冲区，读缓冲区有数据 ，epoll检测到了会给用户通知，只支持 no-block socket

​				a.用户不读数据，数据一直在缓冲区中，epoll下次检测的时候就不通知了

​				b.用户只读了一部分数据，epoll不通知

​				c.缓冲区的数据读完了，不通知

​		如果一直不对这个 fd 作 IO 操作（从而导致它再次变成未就绪），内核不会发送更多的通知（only once）。

ET 模式在很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。epoll工作在 ET 模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

### (4) epoll和select的区别

（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大；而epoll保证了每个fd在整个过程中只会拷贝一次。

（2）每次调用select都需要在内核遍历传递进来的所有fd；而epoll只需要轮询一次fd集合，同时查看就绪链表中有没有就绪的fd就可以了。

（3）select支持的文件描述符数量太小了，默认是1024；而epoll没有这个限制，它所支持的fd上限是最大可以打开文件的数目，这个数字一般远大于2048。

### (5) epoll为什么高效

（1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。

（2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把当前进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把当前进程往等待队列上挂也只挂一次，这也能节省不少的开销。

### (6) select，epoll的使用场景

​		都是IO多路复用的机制，应用于高并发的网络编程的场景。I/O多路复用就是通过一种机制，可以监视多个文件描述符，一旦某个文件描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。

### (7) epoll水平触发与边缘触发的区别

​		LT模式（水平触发）下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作；

​		ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。

### (8) 多路IO复用技术及区别

1. **select，poll，epoll**都是IO多路复用的机制，I/O多路复用就是通过一种机制，可以监视多个文件描述符，一旦某个文件描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。

2. **区别**：

   （1）poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。

   （2）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。

   （3）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把当前进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把当前进程往等待队列上挂也只挂一次，这也能节省不少的开销。

## 5. 面试

### (1) 为什么服务器会缓存这一项功能

**原因**

- 缓解服务器压力；
- 降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。

**实现方法**

- 让代理服务器进行缓存；
- 让客户端浏览器进行缓存。

### (2) 服务器怎么判断客户端断开了连接

1. 检测连接是否丢失的方法大致有两种：**keepalive**和**heart-beat**
2. （tcp内部机制）采用keepalive，它会先要求此连接一定时间没有活动（一般是几个小时），然后发出数据段，经过多次尝试后（每次尝试之间也有时间间隔），如果仍没有响应，则判断连接中断。可想而知，整个**周期需要很长**的时间。
3. （应用层实现）一个简单的heart-beat实现一般测试连接是否中断采用的时间间隔都比较短，可以**很快的决定连接是否中断**。并且，由于是在应用层实现，因为可以自行决定当判断连接中断后应该采取的行为，而keepalive在判断连接失败后只会将连接丢弃。

#### keepalive

1. **HTTP Keep-Alive**

   在http早期，每个http请求都要求打开一个tpc socket连接，并且使用一次之后就断开这个tcp连接。使用keep-alive可以改善这种状态，即在一次TCP连接中可以持续发送多份数据而不会断开连接。通过使用keep-alive机制，可以减少tcp连接建立次数，也意味着可以减少TIME_WAIT状态连接，以此提高性能和提高httpd服务器的吞吐率(更少的tcp连接意味着更少的系统内核调用,socket的accept()和close()调用)。但是，keep-alive并不是免费的午餐,长时间的tcp连接容易导致系统资源无效占用。配置不当的keep-alive，有时比重复利用连接带来的损失还更大。所以，正确地设置keep-alive timeout时间非常重要。

2. **TCP KEEPALIVE**

   链接建立之后，如果应用程序或者上层协议一直不发送数据，或者隔很长时间才发送一次数据，当链接很久没有数据报文传输时如何去确定对方还在线，到底是掉线了还是确实没有数据传输，链接还需不需要保持，这种情况在TCP协议设计中是需要考虑到的。TCP协议通过一种巧妙的方式去解决这个问题，当超过一段时间之后，TCP自动发送一个数据为空的报文给对方，如果对方回应了这个报文，说明对方还在线，链接可以继续保持，如果对方没有报文返回，并且重试了多次之后则认为链接丢失，没有必要保持链接。

   1. TCP的keepalive机制和HTTP的keep-alive机制是说的完全不同的两个东西，tcp的keepalive是在ESTABLISH状态的时候，双方如何检测连接的可用行。而http的keep-alive说的是如何避免进行重复的TCP三次握手和四次挥手的环节。

### (3) 为何需要把 TCP/IP 协议栈分成 5 层（或7层）

答：ARPANET 的研制经验表明，对于复杂的计算机网络协议，其结构应该是层次式的。

分层的好处：

①隔层之间是独立的

②灵活性好

③结构上可以分隔开

④易于实现和维护

⑤能促进标准化工作。

### (4) DDos 攻击

客户端向服务端发送请求链接数据包，服务端向客户端发送确认数据包，客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认
没有彻底根治的办法，除非不使用TCP
DDos 预防：
1）限制同时打开SYN半链接的数目
2）缩短SYN半链接的Time out 时间
3）关闭不必要的服务

### (5) TCP对应的应用层协议

FTP：定义了文件传输协议，使用21端口.
Telnet：它是一种用于远程登陆的端口,23端口
SMTP：定义了简单邮件传送协议，服务器开放的是25号端口。
POP3：它是和SMTP对应，POP3用于接收邮件。

### (6) UDP对应的应用层协议

DNS：用于域名解析服务，用的是53号端口
SNMP：简单网络管理协议，使用161号端口
TFTP(Trival File Transfer Protocal)：简单文件传输协议，69

###  (7) 服务器出现大量close_wait的连接的原因和解决措施

close_wait状态是在TCP四次挥手的时候收到FIN但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因有两种：

* 服务器内部业务处理占用了过多时间，都没能处理完业务；或者还有数据需要发送；或者服务器的业务逻辑有问题，没有执行close()方法
* 服务器的父进程派生出子进程，子进程继承了socket，收到FIN的时候子进程处理但父进程没有处理该信号，导致socket的引用不为0无法回收

处理方法：

* 停止应用程序
* 修改程序里的bug

# 3 HTTP协议

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/7.jpg" alt="img" style="zoom:50%;" />

## 1. 浏览器从输入 URL 到展现页面的全过程

#### ① 在浏览器中输入url地址后显示主页的过程?

- 根据域名url，进行DNS域名解析；   （向DNS服务器发送DNS请求，查询本地DNS服务器，这其中用的是UDP的协议）                
- 拿到解析的IP地址，建立TCP连接；    

- 向IP地址，发送HTTP请求；
- 服务器处理请求；
- 返回响应结果；
- 关闭TCP连接；
- 浏览器解析HTML；
- 浏览器布局渲染

#### ② 地址栏输入一个URL后回车，会进行的技术步骤

1、检查本机host文件，查浏览器缓存，看看有没有已经缓存好的，如果没有，调用API，Linux下Scoket函数 gethostbyname，向DNS服务器发送DNS请求，查询本地DNS服务器，这其中用的是UDP的协议。

2、如果在一个子网内采用ARP地址解析协议进行ARP查询如果不在一个子网那就需要对默认网关进行DNS查询，如果还找不到会一直向上找根DNS服务器，直到最终拿到IP地址（全球400多个根DNS服务器，由13个不同的组织管理）

3、这个时候我们就有了服务器的IP地址 以及默认的端口号了，http默认是80 https是 443 端口号，会，首先尝试http然后调用Socket建立TCP连接，

4、经过三次握手成功建立连接后，开始传送数据，如果正是http协议的话，就返回就完事了，

5、如果不是http协议，服务器会返回一个5开头的的重定向消息，告诉我们用的是https，那就是说IP没变，但是端口号从80变成443了，好了，再四次挥手，完事，

6、再来一遍，这次除了上述的端口号从80变成443之外，还会采用SSL的加密技术来保证传输数据的安全性，保证数据传输过程中不被修改或者替换之类的，

7、这次依然是三次握手，沟通好双方使用的认证算法，加密和检验算法，在此过程中也会检验对方的CA安全证书。

8、确认无误后，开始通信，然后服务器就会返回你所要访问的网址的一些数据，在此过程中会将界面进行渲染，牵涉到ajax技术之类的，直到最后我们看到色彩斑斓的网页

### 一次完整的HTTP请求过程包括哪些内容

##### 第一种回答

- 建立起客户机和服务器连接。
- 建立连接后，客户机发送一个请求给服务器。
- 服务器收到请求给予响应信息。
- 客户端浏览器将返回的内容解析并呈现，断开连接。

##### 第二种回答

​		域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户。

## 2. HTTP基本概念

### (1) HTTP 是什么

​		HTTP 是超文本传输协议，也就是**H**yperText **T**ransfer **P**rotocol。

​		HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。

### (2) HTTP的缺点

- 使用明文进行通信，内容可能会被窃听；
- 不验证通信方的身份，通信方的身份有可能遭遇伪装；
- 无法证明报文的完整性，报文有可能遭篡改。

### (3) HTTP 常见的响应状态码

**五大类HTTP状态码**

- **1XX : 信息类状态码**（表示接收请求状态处理）（提示信息，目前是协议处理的中间状态，还有后续的操作）
- **2XX : 成功状态码**（表示请求正常处理完毕） （成功，报文已经收到并且被正确处理）  常见：200 204 206
  - 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
  - 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
  - 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分。
- **3XX : 重定向**（表示需要进行附加操作，已完成请求）（资源位置发生变动，需要客户端重新发送请求） 常见： 301 302 304
  - 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
  - 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。
    - 301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。
  - 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。
- **4XX : 客户端错误**（表示服务器无法处理请求）（请求报文有误，服务器无法处理）常见：400 403 404
  - 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
  - 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
  - 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。
- **5XX : 服务器错误状态码**（表示服务器处理请求的时候出错）（服务器在处理内部请求的时候发生了错误） 常见：500 501 502 503
  - 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
  - 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
  - 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
  - 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。

### (4) HTTP 常见字段

- **Host**：客户端发送请求时，用来指定服务器的域名。                      可以将请求发往「同一台」服务器上的不同网站
- **Content-Length**：服务器在返回数据时,本次回应的数据长度。
- **Connection**： **keep-alive** 客户端要求服务器使用 TCP 持久连接，以便其他请求复用。
- **Content-Type**：用于服务器回应时，告诉客户端，本次数据是什么格式。
- **Accept：**客户端请求的时候，声明自己可以接受哪些数据格式。
- **Content-Encoding**：服务器返回的数据使用了什么压缩格式
- **Accept-Encoding**：客户端在请求时，说明自己可以接受哪些压缩方法

```c
Host: www.A.com  //客户端发送请求时，用来指定服务器的域名。
Content-Length: 1000 //服务器在返回数据时,本次回应的数据长度
Connection: keep-alive  //客户端要求服务器使用 TCP 持久连接，以便其他请求复用
Content-Type: text/html; charset=utf-8   //用于服务器回应时，告诉客户端，本次数据是什么格式
Content-Encoding: gzip  //用于服务器回应时，数据使用了什么压缩格式
Accept-Encoding: gzip, deflate //客户端在请求时，说明自己可以接受哪些压缩方法
Accept:  */*  //客户端声明自己可以接受任何格式的数据。
```

#### HTTP请求和响应报文的主要字段

##### 请求报文

简单来说：

- 请求行：Request Line
- 请求头：Request Headers
- 请求体：Request Body

##### 响应报文

简单来说：

- 状态行：Status Line
- 响应头：Response Headers
- 响应体：Response Body

### (5) HTTP 的 referer 头的作用

1. 当浏览器向web服务器发送请求的时候，告诉服务器该网页是从哪个页面链接过来的。

2. 防盗链。

3. 防止恶意请求

4. 空Referer

   **定义**：Referer头部的内容为空，或者，一个HTTP请求中根本不包含Referer头部（一个请求并不是由链接触发产生的）

   ​		直接在浏览器的地址栏中输入一个资源的URL地址，那么这种请求是不会包含Referer字段的，因为这是一个“凭空产生”的HTTP请求，并不是从一个地方链接过去的。

   那么在防盗链设置中，允许空Referer和不允许空Referer有什么区别？允许Referer为空，意味着你允许比如浏览器直接访问。

5. 防御CSRF，比对HTTP 请求的来源地址，如果Referer中的地址是安全可信任的地址，那么就放行

## 3. HTTP 的请求方法

### HTTP请求方法你知道多少？

客户端发送的   **请求报文**   第一行为请求行，包含了方法字段。

根据 HTTP 标准，HTTP 请求可以使用多种请求方法。

HTTP1.0 定义了三种请求方法： GET, POST 和 HEAD方法。

HTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。

| 序  号 | 方法    | 描述                                                         |
| :----- | :------ | :----------------------------------------------------------- |
| 1      | GET     | 请求指定的页面信息，并返回实体主体。                         |
| 2      | HEAD    | 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 |
| 3      | POST    | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。 |
| 4      | PUT     | 从客户端向服务器传送的数据取代指定的文档的内容。             |
| 5      | DELETE  | 请求服务器删除指定的页面。                                   |
| 6      | CONNECT | HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。    |
| 7      | OPTIONS | 允许客户端查看服务器的性能。                                 |
| 8      | TRACE   | 回显服务器收到的请求，主要用于测试或诊断。                   |
| 9      | PATCH   | 是对 PUT 方法的补充，用来对已知资源进行局部更新 。           |

### GET请求和 POST 请求

​		在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。

​		所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

#### (1) GET和 POST 的区别

- **语义：**
  - GET 的语义是从服务器获取指定的资源，是「只读」操作
  - POST 的语义是根据请求负荷（报文body）对指定的资源做出处理，是「新增或提交数据」的操作
- **携带数据：**
  - GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制
  - POST 请求携带数据的位置一般是写在报文 body 中， 数据可以是任意格式的数据，只要客户端与服务端协商好即可，浏览器不会对 body 大小做限制
- **安全和幂等：**
  - GET 方法是安全且幂等的，可以对 GET 请求的数据做缓存，缓存可以做到浏览器或者代理上，而且在浏览器中 GET 请求可以保存为书签。
  - POST 方法是不安全且不幂等的，会修改服务器的资源，多次提交数据会创建多个资源，浏览器一般不会缓存 POST 请求，也不把 POST 请求保存为书签
    - 可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。
    - 可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。

#### (2) GET 请求可以带 body 吗

​		RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。

#### (3) GET和POST的长度限制

​		网络上都会提到浏览器地址栏输入的参数是有限的。

​		首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。

​		浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。

​		get 限制是**特定的浏览器及服务器对它的限制**，比如IE对URL长度的限制是2083字节(2K+35字节)。对于其他浏览器，如FireFox，Netscape等，则没有长度限制，这个时候其限制**取决于服务器的操作系统**；即如果url太长，服务器可能会因为安全方面的设置从而拒绝请求或者发生不完整的数据请求。

​		post 理论上讲是没有大小限制的，HTTP协议规范也没有进行大小限制，但实际上**post所能传递的数据量大小取决于服务器的设置和内存大小**。


#### (4) POST 方法比 GET 方法安全

​		有人说POST 比 GET 安全，因为数据在地址栏上不可见。

​		然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。

​		要想安全传输，就只有加密，也就是 HTTPS。


#### (5) POST 产生两个 TCP 数据包

​		有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。

​		HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。

​		所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。

## 3. HTTP 特性

#### (1) HTTP/1.1 的优点

- **简单**：HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**
- **灵活和易于扩展**：HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。
- **应用广泛和跨平台：**台式机的浏览器到手机上的各种 APP，从看新闻、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有**跨平台**的优越性。

#### (2) HTTP/1.1 的缺点

- **无状态双刃剑**
  - **好处**，因为服务器不会去记忆 HTTP 的状态，不需要额外的资源来记录状态信息，这能减轻服务器的负担，能把更多的 CPU 和内存用来提供服务。
  - **坏处**，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。 
    - 解决办法： **Cookie** 技术：`Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。
- **明文传输双刃剑**
  - **好处**，在传输过程中的信息，是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看
  - **坏处**，HTTP 的所有信息都暴露在了光天化日下，相当于**信息裸奔**，在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能**被窃取**
- **不安全**                     
  - **窃听风险**：通信使用明文（不加密），内容可能会被窃听。比如，账号信息容易泄漏，那你号没了。
  - **冒充风险**：不验证通信方的身份，因此有可能遭遇伪装。比如，访问假的淘宝、拼多多，那你钱没了。
  - **篡改风险**：无法证明报文的完整性，所以有可能已遭篡改。比如，网页上植入垃圾广告，视觉污染，眼没了。
  - 可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层

#### (3) HTTP/1.1 的性能

- 基于 **TCP/IP**，并且使用了「**请求 - 应答**」的通信模式
- **长连接（持久连接）**：只要任意一端没有断开连接，保持 TCP 连接状态。减少了重复建立和断开所造成的额外开销，减轻了服务器端的负载。
- **管道网络传输**： 客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**
- **队头阻塞**：当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据

​		总之 HTTP/1.1 的性能一般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。

## 5. HTTP 和 HTTPS 

​		HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。

### (1) HTTP 与 HTTPS 的区别

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### (2) HTTPS 解决了 HTTP哪些问题

​		HTTP 由于是明文传输，所以安全上存在以下三个风险：**窃听风险**，**篡改风险**，**冒充风险**

​		HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议：**信息加密**、**校验机制**、**身份证书**

### (3) HTTPS 是如何解决的

- **混合加密：** 实现信息的机密性，解决了窃听的风险。
  - HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：
    - 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
    - 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。
    - 使用**非对称密钥加密用于传输对称密钥来保证传输过程的安全性**，之后使用**对称密钥加密进行通信来保证通信过程的效率**。
  - 采用「混合加密」的方式的原因：
    - **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
    - **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发，而私钥保密，解决了密钥交换问题但速度慢。
- **摘要算法**：实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。
  - 客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。
- **数字证书：**将服务器公钥放入到**数字证书**中，解决了冒充的风险。
  - 客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。
  - 如何保证公钥不被篡改和信任度？
    - 借助第三方权威机构 `CA` （数字证书认证机构），将**服务器公钥放在数字证书**（由数字证书认证机构颁发）中，只要证书是可信的公钥就是可信的。

#### ① 对称密钥加密的优点缺点

​		对称密钥加密，加密和解密使用同一密钥。

- 优点：运算速度快
- 缺点：无法安全地将密钥传输给通信方

#### ② 非对称密钥加密的优缺点

​		非对称密钥加密，又称**公开密钥加密**，加密和解密使用不同的密钥。公钥和私钥是不同的一对。

​		公开密钥所有人都可以获得，**通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密**，**接收方收到通信内容后使用私有密钥解密**。

​		非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确。

- 优点：可以更安全地将公开密钥传输给通信发送方；
- 缺点：运算速度慢。

HTTPS 采用混合的加密机制，使用**非对称密钥加密用于传输对称密钥来保证传输过程的安全性**，之后使用**对称密钥加密进行通信来保证通信过程的效率**。

#### ③ RSA 算法的缺陷

​		**使用 RSA 密钥协商算法的最大问题是不支持前向保密**。

​		因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。

​		为了解决问题，后面就出现了 ECDHE 密钥协商算法，我们现在大多数网站使用的正是 ECDHE 密钥协商算法，关于 ECDHE 握手的过程，将在下一篇揭晓。

#### ④ RSA 和 ECDHE 握手过程的区别

- RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；
- 使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间；
- 使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息；

### (4) SSL/TLS 协议建立的流程

#### ① 什么是SSL/TLS

​		SSL代表安全套接字层。它是一种**用于加密和验证应用程序（如浏览器）和Web服务器之间发送的数据的协议**。 

​		SSL/TLS协议作用：认证用户和服务，加密数据，维护数据的完整性的应用层协议加密和解密需要两个不同的密钥

​		SSL/TLS协议的基本思路：采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。

#### ② SSL/TLS 建立的基本流程

- **https和http相比：**
  1. 建立连接时候：https 比 http多了 TLS 的握手过程；
  2. 传输内容的时候：https 会把数据进行加密，通常是对称加密数据；
- **SSL/TLS 协议基本流程：**
  - 客户端向服务器索要并验证服务器的公钥。

  - 双方协商生产「会话秘钥」。
  - 双方采用「会话秘钥」进行加密通信。
- 前两步也就是 **SSL/TLS** 的建立过程，也就是握手阶段，SSL/TLS 的「握手阶段」涉及**四次**通信

#### ② SSL/TLS 建立的详细流程

- **第一步：**首先，由客户端向服务器发起加密通信请求，也就是 `ClientHello` 请求。
  - 在这一步，客户端主要向服务器发送以下信息：、
    - 客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。
    - 客户端生产的随机数（`Client Random`），后面用于生产「会话秘钥」。
    - 客户端支持的密码套件列表，如 RSA 加密算法。
- **第二步：**服务器收到客户端请求后，向客户端发出响应，也就是 `SeverHello`。
  - 服务器回应的内容有如下内容：
    - 确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。
    - 服务器生产的随机数（`Server Random`），后面用于生产「会话秘钥」。
    - 确认的密码套件列表，如 RSA 加密算法。
    - 服务器的数字证书。
- **第三步：**客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。
  - 如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
    - 一个随机数（`pre-master key`）。该随机数会被公钥加密。
    - 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
    - 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。
  - 上面第一项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，**各自生成**本次通信的「会话秘钥」。
- **第四步：**服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法计算出本次通信的「会话秘钥」。
  - 然后，向客户端发生最后的信息：
    - 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
    - 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。

##### HTTPS是如何保证数据传输的安全

**SSL是怎么工作保证安全的**

1. 客户端向服务器端发起SSL连接请求，给出协议版本号、一个客户端生成的随机数，以及客户端支持的加密方法。
2. 服务器确认双方使用的加密方法，并送给客户端数字证书（公钥）、以及一个服务器生成的随机数。
3. 客户端确认数字证书有效，然后生成一个新的随机数，并使用数字证书中的公钥，加密这个随机数，发给服务器。
4. 服务器使用自己的私钥，获取客户端发来的随机数。
5. 进行数据传输，服务器和客户端根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”，用来加密接下来的整个对话过程。

#### ③ HTTPS加密过程

​			客户端在浏览器中输入一个https网址，然后连接到server的443端口采用https协议的server必须有一套数字证书（一套公钥和密钥）

​			首先server将证书传送到客户端，客户端解析证书验证成功，生成一个随机数，用证书里的公钥加密后（私钥）传回，server server用密钥解密后，获得这个随机值，然后将要传输的信息和私钥通过某种算法混合在一起（加密）传到客户端，客户端用之前的生成的随机数（私钥）解密服务器端传来的信息。

​		HTTPS 采用混合的加密机制，使用**非对称密钥加密用于传输对称密钥来保证传输过程的安全性**，之后使用**对称密钥加密进行通信来保证通信过程的效率**。

#### ④ HTTPS认证过程

​		首先浏览器会从内置的证书列表中索引，找到服务器下发证书对应的机构，如果没有找到，此时就会提示用户该证书是不是由权威机构颁发，是不可信任的。如果查到了对应的机构，则取出该机构颁发的公钥。

##### SSL中的认证中的证书是什么

​		通过使用 **证书** 来对通信方进行认证。

​		数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。

​		服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。

​		进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。

**CA 签发证书的过程：**

- 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
- 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
- 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

**客户端校验服务端的数字证书的过程：**

- 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

#### ⑤ 为什么有的时候刷新页面不需要重新建立 SSL 连接？

​		TCP 连接有的时候会被浏览器和服务端维持一段时间，TCP 不需要重新建立，SSL 自然也会用之前的。

#### ⑥ 如何保证公钥不被篡改？

​		将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。

**公钥加密计算量太大，如何减少耗用的时间？**

- 每一次对话（session），客户端和服务器端都生成一个"对话密钥"，用它来加密信息。
- 由于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。

## 6. Cookie 和 Session

### (1) Cookie是什么

​		HTTP 协议是**无状态**的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，HTTP/1.1 引入 Cookie 来保存状态信息。

​		Cookie 是**服务器发送到用户浏览器并保存在本地的一小块数据**，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。

​		新的浏览器 API 已经允许开发者直接将数据存储到本地

- **cookie 存储在客户端：** 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。
- **cookie 是不可跨域的：** 每个 cookie 都会绑定单一的域名，无法在别的域名下获取使用，**一级域名和二级域名之间是允许共享使用的**（**靠的是 domain）**。

#### Cookie有什么用途

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
- 个性化设置（如用户自定义设置、主题等）
- 浏览器行为跟踪（如跟踪分析用户行为等）

### (3) Session

#### ① Session是什么

​		除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。

​		Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。

- **session 是另一种记录服务器和客户端会话状态的机制**
- **session 是基于 cookie 实现的，session 存储在服务器端，sessionId 会被存储到客户端的cookie 中**

#### ② Session 的工作原理是什么

​		session 的工作原理是客户端登录完成之后，服务器会创建对应的 session，session 创建完之后，会把 session 的 id 发送给客户端，客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 sessionid，服务器拿到 sessionid 之后，在内存找到与之对应的 session 这样就可以正常工作了。

#### ③ 使用 Session 的过程是怎样的

- 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
- 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
- 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
- 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

**注意**：Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。

- **session 认证流程：**
  - 用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session
  - 请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器
  - 浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名
  - 当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。

根据以上流程可知，**SessionID 是连接 Cookie 和 Session 的一道桥梁**，大部分系统也是根据此原理来验证用户登录状态。


### (3) Cookie与Session的对比

- ##### Cookie

  ​		Cookie是客户端保持状态的方法。

  ​		Cookie简单的理解就是存储由服务器发至客户端并由客户端保存的一段字符串。为了保持会话，服务器可以在响应客户端请求时将Cookie字符串放在Set-Cookie下，客户机收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别。

  ​		除了上面提到的这些，Cookie在客户端的保存形式可以有两种，一种是会话Cookie一种是持久Cookie，会话Cookie就是将服务器返回的Cookie字符串保持在内存中，关闭浏览器之后自动销毁，持久Cookie则是存储在客户端磁盘上，其有效时间在服务器响应头中被指定，在有效期内，客户端再次请求服务器时都可以直接从本地取出。需要说明的是，存储在磁盘中的Cookie是可以被多个浏览器代理所共享的。

- **Session**

  ​		Session是服务器保持状态的方法。

  ​		首先需要明确的是，Session保存在服务器上，可以保存在数据库、文件或内存中，每个用户有独立的Session用户在客户端上记录用户的操作。我们可以理解为每个用户有一个独一无二的Session ID作为Session文件的Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用户操作行为。
  
  ​		当服务器需要识别客户端时就需要结合Cookie了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用Cookie来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。如果客户端的浏览器禁用了Cookie，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如sid=xxxxx这样的参数，服务端据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了。

#### Cookie与Session的关系和区别

1. Cookie与Session都是会话（保持连接状态）的一种方式。
2. **存储数据的位置不同**：cookie数据存放在客户的浏览器上，session数据放在服务器上。
3. **存储数据的安全不同：**cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，Session存储的数据比较安全。
4. **存储的数据类型不同：**两者都是key-value的结构，但针对value的类型是有差异的，cookie：value只能是字符串类型，session：value是Object类型
5. **存储的数据大小限制不同：**cookie：大小受浏览器的限制，很多是是4K的大小， session：理论上受当前内存的限制
6. **生命周期的控制：**cookie的生命周期当浏览器关闭的时候，就消亡了
   1. cookie的生命周期是累计的，从创建时，就开始计时，20分钟后，cookie生命周期结束，
   2. session的生命周期是间隔的，从创建时，开始计时如在20分钟，没有访问session，那么session生命周期被销毁

另一种

- **安全性：** Session 比 Cookie 安全，Session 是存储在服务器端的，Cookie 是存储在客户端的。
- **存取值的类型不同**：Cookie 只支持存字符串数据，想要设置其他类型的数据，需要将其转换成字符串，Session 可以存任意数据类型。
- **有效期不同：** Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭（默认情况下）或者 Session 超时都会失效。
- **存储大小不同：** 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie，但是当访问量过多，会占用过多的服务器资源。




#### Session和cookie应该如何去选择（适用场景）

- Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session；
- Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
- 对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。

### (4) Token（令牌）

#### Acesss Token

- **访问资源接口（API）时所需要的资源凭证**
- **简单 token 的组成：** uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign（签名，token 的前几位以哈希算法压缩成的一定长度的十六进制字符串）
- 特点：
  - **服务端无状态化、可扩展性好**
  - **支持移动端设备**
  - 安全
  - 支持跨程序调用

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/12/29/16f523a04d9c745f~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp" alt="img" style="zoom:50%;" />

- **token 的身份验证流程：**

1. 客户端使用用户名跟密码请求登录
2. 服务端收到请求，去验证用户名与密码
3. 验证成功后，服务端会签发一个 token 并把这个 token 发送给客户端
4. 客户端收到 token 以后，会把它存储起来，比如放在 cookie 里或者 localStorage 里
5. 客户端每次向服务端请求资源的时候需要带着服务端签发的 token
6. 服务端收到请求，然后去验证客户端请求里面带着的 token ，如果验证成功，就向客户端返回请求的数据

- **每一次请求都需要携带 token，需要把 token 放到 HTTP 的 Header 里**
- **基于 token 的用户认证是一种服务端无状态的认证方式，服务端不用存放 token 数据。用解析 token 的计算时间换取 session 的存储空间，从而减轻服务器的压力，减少频繁的查询数据库**
- **token 完全由应用管理，所以它可以避开同源策略**

#### Refresh Token

- 另外一种 token——refresh token
- refresh token 是专用于刷新 access token 的 token。如果没有 refresh token，也可以刷新 access token，但每次刷新都要用户输入登录用户名与密码，会很麻烦。有了 refresh token，可以减少这个麻烦，客户端直接用 refresh token 去更新 access token，无需用户进行额外的操作。

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/12/29/16f523a04d1c887b~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp" alt="img" style="zoom:50%;" />



- Access Token 的有效期比较短，当 Acesss Token 由于过期而失效时，使用 Refresh Token 就可以获取到新的 Token，如果 Refresh Token 也失效了，用户就只能重新登录了。
- Refresh Token 及过期时间是存储在服务器的数据库中，只有在申请新的 Acesss Token 时才会验证，不会对业务接口响应时间造成影响，也不需要向 Session 一样一直保持在内存中以应对大量的请求。

#### Token 和 Session 的区别

- Session 是一种**记录服务器和客户端会话状态的机制，使服务端有状态化，可以记录会话信息**。而 Token 是**令牌**，**访问资源接口（API）时所需要的资源凭证**。Token **使服务端无状态化，不会存储会话信息。**
- Session 和 Token 并不矛盾，作为身份认证 Token 安全性比 Session 好，因为每一个请求都有签名还能防止监听以及重放攻击，而 Session 就必须依赖链路层来保障通讯安全了。**如果你需要实现有状态的会话，仍然可以增加 Session 来在服务器端保存一些状态。**
- 所谓 Session 认证只是简单的把 User 信息存储到 Session 里，因为 SessionID 的不可预测性，暂且认为是安全的。而 Token ，如果指的是 OAuth Token 或类似的机制的话，提供的是 认证 和 授权 ，认证是针对用户，授权是针对 App 。其目的是让某 App 有权利访问某用户的信息。这里的 Token 是唯一的。不可以转移到其它 App上，也不可以转到其它用户上。Session 只提供一种简单的认证，即只要有此 SessionID ，即认为有此 User 的全部权利。是需要严格保密的，这个数据应该只保存在站方，不应该共享给其它网站或者第三方 App。
- 所以简单来说：**如果你的用户数据可能需要和第三方共享，或者允许第三方调用 API 接口，用 Token 。如果永远只是自己的网站，自己的 App，用什么就无所谓了。**

### (5) JWT

- JSON Web Token（简称 JWT）是目前最流行的**跨域认证**解决方案。
- 是一种**认证授权机制**。
- JWT 是为了在网络应用环境间**传递声明**而执行的一种基于 JSON 的开放标准（[RFC 7519](https://link.juejin.cn?target=https%3A%2F%2Ftools.ietf.org%2Fhtml%2Frfc7519)）。JWT 的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源。比如用在用户登录上。
- 可以使用 HMAC 算法或者是 RSA 的公/私秘钥对 JWT 进行签名。因为数字签名的存在，这些传递的信息是可信的。

#### JWT 的原理



<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/12/29/16f523a04e881087~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp" alt="img" style="zoom:50%;" />



- JWT 认证流程：
  - 用户输入用户名/密码登录，服务端认证成功后，会返回给客户端一个 JWT
  - 客户端将 token 保存到本地（通常使用 localstorage，也可以使用 cookie）
  - 当用户希望访问一个受保护的路由或者资源的时候，需要请求头的 Authorization 字段中使用Bearer 模式添加 JWT，其内容看起来是下面这样

```
Authorization: Bearer <token>
```

- 服务端的保护路由将会检查请求头 Authorization 中的 JWT 信息，如果合法，则允许用户的行为
- 因为 JWT 是自包含的（内部包含了一些会话信息），因此减少了需要查询数据库的需要
- 因为 JWT 并不使用 Cookie 的，所以你可以使用任何域名提供你的 API 服务而不需要担心跨域资源共享问题（CORS）
- 因为用户的状态不再存储在服务端的内存中，所以这是一种无状态的认证机制

#### JWT 的使用方式

- 客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。

**方式一**

- 当用户希望访问一个受保护的路由或者资源的时候，可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求头信息的 Authorization 字段里，使用 Bearer 模式添加 JWT。

  ```
  GET /calendar/v1/events
  Host: api.example.com
  Authorization: Bearer <token>
  ```

  - 用户的状态不会存储在服务端的内存中，这是一种 **无状态的认证机制**
  - 服务端的保护路由将会检查请求头 Authorization 中的 JWT 信息，如果合法，则允许用户的行为。
  - 由于 JWT 是自包含的，因此减少了需要查询数据库的需要
  - JWT 的这些特性使得我们可以完全依赖其无状态的特性提供数据 API 服务，甚至是创建一个下载流服务。
  - 因为 JWT 并不使用 Cookie ，所以你可以使用任何域名提供你的 API 服务而**不需要担心跨域资源共享问题**（CORS）

**方式二**

- 跨域的时候，可以把 JWT 放在 POST 请求的数据体里。

**方式三**

- 通过 URL 传输

```
http://www.example.com/user?token=xxx
```

#### Token 和 JWT 的区别  

**相同：**

- 都是访问资源的令牌
- 都可以记录用户的信息
- 都是使服务端无状态化
- 都是只有验证成功后，客户端才能访问服务端上受保护的资源

**区别：**

- Token：服务端验证客户端发送过来的 Token 时，还需要查询数据库获取用户信息，然后验证 Token 是否有效。
- JWT： 将 Token 和 Payload 加密后存储于客户端，服务端只需要使用密钥解密进行校验（校验也是 JWT 自己实现的）即可，不需要查询或者减少查询数据库，因为 JWT 自包含了用户信息和加密的数据。

#### 常见的前后端鉴权方式 

1. Session-Cookie
2. Token 验证（包括 JWT，SSO）
3. OAuth2.0（开放授权）

#### 常见的加密算法

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/12/29/16f523a04f17f2fc~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp" alt="image.png" style="zoom: 67%;" />

- 哈希算法(Hash Algorithm)又称散列算法、散列函数、哈希函数，是一种从任何一种数据中创建小的数字“指纹”的方法。哈希算法将数据重新打乱混合，重新创建一个哈希值。
- 哈希算法主要用来保障数据真实性(即完整性)，即发信人将原始消息和哈希值一起发送，收信人通过相同的哈希函数来校验原始数据是否真实。
- 哈希算法通常有以下几个特点：
  - 正像快速：原始数据可以快速计算出哈希值
  - 逆向困难：通过哈希值基本不可能推导出原始数据
  - 输入敏感：原始数据只要有一点变动，得到的哈希值差别很大
  - 冲突避免：很难找到不同的原始数据得到相同的哈希值，宇宙中原子数大约在 10 的 60 次方到 80 次方之间，所以 2 的 256 次方有足够的空间容纳所有的可能，算法好的情况下冲突碰撞的概率很低：
    - 2 的 128 次方为 340282366920938463463374607431768211456，也就是 10 的 39 次方级别
    - 2 的 160 次方为 1.4615016373309029182036848327163e+48，也就是 10 的 48 次方级别
    - 2 的 256 次方为 1.1579208923731619542357098500869 × 10 的 77 次方，也就是 10 的 77 次方

**注意：**

1. 以上不能保证数据被恶意篡改，原始数据和哈希值都可能被恶意篡改，要保证不被篡改，可以使用RSA 公钥私钥方案，再配合哈希值。
2. 哈希算法主要用来防止计算机传输过程中的错误，早期计算机通过前 7 位数据第 8 位奇偶校验码来保障（12.5% 的浪费效率低），对于一段数据或文件，通过哈希算法生成 128bit 或者 256bit 的哈希值，如果校验有问题就要求重传。



### (6) 常见问题

#### 使用 cookie 需要考虑的问题

- 因为存储在客户端，容易被客户端篡改，使用前需要验证合法性
- 不要存储敏感数据，比如用户密码，账户余额
- 使用 httpOnly 在一定程度上提高安全性
- 尽量减少 cookie 的体积，能存储的数据量不能超过 4kb
- 设置正确的 domain 和 path，减少数据传输
- **cookie 无法跨域**
- 一个浏览器针对一个网站最多存 20 个Cookie，浏览器一般只允许存放 300 个Cookie
- **移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token**

#### 使用 session 需要考虑的问题

- 将 session 存储在服务器里面，当用户同时在线量比较多时，这些 session 会占据较多的内存，需要在服务端定期的去清理过期的 session
- 当网站采用**集群部署**的时候，会遇到多台 web 服务器之间如何做 session 共享的问题。因为 session 是由单个服务器创建的，但是处理用户请求的服务器不一定是那个创建 session 的服务器，那么该服务器就无法拿到之前已经放入到 session 中的登录凭证之类的信息了。
- 当多个应用要共享 session 时，除了以上问题，还会遇到跨域问题，因为不同的应用可能部署的主机不一样，需要在各个应用做好 cookie 跨域的处理。
- **sessionId 是存储在 cookie 中的，假如浏览器禁止 cookie 或不支持 cookie 怎么办？** 一般会把 sessionId 跟在 url 参数后面即重写 url，所以 session 不一定非得需要靠 cookie 实现
- **移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token**

#### 使用 token 需要考虑的问题

- 如果你认为用数据库来存储 token 会导致查询时间太长，可以选择放在内存当中。比如 redis 很适合你对 token 查询的需求。
- **token 完全由应用管理，所以它可以避开同源策略**
- **token 可以避免 CSRF 攻击(因为不需要 cookie 了)**
- **移动端对 cookie 的支持不是很好，而 session 需要基于 cookie 实现，所以移动端常用的是 token**

#### 使用 JWT 时需要考虑的问题

- 因为 JWT 并不依赖 Cookie 的，所以你可以使用任何域名提供你的 API 服务而不需要担心跨域资源共享问题（CORS）
- JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。
- JWT 不加密的情况下，不能将秘密数据写入 JWT。
- JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。
- JWT 最大的优势是服务器不再需要存储 Session，使得服务器认证鉴权业务可以方便扩展。但这也是 JWT 最大的缺点：由于服务器不需要存储 Session 状态，因此使用过程中无法废弃某个 Token 或者更改 Token 的权限。也就是说一旦 JWT 签发了，到期之前就会始终有效，除非服务器部署额外的逻辑。
- JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。
- JWT 适合一次性的命令认证，颁发一个有效期极短的 JWT，即使暴露了危险也很小，由于每次操作都会生成新的 JWT，因此也没必要保存 JWT，真正实现无状态。
- 为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。

#### 使用加密算法要考虑的问题

- 绝不要以**明文存储**密码
- **永远使用 哈希算法 来处理密码，绝不要使用 Base64 或其他编码方式来存储密码，这和以明文存储密码是一样的，使用哈希，而不要使用编码**。编码以及加密，都是双向的过程，而密码是保密的，应该只被它的所有者知道， 这个过程必须是单向的。哈希正是用于做这个的，从来没有解哈希这种说法， 但是编码就存在解码，加密就存在解密。
- 绝不要使用弱哈希或已被破解的哈希算法，像 MD5 或 SHA1 ，只使用强密码哈希算法。
- 绝不要以明文形式显示或发送密码，即使是对密码的所有者也应该这样。如果你需要 “忘记密码” 的功能，可以随机生成一个新的 **一次性的**（这点很重要）密码，然后把这个密码发送给用户。

#### 分布式架构session 共享方案

###### 1. session 复制

- 任何一个服务器上的 session 发生改变（增删改），该节点会把这个 session 的所有内容序列化，然后广播给所有其它节点，不管其他服务器需不需要 session ，以此来保证 session 同步

**优点：** 可容错，各个服务器间 session 能够实时响应。 
 **缺点：** 会对网络负荷造成一定压力，如果 session 量大的话可能会造成网络堵塞，拖慢服务器性能。

###### 2. 粘性 session /IP 绑定策略

- **采用 Ngnix 中的 ip_hash 机制，将某个 ip的所有请求都定向到同一台服务器上，即将用户与服务器绑定。** 用户第一次请求时，负载均衡器将用户的请求转发到了 A 服务器上，如果负载均衡器设置了粘性 session 的话，那么用户以后的每次请求都会转发到 A 服务器上，相当于把用户和 A 服务器粘到了一块，这就是粘性 session 机制。

**优点：** 简单，不需要对 session 做任何处理。 
 **缺点：** 缺乏容错性，如果当前访问的服务器发生故障，用户被转移到第二个服务器上时，他的 session 信息都将失效。 
 **适用场景：** 发生故障对客户产生的影响较小；服务器发生故障是低概率事件 。
 **实现方式：** 以 Nginx 为例，在 upstream 模块配置 ip_hash 属性即可实现粘性 session。

###### 3. session 共享（常用）

- 使用分布式缓存方案比如 Memcached 、Redis 来缓存 session，但是要求 Memcached 或 Redis 必须是集群
- 把 session 放到 Redis 中存储，虽然架构上变得复杂，并且需要多访问一次 Redis ，但是这种方案带来的好处也是很大的：
  - 实现了 session 共享；
  - 可以水平扩展（增加 Redis 服务器）；
  - 服务器重启 session 不丢失（不过也要注意 session 在 Redis 中的刷新/失效机制）；
  - 不仅可以跨服务器 session 共享，甚至可以跨平台（例如网页端和 APP 端）

<img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/12/29/16f523a04fb8b4b8~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp" alt="img" style="zoom:50%;" />

###### 4. session 持久化

- 将 session 存储到数据库中，保证 session 的持久化

**优点：** 服务器出现问题，session 不会丢失 
 **缺点：** 如果网站的访问量很大，把 session 存储到数据库中，会对数据库造成很大压力，还需要增加额外的开销维护数据库。

#### **只要关闭浏览器 ，session 真的就消失了？**

​		不对。对 session 来说，除非程序通知服务器删除一个 session，否则服务器会一直保留，程序一般都是在用户做 log off 的时候发个指令去删除 session。
然而浏览器从来不会主动在关闭之前通知服务器它将要关闭，因此服务器根本不会有机会知道浏览器已经关闭，之所以会有这种错觉，是大部分 session 机制都使用会话 cookie 来保存 session id，而关闭浏览器后这个 session id 就消失了，再次连接服务器时也就无法找到原来的 session。如果服务器设置的 cookie 被保存在硬盘上，或者使用某种手段改写浏览器发出的 HTTP 请求头，把原来的 session id 发送给服务器，则再次打开浏览器仍然能够打开原来的 session。

​		恰恰是**由于关闭浏览器不会导致 session 被删除，迫使服务器为 session 设置了一个失效时间，当距离客户端上一次使用 session 的时间超过这个失效时间时，服务器就认为客户端已经停止了活动，才会把 session 删除以节省存储空间。**

## 4. HTTP 1.0，1.1，2.0

### (1) HTTP 1.0，1.1，2.0 的主要区别

http/1.0 :

1. 默认不支持长连接，需要设置keep-alive参数指定
2. 强缓存expired、协商缓存last-modified\if-modified-since 有一定的缺陷

http 1.1 :

1. 默认长连接(keep-alive)，http请求可以复用Tcp连接，但是同一时间只能对应一个http请求(http请求在一个Tcp中是串行的)
2. 增加了强缓存cache-control、协商缓存etag\if-none-match 是对http/1 缓存的优化

http/2.0 :

1. 多路复用，一个Tcp中多个http请求是并行的 (雪碧图、多域名散列等优化手段http/2中将变得多余)
2. 二进制格式编码传输
3. 使用HPACK算法做header压缩
4. 服务端推送

### (2)  HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

**HTTP/1.1 相比 HTTP/1.0 性能上的改进：**

- 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

**但 HTTP/1.1 还是有性能瓶颈：**

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。

### (3) HTTP/2 做了什么优化？

- HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。
- 那 HTTP/2 相比 HTTP/1.1 性能上的改进：
  - **头部压缩：**如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的部分**。
    - `HPACK` 算法：客户端和服务器同时维护一张头信息表，所有字段都会存入这个表生成一个索引号，以后就不发送同样字段，只发送索引号，提高速度
  - **二进制格式**：HTTP/1.1 是纯文本形式的报文，2.0全面采用了**二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧和数据帧**。
  - **数据流：**每个请求或回应的所有数据包，称为一个数据流（`Stream`）。
    - 数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。
    - 每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数。
    - 客户端还可以**指定数据流的优先级**。优先级高的请求，服务器就先响应该请求。
  - **多路复用**：可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。
    - 移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟，大幅度提高了连接的利用率**。
  - **服务器推送：**HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。
    - 在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，**减少延时的等待**。

####  HTTP/2 是如何提示性能的几个方向

​		它相比 HTTP/1 大大提高了传输效率、吞吐能力。

- 第一点，对于常见的 HTTP 头部通过**静态表和 Huffman 编码**的方式，将体积压缩了近一半，而且针对后续的请求头部，还可以建立**动态表**，将体积压缩近 90%，大大提高了编码效率，同时节约了带宽资源。
  - 不过，动态表并非可以无限增大， 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的并发能力，因此服务器需要限制 HTTP/2 连接时长或者请求次数。
- 第二点，**HTTP/2 实现了 Stream 并发**，多个 Stream 只需复用 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，以及减少了 TCP 慢启动阶段对流量的影响。不同的 Stream ID 才可以并发，即时乱序发送帧也没问题，但是同一个 Stream 里的帧必须严格有序。
  - 另外，可以根据资源的渲染顺序来设置 Stream 的**优先级**，从而提高用户体验。
- 第三点，**服务器支持主动推送资源**，大大提升了消息的传输性能，服务器推送资源时，会先发送 PUSH_PROMISE 帧，告诉客户端接下来在哪个 Stream 发送资源，然后用偶数号 Stream 发送资源给客户端。
  - HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。
  - HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。

### (4) HTTP/2 有哪些缺陷？

HTTP/2 主要的问题在于，多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。

- HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了
- HTTP/2 多个请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。

这都是基于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

**缺陷：**

HTTP/2 虽然具有多个流并发传输的能力，但是传输层是 TCP 协议，于是存在以下缺陷：

- **队头阻塞**，HTTP/2 多个请求跑在一个 TCP 连接中，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是多个请求被阻塞了；
- **TCP 和 TLS 握手时延**，TCL 三次握手和 TLS 四次握手，共有 3-RTT 的时延；
- **连接迁移需要重新连接**，移动设备从 4G 网络环境切换到 WIFI 时，由于 TCP 是基于四元组来确认一条 TCP 连接的，那么网络环境变化后，就会导致 IP 地址或端口变化，于是 TCP 只能断开连接，然后再重新建立连接，切换网络环境的成本高；

### (5) HTTP/3 做了哪些优化？

于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。**

UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。

大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

- QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，**其他流不会受到影响**。
- TLS3 升级成了最新的 `1.3` 版本，头部压缩算法也升级成了 `QPack`。
- HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 `TLS/1.3` 的三次握手。QUIC 直接把以往的 TCP 和 `TLS/1.3` 的 6 次交互**合并成了 3 次，减少了交互次数**。

所以， QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。

QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题。所以 HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。

**QUIC 协议的特点：**

- **无队头阻塞**，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，也不会有底层协议限制，某个流发生丢包了，只会影响该流，其他流不受影响；
- **建立连接速度快**，因为 QUIC 内部包含 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与 TLS 密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。
- **连接迁移**，QUIC 协议没有用四元组的方式来“绑定”连接，而是通过「连接 ID 」来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本；

另外 HTTP/3 的 QPACK 通过两个特殊的单向流来同步双方的动态表，解决了 HTTP/2 的 HPACK 队头阻塞问题。

## 4. HTTP长连接和短连接的区别

​		在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。

​		而从HTTP/1.1起，默认使用长连接，用以保持连接特性。

## 5. HTTP中缓存的私有和共有字段

​		private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。

​		public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中。

#### HTTP如何禁用缓存？如何确认缓存？

​		HTTP/1.1 通过 Cache-Control 首部字段来控制缓存。

 **禁止进行缓存**

​		no-store 指令规定不能对请求或响应的任何一部分进行缓存。

**强制确认缓存**

​		no-cache 指令规定缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。

## 6. TCP和HTTP

### (1) 一个TCP连接可以对应几个HTTP请求？

​		如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

### (2) 一个 TCP 连接中 HTTP 请求发送可以一起发送么？

HTTP/1.1 存在一个问题，单个 TCP 连接在同一时刻只能处理一个请求，意思是说：两个请求的生命周期不能重叠，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。

在 HTTP/1.1 存在 Pipelining 技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的。在 HTTP2 中由于 Multiplexing 特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。

那么在 HTTP/1.1 时代，浏览器是如何提高页面加载效率的呢？主要有下面两点：

- 维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求。
- 和服务器建立多个 TCP 连接。

### (3) 浏览器对同一 Host 建立TCP连接到的数量有没有限制？

​		假设我们还处在 HTTP/1.1 时代，那个时候没有多路传输，当浏览器拿到一个有几十张图片的网页该怎么办呢？肯定不能只开一个 TCP 连接顺序下载，那样用户肯定等的很难受，但是如果每个图片都开一个 TCP 连接发 HTTP 请求，那电脑或者服务器都可能受不了，要是有 1000 张图片的话总不能开 1000 个TCP 连接吧，你的电脑同意 NAT 也不一定会同意。

**有。Chrome 最多允许对同一个 Host 建立六个 TCP 连接。不同的浏览器有一些区别。**

​		如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP2，如果能的话就使用 Multiplexing 功能在这个连接上进行多路传输。不过也未必会所有挂在这个域名的资源都会使用一个 TCP 连接去获取，但是可以确定的是 Multiplexing 很可能会被用到。

​		如果发现用不了 HTTP2 呢？或者用不了 HTTPS（现实中的 HTTP2 都是在 HTTPS 上实现的，所以也就是只能使用 HTTP/1.1）。那浏览器就会在一个 HOST 上建立多个 TCP 连接，连接数量的最大限制取决于浏览器设置，这些连接会在空闲的时候被浏览器用来发送新的请求，如果所有的连接都正在发送请求呢？那其他的请求就只能等等了。

### (4) 建立TCP 连接后是否会在一个 HTTP 请求完成后断开？

在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。但是这样每次请求都会重新建立和断开 TCP 连接，代价过大。所以虽然标准中没有设定，**某些服务器对 Connection: keep-alive 的 Header 进行了支持**。意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免。

**持久连接**：既然维持 TCP 连接好处这么多，HTTP/1.1 就把 Connection 头写进标准，并且默认开启持久连接，除非请求中写明 Connection: close，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，不会一个请求结束就断掉。

默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 Connection: close 才会在请求完成后关闭连接。

## 7. 优化

### (1) 优化 HTTP/1.1 协议

- 第一个思路是，通过**缓存技术来避免发送 HTTP 请求**。客户端收到第一个请求的响应后，可以将其缓存在本地磁盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候带上响应数据的摘要，服务器比对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然有效。
- 第二个思路是，**减少 HTTP 请求的次数**，有以下的方法：
  - 将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少重定向请求的次数；
  - 将多个小资源合并成一个大资源再传输，能减少 HTTP 请求次数及头部的重复传输，再来减少 TCP 连接数量，进而省去 TCP 握手和慢启动的网络消耗；
  - 按需访问资源，只访问当前用户看得到/用得到的资源，当客户往下滑动再访问接下来的资源，以此达到延迟请求也就减少了同一时间的 HTTP 请求次数。

- 第三思路是，**通过压缩响应资源，降低传输资源的大小**，从而提高传输效率，所以应当选择更优秀的压缩算法。

#### 如何避免发送 HTTP 请求？

​		对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了

#### 如何减少 HTTP 请求次数？

- **减少重定向请求次数：**如果重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了
- **合并请求：**
  - 如果把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着**减少了重复发送的 HTTP 头部**。
  - 如果合并了请求，也就会**减少 TCP 连接的数量，因而省去了 TCP 握手和慢启动过程耗费的时间**。
  - 当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件，这显然**带来了额外的网络消耗**。
- **延迟发送请求：**请求网页的时候，只获取当前用户所看到的页面资源，当用户向下滑动页面的时候再向服务器获取接下来的资源，达到延迟发送请求的效果。

#### 如何减少 HTTP 响应的数据大小？

于是，我们可以考虑对响应的资源进行**压缩**，这样就可以减少响应的数据大小，从而提高网络传输的效率。

压缩的方式一般分为 2 种，分别是：

- 无损压缩：资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合用在文本文件、程序可执行文件、程序源代码。
- 有损压缩：解压的数据会与原始数据不同但是非常接近，将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，这种方法经常用于压缩多媒体数据

### (2) 优化HTTPS

​		因为 HTTPS 相比 HTTP 协议多一个 TLS 协议握手过程，**目的是为了通过非对称加密握手协商或者交换出对称加密密钥**，这个过程最长可以花费掉 2 RTT，接着后续传输的应用数据都得使用对称加密密钥来加密/解密。为了数据的安全性，我们不得不使用 HTTPS 协议，因此针对 HTTPS 的优化是非常重要的。

- **硬件优化：**因为 HTTPS 是属于计算密集型，应该选择计算力更强的 CPU，而且最好选择**支持 AES-NI 特性的 CPU**，这个特性可以在硬件级别优化 AES 对称加密算法，加快应用数据的加解密。
- **软件优化：**如果可以，把软件升级成较新的版本，比如将 Linux 内核 2.X 升级成 4.X，将 openssl 1.0.1 升级到 1.1.1，因为新版本的软件不仅会提供新的特性，而且还会修复老版本的问题。
- **协议优化：**
  - 密钥交换算法应该选择 **ECDHE 算法**，而不用 RSA 算法，因为 ECDHE 算法具备前向安全性，而且客户端可以在第三次握手之后，就发送加密应用数据，节省了 1 RTT。
  - 将 TSL1.2 升级 **TSL1.3**，因为 TSL1.3 的握手过程只需要 1 RTT，而且安全性更强。
- **证书优化：**
  - 服务器应该选用 **ECDSA 证书**，而非 RSA 证书，因为在相同安全级别下，ECC 的密钥长度比 RSA 短很多，这样可以提高证书传输的效率；
  - 服务器应该开启 **OCSP Stapling** 功能，由服务器预先获得 OCSP 的响应，并把响应结果缓存起来，这样 TLS 握手的时候就不用再访问 CA 服务器，减少了网络通信的开销，提高了证书验证的效率；
- **重连 HTTPS ：**
  - 我们可以使用一些技术让客户端和服务端使用上一次 HTTPS 连接使用的会话密钥，直接恢复会话，而不用再重新走完整的 TLS 握手过程。
  - 常见的**会话重用**技术有 Session ID 和 Session Ticket，用了会话重用技术，当再次重连 HTTPS 时，只需要 1 RTT 就可以恢复会话。对于 TLS1.3 使用 Pre-shared Key 会话重用技术，只需要 0 RTT 就可以恢复会话。
  - 这些会话重用技术虽然好用，但是存在一定的安全风险，它们不仅不具备前向安全，且有重放攻击的风险，所以应对会话密钥设定一个合理的过期时间。

## 8. 代理HTTP服务器

**(1) 访问DNS服务器以查询域名对应的IP地址**

**(2) 查询路由器MAC地址的ARP请求和应答**

- **HTTP服务器执行DNS查询的完整过程**
  - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413110826832.png" alt="image-20220413110826832" style="zoom:67%;" />
  - HTTP服务器先查询DNS服务器的IP地址，然后把控制权传递给内核中的UDP模块，UDP模块将DNS查询报文封装成UDP数据报，然后UDP模块调用IP服务，将UDP数据报封装为IP数据报，IP模块查询路由表得到路由器的IP地址，通过ARP广播以查询该路由器的MAC地址，然后封装成以太网帧发送给路由器。

**(3) 客户端和HTTP服务器的HTTP通信**

**(4) HTTP和Web服务器之间的HTTP通信**

# 4 DNS域名解析

## (1) DNS是什么

​		**官方解释**：DNS（Domain Name System，域名系统），因特网上作为**域名和IP地址相互映射**的一个**分布式数据库**，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。

​		通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。

​		**通俗的讲**，我们更习惯于记住一个网站的名字，比如www.baidu.com,而不是记住它的ip地址，比如：167.23.10.2。

## (2) DNS的工作原理

将主机域名转换为ip地址，属于应用层协议，使用UDP传输。（DNS应用层协议，以前有个考官问过）

![](https://cdn.jsdelivr.net/gh/forthespada/mediaImage1@1.6.4.1/202103/QQ截图20210317172225.png)

​		浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。

​		主机向本地域名服务器的查询一般都是采用递归查询。

​		本地域名服务器向根域名服务器的查询的迭代查询。

​				1. 当用户输入域名时，浏览器先检查自己的缓存中是否 这个域名映射的ip地址，有解析结束。

​				2. 若没命中，则检查操作系统缓存（如Windows的hosts）中有没有解析过的结果，有解析结束。

​				3. 若无命中，则请求本地域名服务器解析（ LDNS）。

​				4. 若LDNS没有命中就直接跳到根域名服务器请求解析。根域名服务器返回给LDNS一个 主域名服务器地址。

​				5. 此时LDNS再发送请求给上一步返回的gTLD（ 通用顶级域）， 接受请求的gTLD查找并返回这个域名对应的Name Server的地址

​				6. Name Server根据映射关系表找到目标ip，返回给LDNS

​				7. LDNS缓存这个域名和对应的ip， 把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束

## (3) DNS解析过程

![](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.6/202104/net-net-17-1.png)

- 请求一旦发起，若是chrome浏览器，先在浏览器找之前**有没有缓存过的域名所对应的ip地址**，有的话，直接跳过dns解析了，若是没有，就会**找硬盘的hosts文件**，看看有没有，有的话，直接找到hosts文件里面的ip
- 如果本地的hosts文件没有能得到对应的ip地址，浏览器会发出一个**dns请求到本地dns服务器**，**本地dns服务器一般都是你的网络接入服务器商提供**，比如中国电信，中国移动等。
- 查询你输入的网址的DNS请求到达本地DNS服务器之后，**本地DNS服务器会首先查询它的缓存记录**，如果缓存中有此条记录，就可以直接返回结果，此过程是**递归的方式进行查询**。如果没有，本地DNS服务器还要向**DNS根服务器**进行查询。
- 本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址。
- 最后，本地DNS服务器向**域名的解析服务器**发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。

#### 域名解析的工作流程

1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
3. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
6. 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。

## (4) 域名解析过程，本机如何干预域名解析

1. （1）在浏览器中输入[www.qq.com](http://www.qq.com/)域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。

   （2）如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。

   （3）如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。

   （4）如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。

   （5）如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到[www.qq.com](http://www.qq.com/)主机。

   （6）如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。

   从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。

2. 通过修改本机host来干预域名解析，例如： 在/etc/hosts文件中添加一句话

   ```
    192.168.188.1 www.baidu.com
   ```

   保存文件后再ping一下www.baidu.com就会连接到192.168.188.1了

   每一行为一条记录，分成两部分，第一部分是IP，第二部分是域名。

   - 一个IP后面可以跟多个域名，可以是几十个甚至上百个
   - 每一行只能有一个IP，也就是说一个域名不能对应多个IP
   - 如果有多行中出现相同的域名（对应的ip不一样），会按最前面的记录来解析

## (5) DNS 查询服务器的基本流程

​		打开浏览器，输入一个域名。比如输入www.163.com，这时，你使用的电脑会发出一个DNS请求到本地DNS服务器。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动。

​		DNS请求到达本地DNS服务器之后，本地DNS服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果。如果没有，本地DNS服务器还要向DNS根服务器进行查询。

​			根DNS服务器没有记录具体的域名和IP地址的对应关系，而是告诉本地DNS服务器，你可以到域服务器上去继续查询，并给出域服务器的地址。

​		本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址。

​		最后，本地DNS服务器向域名的解析服务器发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。

## (6) DNS 劫持

​		DNS劫持就是通过劫持了DNS服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致对该域名的访问由原IP地址转入到修改后的指定IP，其结果就是对特定的网址不能访问或访问的是假网址，从而实现窃取资料或者破坏原有正常服务的目的。DNS劫持通过篡改DNS服务器上的数据返回给用户一个错误的查询结果来实现的。

​		DNS劫持症状：在某些地区的用户在成功连接宽带后，首次打开任何页面都指向ISP提供的“电信互联星空”、“网通黄页广告”等内容页面。还有就是曾经出现过用户访问Google域名的时候出现了百度的网站。这些都属于DNS劫持。

## (7) 为什么域名解析用UDP协议

​		因为UDP快啊！UDP的DNS协议只要一个请求、一个应答就好了。

​		而使用基于TCP的DNS协议要三次握手、发送数据以及应答、四次挥手，但是UDP协议传输内容不能超过512字节。

​		不过客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。

## (8) 为什么区域传送用TCP协议

​		因为TCP协议可靠性好啊！

​		你要从主DNS上复制内容啊，你用不可靠的UDP？ 因为TCP协议传输的内容大啊，你用最大只能传512字节的UDP协议？万一同步的数据大于512字节，你怎么办？所以用TCP协议比较好！

## (9) DNS负载均衡是什么策略？

​		当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会崩掉。处理办法就是用DNS负载均衡技术，它的原理是在**DNS服务器中为同一个主机名配置多个IP地址,在应答DNS查询时,DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果,将客户端的访问引导到不同的机器上去,使得不同的客户端访问不同的服务器**,从而达到负载均衡的目的｡例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。

## (10) DNS查询方式有哪些

##### 递归解析

当局部DNS服务器自己不能回答客户机的DNS查询时，它就需要向其他DNS服务器进行查询。此时有两种方式。**局部DNS服务器自己负责向其他DNS服务器进行查询，一般是先向该域名的根域服务器查询，再由根域名服务器一级级向下查询**。最后得到的查询结果返回给局部DNS服务器，再由局部DNS服务器返回给客户端。

##### 迭代解析

当局部DNS服务器自己不能回答客户机的DNS查询时，也可以通过迭代查询的方式进行解析。局部DNS服务器不是自己向其他DNS服务器进行查询，**而是把能解析该域名的其他DNS服务器的IP地址返回给客户端DNS程序**，客户端DNS程序再继续向这些DNS服务器进行查询，直到得到查询结果为止。也就是说，迭代解析只是帮你找到相关的服务器而已，而不会帮你去查。比如说：baidu.com的服务器ip地址在192.168.4.5这里，你自己去查吧，本人比较忙，只能帮你到这里了。