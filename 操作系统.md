# 1 操作系统概述

## 1. 操作系统作用

​		1. OS作为**用户与计算机硬件系统之间的接口**

​		2.  作为**计算机系统资源的管理者**

​			在一个计算机系统中，通常都含有多种硬件和软件资源。归纳起来可将这些**资源**分为四类：**处理机、存储器、I/O设备以及文件(数据和程序)**。

​		3.  实现了**对计算机资源的抽象**

## 2. 操作系统的主要功能

​		**(1) 处理机管理功能**

​				进程控制、进程同步、进程通信、调度（作业调度，进程调度）

​		**(2) 存储器管理**

​				内存分配（静态、动态）、内存保护、地址映射、内存扩充（虚拟存储技术，系统必须设置内存扩充机制：请求调入功能，置换功能）

​		**(3) 设备管理**

​				缓冲管理、设备分配、设备处理

​		**(4) 文件管理**

​				文件存储空间的管理、目录管理、文件的读/写管理和保护（文件的读/写管理、文件保护）

​		**(5) 操作系统与用户之间的接口** 

​				用户接口（联机用户接口，脱机用户接口，图形用户接口）、程序接口

​		**(6) 现代操作系统的新功能**

​				**系统安全**（认证技术，密码技术，访问控制技术，反病毒技术）**网络的功能和服务**（网络通信，资源管理，应用互操作）**支持多媒体**（接纳控制功能，实时调度，多媒体文件的存储）

# 2 硬件结构

## 1. 硬件结构

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220323094448490.png" alt="image-20220323094448490" style="zoom:33%;" />

​	**中央处理器（CPU）、内存、输入设备、输出设备、总线**

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220322132509182.png" alt="image-20220322132509182" style="zoom: 67%;" />

**中央处理器（CPU）**：32 位和 64 位（**位宽**） CPU 最主要区别在于一次能计算多少字节数据。 32位 最大4294967295 42亿

​										**控制单元CU**负责控制 CPU 工作，**逻辑运算单元**负责计算，**寄存器**存储计算时的数据（通用寄存器、程序计数器PC、指令寄存器IR）

**内存**：程序和数据都是存储在内存，存储的区域是线性的。数据存储的单位是一个**二进制位(bit)**。最小的存储单位是**字节(byte)**，1字节是8 位。存储结构像数组

**总线**：用于 CPU 和内存以及其他设备之间的通信（地址总线、数据总线、控制总线）

**输入/输出设备**：若输入设备是键盘，按下按键时是需要和 CPU 进行交互的，这时就需要用到控制总线

4G内存 32条地址总线 32 位 CPU 最大只能操作 4GB 内存，就算装了 8 GB 内存条，也没用。而 64 位 CPU 寻址范围则很大，理论最大的寻址空间为 `2^64`

## 2. 冯诺依曼模型

**冯诺依曼模型，计算机由五大部件组成**

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220323094050600.png" alt="image-20220323094050600" style="zoom: 33%;" />

**现代计算机硬件框图**

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220323094149177.png" alt="image-20220323094149177" style="zoom:33%;" />

**冯诺依曼结构，分别对应现代计算机的哪几个部分？**

* 存储器：内存
* 控制器：南桥北桥？
* 运算器：CPU
* 输入设备：键盘
* 输出设备：显示器、网卡

## 3. 存储器的层次结构

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220322140105911.png" alt="image-20220322140105911" style="zoom:50%;" />

​		**寄存器**：最靠近 CPU 的控制单元和逻辑计算单元的存储器，就是寄存器，也是最快的

​		**CPU Cache**：（L1-Cache L2-Cache L3-Cahce） **SRAM**（ Static Random-Access Memory，**静态随机存储器**）芯片，只要有电，数据就可以保持存在

​		**内存**：**DRAM** （Dynamic Random Access Memory，**动态随机存储器**）芯片，需要「定时刷新」电容，才能保证数据不会被丢失

​		**SSD 固体硬盘**：断电后数据还是存在的，内存的读写速度比 SSD 大概快 `10~1000` 倍。

​		**HDD 机械硬盘**：断电后数据还是存在的，通过物理读写的方式来访问数据的，因此它访问速度是非常慢的，它的速度比内存慢 `10W` 倍左右

## 4. 内核

**内核功能：**

- 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力；
- 管理内存，决定内存的分配和回收，也就是内存管理的能力；
- 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力；
- 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。

**内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件**，而应用程序具有的权限很小，因此大多数操作系统，把**内存**分成了两个区域：

- **内核空间**，这个内存空间只有内核程序可以访问；

- **用户空间**，这个内存空间专门给应用程序使用；

  **用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。**因此，当程序使用用户空间时，我们常说该程序在**用户态**执行，而当程序使内核空间时，程序则在**内核态**执行。应用程序如果需要进入内核空间，就需要通过**系统调用**。

**系统调用的过程**：

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220322143713261.png" alt="image-20220322143713261" style="zoom: 67%;" />

​		**当应用程序使用系统调用时，会产生一个中断**。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。

###  Linux什么时候进入内核态

1. **内核态与用户态**：**内核态**（系统态）与**用户态**是操作系统的两种运行级别。内核态拥有最高权限，可以访问所有系统指令；用户态则只能访问一部分指令。
2. **什么时候进入内核态**：共有三种方式：a、**系统调用**。b、**异常**。c、**设备中断**。其中，系统调用是主动的，另外两种是被动的。
3. **为什么区分内核态与用户态**：在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。所以区分内核态与用户态主要是出于安全的考虑。

## 5. 软中断

为了避免由于中断处理程序执行时间过长，而影响正常进程的调度，Linux 将中断处理程序分为上半部和下半部：

- 上半部，对应硬中断，由硬件触发中断，用来快速处理中断；
- 下半部，对应软中断，由内核触发中断，用来异步处理上半部未完成的工作；内核自定义事件，比如内核调度等、RCU 锁（内核里常用的一种锁）等

#### 外中断和异常有什么区别？

​		外中断是指由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

​		而异常时由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

## 6. 程序执行的基本过程

**(1) 主机完成一条指令的过程**

​		将程序通过输入设备送至计算机，将程序首地址送入程序计数器，启动程序运行，取指令(数据)，程序计数器加一，分析指令，执行指令，打印结果，停机

**(2) CPU 执行一条程序**

​		一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。

​		CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束

**(3) 操作系统加载一个程序到执行所经历的全部步骤**   -> (1)

## 7. GCC编译器

 **GCC工作流程**

![image-20220318113531685](file://C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220318113531685.png?lastModify=1648001289)

![image-20220318113544144](file://C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220318113544144.png?lastModify=1648001289)

**预处理：头文件的展开，注释的删除，宏的替换**

**cpp文件用gcc编译会出现报错找不到头文件 得用g++**

## 8. 虚拟内存

​		操作系统为每个进程分配独立的一套「**虚拟地址**」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了

​		**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**

​				(1) 我们程序所使用的**内存地址**叫做**虚拟内存地址**（*Virtual Memory Address*）

​				(2) 实际存在**硬件里面的空间地址**叫**物理内存地址**（*Physical Memory Address*）。

​		进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220318124739676.png" alt="image-20220318124739676" style="zoom:67%;" />

​		**用户区：**代码区、未初始化数据区(BSS)、已初始化数据区（全局变量/静态常量）、栈区（局部变量和函数调用的上下文）、堆区(动态分配的内存)

### 虚拟内存和物理内存

#### (1) 操作系统如何管理内存

1. **物理内存**：物理内存有四个层次，分别是寄存器、高速缓存、主存、磁盘。

   寄存器：速度最快、量少、价格贵。

   高速缓存：次之。

   主存：再次之。

   磁盘：速度最慢、量多、价格便宜。

   ![img](https://uploadfiles.nowcoder.com/images/20220225/4107856_1645788827958/4BD0E43BE7E80C2863C7F79CFE480CF3)

   操作系统会对物理内存进行管理，有一个部分称为**内存管理器(memory manager)**，它的主要工作是有效的管理内存，记录哪些内存是正在使用的，在进程需要时分配内存以及在进程完成时回收内存。

2. **虚拟内存**：操作系统为每一个进程分配一个独立的地址空间是虚拟内存。**虚拟内存与物理内存**存在映射关系，通过**页表寻址**完成虚拟地址和物理地址的转换。

#### (2) 为什么要用虚拟内存

因为早期的内存分配方法存在以下问题：

（1）**进程地址空间不隔离**。会导致数据被随意修改。

（2）**内存使用效率低**。

（3）程序运行的地址不确定。操作系统**随机**为进程分配内存空间，所以**程序运行的地址是不确定的**。

#### (3) 使用虚拟内存的好处

（1）**扩大地址空间。**每个进程独占一个4G空间，虽然真实物理内存没那么多。

（2）**内存保护**：防止不同进程对物理内存的争夺和践踏，可以对特定内存地址提供写保护，防止恶意篡改。

（3）可以实现**内存共享**，方便进程通信。

（4）可以**避免内存碎片**，虽然物理内存可能不连续，但映射到虚拟内存上可以连续。

#### (4) 使用虚拟内存的缺点

（1）虚拟内存需要额外构建数据结构，**占用空间**。

（2）虚拟地址到物理地址的转换，**增加了执行时间**。

（3）**页面换入换出耗时**。

（4）一页如果只有一部分数据，**浪费内存**。

### 内存管理方式

操作系统通过**内存分段**和**内存分页**的方式管理虚拟地址与物理地址之间的关系。

​			**内存分段：**程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。存在**内存碎片**和**内存交换效率低**的问题，就出现了内存分页。

​			**内存分页：**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小，虚拟地址与物理地址之间通过**页表**来映射。

​			**段页式内存管理：**地址结构就由**段号、段内页号和页内位移**三部分组成。

#### (1) 页表

​		页表是虚拟内存的概念。**操作系统虚拟内存到物理内存的映射表，就被称为页表。**

​		**操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表。**页表中的每一项都记录了这个页的基地址。

​		**原因**：不可能每一个虚拟内存的 Byte 都对应到物理内存的地址。这张表将大得真正的物理地址也放不下，于是操作系统引入了页（Page）的概念。进行分页，这样可以**减小虚拟内存页对应物理内存页的映射表大小**。

#### (2) 内部碎片与外部碎片

​		**内碎片：**分配给某些进程的内存区域中有些部分没用上，常见于固定分配方式，内存总量相同，100M，

​						**固定分配：**将100M分割成10块，每块10M，一个程序需要45M，那么需要分配5块，第五块只用了5M，剩下的5M就是内部碎片；

​						**分段式分配：**按需分配，一个程序需要45M，就给分片45MB，剩下的55M供其它程序使用，不存在内部碎片。

​		**外碎片：**内存中某些空闲区因为比较小，而难以利用上，一般出现在内存动态分配方式中

​						**分段式分配：**内存总量相同，100M，比如，内存分配依次5M，15M，50M，25M，程序运行一段时间之后，5M，15M的程序运行完毕，释放内存，其他程序还在运行，再次分配一个10M的内存供其它程序使用，只能从头开始分片，这样，就会存在10M+5M的外部碎片 

**为什么分段式存储管理有外部碎片而无内部碎片？为什么固定分区分配有内部碎片而不会有外部碎片？**

​						分段式分配是按需分配，而固定式分配是固定分配的方式

**如何消除碎片文件？**

​		对于内部碎片，通过**紧凑技术**消除，就是操作系统不时地对进程进行移动和整理。但是这需要动态重定位寄存器地支持，且相对费时。紧凑地过程实际上类似于Windows系统中地磁盘整理程序，只不过后者是对外存空间地紧凑

​		解决外部内存碎片的问题就是**内存交换**。

​		可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。

​		回收内存时要尽可能地将相邻的空闲空间合并。

### 内存交换

#### (1) 内存交换

**交换(对换)技术的设计思想**：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存(进程在内存与磁盘间动态调度)

​		换入：把准备好竞争CPU运行的程序从辅存移到内存。
​		换出：把处于等待状态（或CPU调度原则下被剥夺运行权力）的程序从内存移到辅存，把内存空间腾出来。

**什么时候会进行内存的交换？**

​		内存交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如:在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程;如果缺页率明显下降，就可以暂停换出。

#### (2) 交换空间与虚拟内存的关系

**交换空间**
		Linux 中的交换空间（Swap space）在**物理内存**（RAM）被充满时被使用。如果系统需要更多的内存资源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去。虽然交换空间可以为带有少量内存的机器提供帮助，但是这种方法不应该被当做是对内存的取代。交换空间位于硬盘驱动器上，它比进入物理内存要慢。 
		交换空间可以是一个专用的交换分区（推荐的方法），交换文件，或两者的组合。 
		交换空间的总大小应该相当于你的计算机内存的两倍和 32 MB这两个值中较大的一个，但是它不能超过 2048MB（2 GB）。 
**虚拟内存**
		虚拟内存是文件数据交叉链接的活动文件。是WINDOWS目录下的一个"WIN386.SWP"文件，这个文件会不断地扩大和自动缩小。 
		就速度方面而言,CPU的L1和L2缓存速度最快，内存次之，硬盘再次之。但是**虚拟内存使用的是硬盘的空间**，为什么我们要使用速度最慢的硬盘来做 为虚拟内存呢？因为电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致我们只有可怜的256M/512M内存消耗殆尽。而硬盘空间动辄几十G上百G，为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用。 

#### (3) 内存交换中，被换出的进程保存在哪里？

保存在磁盘中，也就是外存中。具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式;对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式(学过文件管理章节后即可理解)。总之，对换区的I/O速度比文件区的更快。

#### (4) 在发生内存交换时，有些进程是被优先考虑的？你可以说一说吗？

可优先换出阻塞进程;可换出优先级低的进程;为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间…
(注意: PCB 会常驻内存，不会被换出外存)

#### (5) 内存交换和覆盖有什么区别？

​		交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中。

**覆盖**

​		由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成为一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按照调用关系分段，首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统将其调入覆盖区，替换覆盖区中原有的段。

​		覆盖技术的特点：是打破了必须将一个进程的全部信息装入内存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行，再而，大家要注意到，内存中能够更新的地方只有覆盖区的段，不在覆盖区的段会常驻内存。

### 内存分配

#### (1) 常见内存分配方式

**内存分配方式**

（1） **从静态存储区域分配**。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。

（2） **在栈上创建**。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。

（3） **从堆上分配，亦称动态内存分配。**程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

#### (2) 常见内存分配内存错误

（1）**内存分配未成功，却使用了它。**

编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是，在使用内存之前检查指针是否为NULL。如果指针p是函数的参数，那么在函数的入口处用assert(p!=NULL)进行检查。如果是用malloc或new来申请内存，应该用if(p==NULL) 或if(p!=NULL)进行防错处理。

（2）**内存分配虽然成功，但是尚未初始化就引用它。**

犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。

（3）**内存分配成功并且已经初始化，但操作越过了内存的边界。**

例如在使用数组时经常发生下标“多1”或者“少1”的操作。特别是在for循环语句中，循环次数很容易搞错，导致数组操作越界。

（4）**忘记了释放内存，造成内存泄露。**

含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，你看不到错误。终有一次程序突然挂掉，系统出现提示：内存耗尽。动态内存的申请与释放必须配对，程序中malloc与free的使用次数一定要相同，否则肯定有错误（new/delete同理）。

（5）**释放了内存却继续使用它。常见于以下有三种情况：**

- 程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。
- **函数的return语句写错了，注意不要返回指向“栈内存”的“指针”或者“引用”，因为该内存在函数体结束时被自动销毁。**
- 使用free或delete释放了内存后，没有将指针设置为NULL。导致产生“**野指针**”。

#### (3) 操作系统如何申请内存

​		从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap

#### (4) 简述操作系统中malloc的实现原理

​		**malloc底层实现：**当开辟的空间小于 128K 时，调用 brk（）函数；当开辟的空间大于 128K 时，调用mmap（）。malloc采用的是**内存池**的管理方式，以减少内存碎片。先申请大块内存作为堆区，然后将堆区分为多个内存块。当用户申请内存时，直接从堆区分配一块合适的空闲快。采用**隐式链表**将所有空闲块，每一个空闲块记录了一个未分配的、连续的内存地址。

**第二种**

​		**从操作系统层面上看，malloc是通过两个系统调用来实现的： brk和mmap**

* brk是将进程数据段(.data)的最高地址指针向高处移动，这一步可以扩大进程在运行时的堆大小

* mmap是在进程的虚拟地址空间中寻找一块空闲的虚拟内存，这一步可以获得一块可以操作的堆内存。

  ​	通常，分配的内存小于128k时，使用brk调用来获得虚拟内存，大于128k时就使用mmap来获得虚拟内存。

  ​	进程先通过这两个系统调用获取或者扩大进程的虚拟内存，获得相应的虚拟地址，在访问这些虚拟地址的时候，通过缺页中断，让内核分配相应的物理内存，这样内存分配才算完成。

#### (5) 程序从堆中动态分配内存时，虚拟内存上怎么做的

​		页表：是一个存放在物理内存中的数据结构，它记录了虚拟页与物理页的映射关系

​		在进行动态内存分配时，例如malloc()函数或者其他高级语言中的new关键字，操作系统会在硬盘中创建或申请一段虚拟内存空间，并更新到页表（分配一个页表条目（PTE），使该PTE指向硬盘上这个新创建的虚拟页），通过PTE建立虚拟页和物理页的映射关系。

#### (6) 从堆和栈上建立对象哪个快？（考察堆和栈的分配效率比较）

从两方面来考虑：

- 分配和释放，堆在分配和释放时都要调用函数（malloc,free)，比如分配时会到堆空间去寻找足够大小的空间（因为多次分配释放后会造成内存碎片），这些都会花费一定的时间，具体可以看看malloc和free的源代码，函数做了很多额外的工作，而栈却不需要这些。
- 访问时间，访问堆的一个具体单元，需要两次访问内存，第一次得取得指针，第二次才是真正的数据，而栈只需访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的。

#### (7) 动态分区分配算法

##### 1、首次适应算法

- **算法思想：**每次都从低地址开始查找，找到第–个能满足大小的空闲分区。
- **如何实现：**空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链( 或空闲分[表)，找到大小能满足要求的第-一个空闲分区。

<img src="https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/操作系统-11-1.png" style="zoom: 67%;" />

##### 2、最佳适应算法

- **算法思想：**由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。
- **如何实现：**空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

<img src="https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/操作系统-11-2.png" style="zoom: 67%;" />

##### 3、最坏适应算法

- **算法思想：**为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。又称最大适应算法(Largest Fit)
- **如何实现：**空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

<img src="https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/操作系统-11-3.png" style="zoom:67%;" />

##### 4、邻近适应算法

- **算法思想：**首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
- **如何实现：**空闲分区以地址递增的顺序排列(可排成-一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。

<img src="https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/操作系统-11-4.png" style="zoom:67%;" />

##### 5、总结

首次适应不仅最简单，通常也是最好最快，不过首次适应算法会使得内存低地址部分出现很多小的空闲分区，而每次查找都要经过这些分区，因此也增加了查找的开销。邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。

最佳导致大量碎片，最坏导致没有大的空间。

进过实验，**首次适应**比最佳适应要好，他们都比最坏好。

| 算法         | 算法思想                                           | 分区排列顺序                                 | 优点                                                         | 缺点                                                         |
| ------------ | -------------------------------------------------- | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **首次适应** | 从头到尾找适合的分区                               | 空闲分区以地址递增次序排列                   | 综合看性能最好。**算法开销小**，回收分区后一.般不需要对空闲分区队列重新排序 |                                                              |
| 最佳适应     | 优先使用更小的分区，以保留更多大分区               | 空闲分区以容量递增次序排列                   | 会有更多的大分区被保留下来，更能满足大进程需求               | 会产生很多太小的、难以利用的碎片;**算法开销大**，回收分区后可能需要对空闲分区队列重新排序 |
| 最坏适应     | 优先使用更大的分区，以防止产生太小的不可用的碎片   | 空闲分区以容量递减次序排列                   | 可以减少难以利用的小碎片                                     | 大分区容易被用完，不利于大进程;**算法开销大**(原因同上)      |
| 邻近适应     | 由首次适应演变而来，每次从上次查找结束位置开始查找 | 空闲分区以地址递增次序排列(可排列成循环链表) | 不用每次都从低地址的小分区开始检索。**算法开销小**(原因同首次适应算法) | 会使高地址的大分区也被用完                                   |



## 9. 调度算法

### (1) 内存页面置换算法

**缺页异常（缺页中断）**：CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。

- **最佳页面置换算法（OPT）：**置换在「未来」最长时间不访问的页面
- **先进先出置换算法（FIFO）：**选择在内存驻留时间很长的页面进行中置换
- **最近最久未使用的置换算法（LRU）：**选择最长时间没有被访问的页面进行置换
- **时钟页面置换算法（Lock）：**把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。
- **最不常用置换算法（LFU）：**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰

### (2) 磁盘调度算法

- **先来先服务算法：**先到来的请求，先被服务
- **最短寻道时间优先算法：**优先选择从当前磁头位置所需寻道时间最短的请求
- **扫描算法：**磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向
- **循环扫描算法：**只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，返回中途不处理任何请求
- **LOOK 与 C-LOOK 算法：**磁头在移动到「最远的请求」位置，然后立即反向移动，反向移动的途中会响应请求

###  (3) 简述LRU算法及实现方式

1. **最近最久未使用的置换算法LRU**：LRU算法用于缓存淘汰。思路是将缓存中最近最少使用的对象删除掉
2. **实现方式**：利用**链表和hashmap**。
   - 当需要插入新的数据项的时候，如果新数据项在链表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。
   - 在访问数据的时候，如果数据项在链表中存在，则把该节点移到链表头部，否则返回-1。这样一来在链表尾部的节点就是最近最久未访问的数据项。

## 10. 面试题

### 1 简述操作系统中的缺页中断

1. **缺页异常**：malloc和mmap函数在分配内存时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个**缺页异常，引发缺页中断**。

2. **缺页中断**：缺页异常后将产生一个缺页中断，此时操作系统会根据页表中的**外存地址**在外存中找到所缺的一页，将其调入**内存**。

   ​	缺页中断与一般中断一样，需要经历四个步骤：保护CPU现场、分析中断原因、转入缺页中断处理程序、恢复CPU现场，继续执行。

   ​	缺页中断与一般中断区别： 

   ​				（1）在指令执行期间产生和处理缺页中断信号 

   ​				（2）一条指令在执行期间，可能产生多次缺页中断

   ​			    （3）缺页中断返回的是执行产生中断的一条指令，而一般中断返回的是执行下一条指令。

### 2 32位系统能访问4GB以上的内存吗

**正常情况下是不可以的**。原因是计算机使用二进制，每位数只有0或1两个状态，32位正好是2的32次方，正好是4G，所以大于4G就没办法表示了，而在32位的系统中，因其它原因还需要占用一部分空间，所以内存只能识别3G多。要使用4G以上就只能换64位的操作系统了。

但是使用**PAE技术**就可以实现 32位系统能访问4GB以上的内存。PAE技术将地址扩展到了36位，这样，系统就能够容纳2^36=64GB的内存。

### 3 堆栈溢出是什么，会怎么样

​		堆栈溢出就是不顾堆栈中分配的局部数据块大小，向该数据块写入了过多的数据，导致数据越界。常指调用堆栈溢出，本质上一种数据结构的满溢情况。

​		堆栈溢出可以理解为两个方面：**堆溢出和栈溢出。**

1. 堆溢出：比如不断的new 一个对象，一直创建新的对象，而不进行释放，最终导致内存不足。将会报错：OutOfMemory Error。
2. 栈溢出：一次函数调用中，栈中将被依次压入：参数，返回地址等，而方法如果递归比较深或进去死循环，就会导致栈溢出。将会报错：StackOverflow Error。

### 4 虚拟技术你了解吗

​		虚拟技术把一个物理实体转换为多个逻辑实体。

​		主要有两种虚拟技术：**时（时间）分复用技术和空（空间）分复用技术**

​		多进程与多线程：**多个进程能在同一个处理器上并发执行使用了时分复用技术**，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

​		**虚拟内存使用了空分复用技术**，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

# 3 进程和线程

## 1. 基本概念

### 程序

​		程序是包含一系列信息的文件，这些信息描述了如何在运行时创建一个进程，程序是指令、数据及其组织形式的描述。

### 进程

​		进程则是程序的运行实例，资源分配和拥有的基本单位。

### 单道、多道程序设计

​		单道程序，即在计算机内存中只允许一个的程序运行。

​		多道程序设计技术，是在计算机内存中同时存放几道相互独立的程序，使它们在管理程序控制下，相互穿插运行，为了提高 CPU 的利用率。

### 时间片

​		操作系统分配给每个正在运行的进程微观上的一段 CPU 时间。首先，内核会给每个进程分配相等的初始时间片，然后每个进程轮番地执行相应的时间

### 并行和并发

​		**并行：**指在同一时刻，有多条指令在多个处理器上同时执行。

​		**并发：**指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果。

#### 请你说说并发和并行

1. **并发**：对于单个CPU，在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级，多个任务不停来回快速切换。
2. **并行**：对于多个CPU，多个进程同时运行。
3. **区别**。通俗来讲，它们虽然都说是"多个进程同时运行"，但是它们的"同时"不是一个概念。并行的"同时"是同一时刻可以多个任务在运行(处于running)，并发的"同时"是经过不同线程快速切换，使得看上去多个任务同时都在运行的现象。

### 进程控制块（PCB）

​		内核为每个进程分配一个PCB进程控制块，维护进程相关的信息，Linux 内核的进程控制块是结构体。

### 线程

​		操作系统调度执行的最小单位，是进程当中的一条执行流程，一个进程里包含多个线程并发执行任务。

​		同一个进程内多个线程之间共享同一份全局内存区域，包括初始化数据段、未初始化数据段，以及堆内存段。但每个线程各自都有一套独立的寄存器和栈。

### 轻量级进程

​		内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持。

​		**LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息**。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。

### 说说进程、线程、协程是什么，区别是什么

1. **进程**：程序是指令、数据及其组织形式的描述，而进程则是程序的运行实例，包括程序计数器、寄存器和变量的当前值。
2. **线程**：微进程，一个进程里更小粒度的执行单元。一个进程里包含多个线程并发执行任务。
3. **协程**：协程是微线程，在子程序内部执行，可在子程序内部中断，转而执行别的子程序，在适当的时候再返回来接着执行。

**线程与进程的区别**：

（1）一个线程从属于一个进程；一个进程可以包含多个线程。

（2）一个线程挂掉，对应的进程挂掉；一个进程挂掉，不会影响其他进程。

（3）进程是系统资源调度的最小单位；线程CPU调度的最小单位。

（4）进程系统开销显著大于线程开销；线程需要的系统资源更少。

（5）进程在执行时拥有独立的内存单元，多个线程共享进程的内存，如代码段、数据段、扩展段；但每个线程拥有自己的栈段和寄存器组。

（6）进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈，线程切换时只需要切换硬件上下文和内核栈。

（7）通信方式不一样。

（8）进程适应于多核、多机分布；线程适用于多核

**线程与协程的区别：**

（1）协程执行效率极高。协程直接操作栈基本没有内核切换的开销，所以上下文的切换非常快，切换开销比线程更小。

（2）协程不需要多线程的锁机制，因为多个协程从属于一个线程，不存在同时写变量冲突，效率比线程高。

（3）一个线程可以有多个协程。

**协程是轻量级线程，轻量级表现在哪里：**

1. **协程调用跟切换比线程效率高**：协程执行效率极高。协程不需要多线程的锁机制，可以不加锁的访问全局变量，所以上下文的切换非常快。
2. **协程占用内存少**：执行协程只需要极少的栈内存（大概是4～5KB），而默认情况下，线程栈的大小为1MB。
3. **切换开销更少**：协程直接操作栈基本没有内核切换的开销，所以切换开销比线程少。

|          |                             进程                             |                        线程                        |                             协程                             |
| -------- | :----------------------------------------------------------: | :------------------------------------------------: | :----------------------------------------------------------: |
| 定义     |                   资源分配和拥有的基本单位                   |                 程序执行的基本单位                 |          用户态的轻量级线程，线程内部调度的基本单位          |
| 切换情况 | 进程CPU环境(栈、寄存器、页表和文件句柄等)的保存以及新调度的进程CPU环境的设置 |     保存和设置程序计数器、少量寄存器和栈的内容     |     先将寄存器上下文和栈保存，等切换回来的时候再进行恢复     |
| 切换者   |                           操作系统                           |                      操作系统                      |                             用户                             |
| 切换过程 |                    用户态->内核态->用户态                    |               用户态->内核态->用户态               |                     用户态(没有陷入内核)                     |
| 调用栈   |                            内核栈                            |                       内核栈                       |                            用户栈                            |
| 拥有资源 |             CPU资源、内存资源、文件资源和句柄等              |           程序计数器、寄存器、栈和状态字           |                  拥有自己的寄存器上下文和栈                  |
| 并发性   |        不同进程之间切换实现并发，各自占有CPU实现并行         |           一个进程内部的多个线程并发执行           | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 |
| 系统开销 | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 |  切换时只需保存和设置少量寄存器内容，因此开销很小  | 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 |
| 通信方面 |                  进程间通信需要借助操作系统                  | 线程间可以直接读写进程数据段(如全局变量)来进行通信 |                      共享内存、消息队列                      |

1、进程是资源调度的基本单位，运行一个可执行程序会创建一个或多个进程，进程就是运行起来的可执行程序

2、线程是程序执行的基本单位，是轻量级的进程。每个进程中都有唯一的主线程，且只能有一个，主线程和进程是相互依存的关系，主线程结束进程也会结束。多提一句：协程是用户态的轻量级线程，线程内部调度的基本单位

## 2. 进程的状态

​		在三态模型中，进程状态分为三个基本状态，即**就绪态**，**运行态**，**阻塞态**。在五态模型中，进程分为**新建态**、**就绪态**，**运行态**，**阻塞态**，**终止态**。

​			**运行态：**进程占有CPU处理器正在运行

​			**就绪态：**进程具备运行条件，加入就绪队列，等待系统分配处理器以便运行。

​			**阻塞态：**指进程不具备运行条件，正在等待某个事件的完成

​			**新建态：**进程刚被创建时的状态，尚未进入就绪队列

​			**终止态：**进程完成任务到达正常结束点，或出现无法克服的错误而异常终止，或被操作系统及有终止权的进程所终止时所处的状态。

## 3. 进程的控制

### (1) 创建进程 fork()

​		操作系统允许一个进程创建新进程，新进程即为子进程，子进程还可以创建新的子进程，形成进程树结构模型

​		Linux 的 fork() 使用是通过写时拷贝 (copy- on-write) 实现。内核区拷贝，用户区资源的复制是在需要写入的时候才会进行，在此之前只有以只读方式共享。

**创建进程的过程：**

- 为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB，PCB 是有限的，若申请失败则创建失败；
- 为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源；
- 初始化 PCB；
- 如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行；

### (2) 阻塞进程

​		当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。

​		通常会把阻塞状态的进程的物理内存空间换出到硬盘，描述进程没有占用实际的物理内存空间的情况，这个状态就是**挂起状态**。

**阻塞进程的过程：**

- 找到将要被阻塞进程标识号对应的 PCB；
- 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
- 将该 PCB 插入到阻塞队列中去；

### (3) 唤醒进程

​		进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。

**唤醒进程的过程：**

- 在该事件的阻塞队列中找到相应进程的 PCB；
- 将其从阻塞队列中移出，并置其状态为就绪状态；
- 把该 PCB 插入到就绪队列中，等待调度程序调度；

### (4) 终止进程

​		C语言 `exit(0);`                  Linux `_exit(0);`(不会刷新I/O缓存，导致部分代码不执行)

​		进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 `kill` 掉）。

​		每个进程结束之后, 都会释放自己地址空间中的用户区数据，内核区的 PCB 没有办法自己释放掉，需要父进程去释放。

**终止进程的过程：**

- 查找需要终止的进程的 PCB；
- 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
- 如果其还有子进程，则应将其所有子进程终止；
- 将该进程所拥有的全部资源都归还给父进程或操作系统；
- 将其从 PCB 所在队列中删除；

### (5) 孤儿进程

​		**父进程运行结束，但子进程还在运行**（未运行结束），这样的子进程就称为孤儿进程。

​		Linux 操作系统对于终止有子进程的父进程，会把子进程交给 1 号进程接管，处理它的一切善后工作。因此孤儿进程并不会有什么危害。

### (6) 僵尸进程

​		子进程终止时，父进程尚未回收，子进程残留资源（PCB）存放于内核中，变成僵尸（Zombie）进程。

​		僵尸进程不能被 kill -9 杀死，如果父进程不调用 wait() 或 waitpid() 的话，那么保留的那段信息就不会释放，其进程号就会一直被占用。

**如何解决僵尸进程**：

（1）一般，为了防止产生僵尸进程，在fork子进程之后我们都要及时使用**wait系统调用**；同时，当子进程退出的时候，内核都会给父进程一个SIGCHLD信号，所以我们可以建立一个捕获SIGCHLD信号的信号处理函数，在函数体中调用wait（或waitpid），就可以清理退出的子进程以达到防止僵尸进程的目的。

（2）**使用kill命令**。

​    打开终端并输入下面命令:

```shell
 ps aux | grep Z 
```

​    会列出进程表中所有僵尸进程的详细内容。

​    然后输入命令：

```shell
 kill -s SIGCHLD pid(父进程pid)
```

### (7) 进程回收

​		在每个进程退出的时候，内核释放该进程所有的资源、包括打开的文件、占用的内存等。但是仍然为其保留一定的信息，这些信息主要主要指进程控制块PCB的信息（包括进程号、退出状态、运行时间等）。父进程可以通过调用 wait 或 waitpid 得到它的退出状态同时彻底清除掉这个进程。

### (8) 进程的上下文切换

​		各个进程之间是共享 CPU 资源的，让不同的进程可以在 CPU 执行，那么这个**一个进程切换到另一个进程运行，称为进程的上下文切换**。

​		CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 **CPU 上下文**。

​		根据任务的不同，把 CPU 上下文切换分成：**进程上下文切换、线程上下文切换和中断上下文切换**。

**进程上下文切换**

​		进程是由内核管理和调度的，所以进程的切换只能发生在内核态。通常，会把交换的信息保存在进程的 PCB。

​		进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。

​		**发生进程上下文切换有哪些场景？**进程调度、进程系统资源不足、进程通过睡眠函数 sleep 主动挂起、有优先级更高的进程运行、硬件中断

### (9) 守护进程

​		**终端：**在 UNIX 系统中，用户通过终端登录系统后得到一个 shell 进程，成为控制终端，在控制终端输入一些特殊的控制键可以给**前台进程**发信号。

​		**进程组：**进程组是一组相关进程的集合，进程组由一个或多个共享同一进程组标识符（PGID）的进程组成。

​		**会话：**会话是一组进程组的集合，会话中的其中一个进程组会成为终端的前台进程组，其他进程组会成为后台进程组。

​		**守护进程：** Daemon 进程（精灵进程），是Linux 中的后台服务进程。生命周期很长，守护进程会在系统启动的时候被创建并一直运行直至系统被关闭。

**守护进程**：守护进程是运行在后台的一种生存期长的特殊进程。它独立于控制终端，处理一些系统级别任务。

**如何实现**：

（1）创建子进程，终止父进程。方法是调用fork() 产生一个子进程，然后使父进程退出。

（2）调用setsid() 创建一个新会话。

（3）将当前目录更改为根目录。使用fork() 创建的子进程也继承了父进程的当前工作目录。

（4）重设文件权限掩码。文件权限掩码是指屏蔽掉文件权限中的对应位。

（5）关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。

- 执行一个 fork()，之后父进程退出，子进程继续执行。 //确保子进程不是首进程


- 子进程调用 setsid() 开启一个新会话。  //脱离控制终端


- 清除进程的 umask 以确保当守护进程创建文件和目录时拥有所需的权限。


- 修改进程的当前工作目录，通常会改为根目录（/）。


- 关闭守护进程从其父进程继承而来的所有打开着的文件描述符。


- 在关闭了文件描述符0、1、2之后，守护进程通常会打开/dev/null (会被丢弃)并使用dup2() 使所有这些描述符指向这个设备。


- 核心业务逻辑

## 4. 进程间的通信  (IPC)

### 进程间的通信  (IPC)

**进程间通信的目的：**数据传输、通知事件、资源共享、进程控制

#### 管道

- **无名管道（内存文件）：**管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程之间使用，通常是指父子进程关系。字节流
- **有名管道（FIFO文件，借助文件系统）：**有名管道也是半双工的通信方式，但是允许在没有亲缘关系的进程之间使用，管道是先进先出的通信方式。

##### 进程通信中的管道实现原理是什么

​		**操作系统在内核中开辟一块缓冲区（称为管道）用于通信。**

​		**管道**是一种两个进程间进行**单向通信**的机制。因为这种单向性，管道又称为半双工管道，所以其使用是有一定的局限性的。半双工是指数据只能由一个进程流向另一个进程（一个管道负责读，一个管道负责写）；如果是全双工通信，需要建立两个管道。管道分为无名管道和命名管道，无名管道只能用于具有亲缘关系的进程直接的通信（父子进程或者兄弟进程），可以看作一种特殊的文件，**管道本质是一种文件**；命名管道可以允许无亲缘关系进程间的通信。

**系统IPC**

#### 共享内存

- **共享内存：**共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与信号量，配合使用来实现进程间的同步和通信。

##### 共享内存和内存映射的区别

​    1.共享内存可以直接创建，内存映射需要磁盘文件（匿名映射除外）

​    2.共享内存效果更高

​    3.内存
​        所有的进程操作的是同一块共享内存。
​        内存映射，每个进程在自己的虚拟地址空间中有一个独立的内存。

​    4.数据安全
​		- 进程突然退出：共享内存还存在、内存映射区消失
​		- 运行进程的电脑死机，宕机了：数据存在在共享内存中，没有了、内存映射区的数据 ，由于磁盘文件中的数据还在，所以内存映射区的数据还存在。

​	5.生命周期
 	   - 内存映射区：进程退出，内存映射区销毁
 	   - 共享内存：进程退出，共享内存还在，标记删除（所有的关联的进程数为0），或者关机：如果一个进程退出，会自动和共享内存进行取消关联。

#### 内存映射

- **内存映射mmap：**将磁盘文件的数据映射到内存，用户通过修改内存就能修改磁盘文件。

##### 简述mmap的原理和使用场景

​		**原理**：**mmap是一种内存映射文件的方法**，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read, write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图：

<img src="https://uploadfiles.nowcoder.com/images/20220225/4107856_1645788988709/A220E13E1B6D83412E78B65059276314" alt="img" style="zoom: 67%;" />

​		**使用场景**：

​		(1) 对同一块区域频繁读写操作；

​		(2) 可用于实现用户空间和内核空间的高效交互

​		(3) 可提供进程间共享内存及相互通信

​		(4) 可实现高效的大规模数据传输。

#### 消息队列

​		消息队列是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、**管道只能承载无格式字节流**以及缓冲区大小受限等缺点。（消息块）

#### 信号

​		用于通知接收进程某个事件已经发生，比如按下ctrl + C就是信号。进程间通信机制中**唯一的异步通信机制**。

##### 常见信号有哪些，表示什么含义

| 信号代号 | 信号名称    | 说 明                                                        |
| :------- | :---------- | :----------------------------------------------------------- |
| 1        | **SIGHUP**  | 该信号让进程立即关闭.然后重新读取配置文件之后重启            |
| 2        | SIGINT      | 程序中止信号，用于中止前台进程。相当于输出 Ctrl+C 快捷键     |
| 8        | SIGFPE      | 在发生致命的算术运算错误时发出。不仅包括浮点运算错误，还包括溢出及除数为 0 等其他所有的算术运算错误 |
| 9        | **SIGKILL** | 用来立即结束程序的运行。本信号不能被阻塞、处理和忽略。般用于强制中止进程 |
| 14       | SIGALRM     | 时钟定时信号，计算的是实际的时间或时钟时间。alarm 函数使用该信号 |
| 15       | **SIGTERM** | 正常结束进程的信号，kill 命令的默认信号。如果进程已经发生了问题，那么这个信号是无法正常中止进程的，这时我们才会尝试 SIGKILL 信号，也就是信号 9 |
| 17       | **SIGCHLD** | 子进程结束时, 父进程会收到这个信号。                         |
| 18       | SIGCONT     | 该信号可以让暂停的进程恢复执行。本信号不能被阻断             |
| 19       | SIGSTOP     | 该信号可以暂停前台进程，相当于输入 Ctrl+Z 快捷键。本信号不能被阻断 |

#### 信号量

​		信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问。

#### 套接字

​		适用于**不同机器**间进程通信，在本地也可作为两个进程通信的方式。

### 线程间通信的方式有哪些

线程间的通信方式包括**临界区、互斥量、信号量、条件变量、读写锁**：

1. 临界区：每个线程中访问临界资源的那段代码称为临界区（Critical Section）（临界资源是一次仅允许一个线程使用的共享资源）。每次只准许一个线程进入临界区，进入后不允许其他线程进入。不论是硬件临界资源，还是软件临界资源，多个线程必须互斥地对它进行访问。
2. 互斥量：采用互斥对象机制，只有拥有互斥对象的线程才可以访问。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。
3. 信号量：计数器，允许多个线程同时访问同一个资源。
4. 条件变量：通过条件变量通知操作的方式来保持多线程同步。
5. 读写锁：读写锁与互斥量类似。但互斥量要么是锁住状态，要么就是不加锁状态。读写锁一次只允许一个线程写，但允许一次多个线程读，这样效率就比互斥锁要高。

## 5. 进程的调度

**调度原则：**CPU 利用率、系统吞吐量（单位时间内 CPU 完成进程的数量）、周转时间（进程运行和阻塞时间总和）、等待时间 (处于就绪队列的时间)、响应时间

**1.  先来先服务 （FCFS）**

​		非抢占式的调度算法，按照请求的顺序进行调度。

​		有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**2.  短作业优先（SJF）**

​		非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

​		长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**3. 最短剩余时间优先 （SRTN）**

​		最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。

​		如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**4.  时间片轮转**

​		将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。

​		当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

**5.  优先级调度**

​		为每个进程分配一个优先级，按优先级进行调度。

​		为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**6.  多级反馈队列**

​		一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。**各个队列优先级从高到低**，**优先级越高的时间片越短**。

​		多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。之前的进程只需要交换 7 次。每个队列优先权也不同最上面的优先权最高。只有上一个队列没有进程在排队，才能调度当前队列上的进程。

​		可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

**7. 分类**

​		**非抢占式（Nonpreemptive）：**让进程运行直到结束或阻塞的调度方式，容易实现，适合专用系统，不适合通用系统。 抢

​		**占式（Preemptive）：**允许将逻辑上可继续运行的在运行过程暂停的调度方式可防止单一进程长时间独占，CPU系统开销大

## 6. 线程的控制

### (1) 线程的上下文切换

- 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
- 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据.
- 线程调度只需要保存线程栈、寄存器数据和PC即可

#### 进程、线程的中断切换的过程是怎样的

上下文切换指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换。

1. **进程上下文切换**

   （1）保护被中断进程的处理器现场信息

   （2）修改被中断进程的进程控制块有关信息，如进程状态等

   （3）把被中断进程的进程控制块加入有关队列

   （4）选择下一个占有处理器运行的进程

   （5）根据被选中进程设置操作系统用到的地址转换和存储保护信息

   ​		    **切换页目录以使用新的地址空间**

   ​		    **切换内核栈和硬件上下文（包括分配的内存，数据段，堆栈段等）**

   （6）根据被选中进程恢复处理器现场

2. **线程上下文切换**

   （1）保护被中断线程的处理器现场信息

   （2）修改被中断线程的线程控制块有关信息，如线程状态等

   （3）把被中断线程的线程控制块加入有关队列

   （4）选择下一个占有处理器运行的线程

   （5）根据被选中线程设置操作系统用到的存储保护信息

   ​		    **切换内核栈和硬件上下文（切换堆栈，以及各寄存器）**

   （6）根据被选中线程恢复处理器现场

### (2) 线程的实现

- **用户线程**：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；
  - 用户线程是基于用户态的线程管理库来实现的(包括**线程控制块TCB**)；
  - 用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。
- **内核线程**：在内核中实现的线程，是由内核管理的线程；

## 7. 线程同步

- **线程同步：**即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作，其他线程才能对该内存地址进行操作，而其他线程则处于等待状态。

- **临界区：**对临界资源进行访问的那段代码

- **同步：**多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- **互斥：**多个进程在同一时刻只有一个进程能进入临界区。

### (1) 互斥和同步的实现

#### 互斥量 mutex

​		为避免线程更新共享变量时出现问题，可以使用互斥量（mutex ）来确保同时仅有一个线程可以访问某项共享资源。

#### 条件变量 cond

​		用于阻塞线程的   没有东西可以读的时候可以阻塞通知生产者生产后再通知消费者消费

​		互斥锁 + 条件变量：只能用于线程同步

#### 读写锁 rwlock

- 如果有其它线程读数据，则允许其它线程执行读操作，但不允许写操作。

- 如果有其它线程写数据，则其它线程都不允许读、写操作。

- 写是独占的，写的优先级高。

#### 信号量 sem

​		**概念**：信号量本质上是一个计数器，用于多进程对共享数据对象的读取，可用于进程同步，也可用于线程同步。

​		**原理**：由于信号量只能进行两种操作等待和发送信号，即P(sv)和V(sv)，具体的行为如下：

​		（1）P(sv)操作：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行（信号量的值为正，进程获得该资源的使用权，进程将信号量减1，表示它使用了一个资源单位）。

​		（2）V(sv)操作：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1（若此时信号量的值为0，则进程进入挂起状态，直到信号量的值大于0，若进程被唤醒则返回至第一步）。

​		**作用**：用于多进程对共享数据对象的读取，它主要是用来保护共享资源（信号量也属于临界资源），使得资源在一个时刻只有一个进程独享。

#### 简述互斥锁的机制，互斥锁与读写的区别

1. **互斥锁机制**：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

2. **互斥锁和读写锁**：

   （1） 读写锁区分读者和写者，而互斥锁不区分

   （2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。

### (2) 死锁

​		两个或两个以上的进程在执行过程中，因争夺共享资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。  （是指多个进程在执行过程中，因争夺资源而造成了互相等待。）

#### 死锁的几种场景

- 忘记释放锁
- 重复加锁
- 多线程多锁，抢占锁资源

#### 满足条件

死锁只有**同时满足**以下四个条件才会发生：

（1）**互斥条件**：进程对所分配到的资源不允许其他进程访问，若其他进程访问，只能等待，直到进程使用完成后释放该资源；

（2）**请求保持条件**：进程获得一定资源后，又对其他资源发出请求，但该资源被其他进程占有，此时请求阻塞，而且该进程不会释放自己已经占有的资源；

（3）**不可剥夺条件**：进程已获得的资源，只能自己释放，不可剥夺；

（4）**环路等待条件**：若干进程之间形成一种头尾相接的循环等待资源关系。

#### 避免死锁

​		要破坏其中一个条件即可，最常用的方法就是使用**资源有序分配法**来破坏环路等待条件。（进程总是以相同的顺序申请自己想要的资源）

**如何解决**：

（1）资源一次性分配，从而解决请求保持的问题

（2）可剥夺资源：当进程新的资源未得到满足时，释放已有的资源；

（3）资源有序分配：资源按序号递增，进程请求按递增请求，释放则相反。  保证上锁的顺序一致。

**处理方法**

- 鸵鸟策略：忽略
- 死锁检测与死锁恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复，利用抢占恢复，利用回滚恢复，通过杀死进程恢复。
- 死锁预防：破坏互斥条件、破坏请求和保持条件、破坏不剥夺条件、破坏循环请求等待
- 死锁避免：
  - **安全状态：**如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕
  - **单个/多个资源的银行家算法：**算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

### (3) 生产者消费者模型

- **生产者**在生成数据后，放在一个缓冲区中；
- **消费者**从缓冲区取出数据处理；
- 任何时刻，**只能有一个**生产者或消费者可以访问缓冲区；

### (4) 锁

​		**互斥锁：**（独占锁）加锁失败后，线程会**释放 CPU** ，给其他线程，会从用户态陷入到内核态，让内核帮我们切换线程，存在一定的性能开销成本

​		**自旋锁：**加锁失败后，线程会**忙等待**，直到它拿到锁；在「用户态」完成加锁和解锁操作，销小一些；一直自旋，利用 CPU 周期，直到锁可用

​		**读写锁：**读锁，允许其它线程执行读操作，不允许写操作。写锁，其它线程都不允许读、写操作。写是独占的，写的优先级高。

​		**乐观锁：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。

​		**悲观锁：** 互斥锁、自旋锁、读写锁，都是悲观锁。乐观锁是先修改同步资源，再验证有没有发生冲突。悲观锁是修改共享数据前，都要先加锁，防止竞争。

**互斥锁**用于临界区持锁时间比较长的操作，比如下面这些情况都可以考虑

​		（1）临界区有IO操作

​		（2）临界区代码复杂或者循环量大

​		（3）临界区竞争非常激烈

​		（4）单核处理器

**自旋锁就**主要用在临界区持锁时间非常短且CPU资源不紧张的情况下。

### (5)  进程同步的方式

1. **信号量semaphore**：是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步。P操作(递减操作)可以用于阻塞一个进程，V操作(增加操作)可以用于解除阻塞一个进程。
2. **管道**：一个进程通过调用管程的一个过程进入管程。在任何时候，只能有一个进程在管程中执行，调用管程的任何其他进程都被阻塞，以等待管程可用。
3. **消息队列**：消息的链接表，放在内核中。消息队列独立于发送与接收进程，进程终止时，消息队列及其内容并不会被删除；消息队列可以实现消息的随机查询，可以按照消息的类型读取。

## 8. 进程和线程的比较

### (1) 进程线程区别

- 进程是资源（包括内存、打开的文件等）分配的基本单位，线程是 CPU 调度的基本单位；
- 同一线程共享的有堆、全局变量、静态变量、指针，引用、文件等，而独自占有栈；
- 线程使用有一定难度，需要处理数据一致性问题；
- 线程能减少并发执行的时间和空间开销；（系统开销小）
  - 创建线程比创建进程通常要快，终止时间也快，同一个进程内的线程切换比进程切换快
  - 线程之间能够方便、快速地共享信息。只需将数据复制到共享（全局或堆）变量中即可。
  - 线程间是共享虚拟地址空间的，无需采用写时复制来复制内存，也无需复制页表。

第二种答案

- 调度：线程是调度的基本单位（PC，状态码，通用寄存器，线程栈及栈指针）；进程是拥有资源的基本单位（打开文件，堆，静态区，代码段等）。
- 并发性：一个进程内多个线程可以并发（最好和CPU核数相等）；多个进程可以并发。
- 拥有资源：线程不拥有系统资源，但一个进程的多个线程可以共享隶属进程的资源；进程是拥有资源的独立单位。
- 系统开销：线程创建销毁只需要处理PC值，状态码，通用寄存器值，线程栈及栈指针即可；进程创建和销毁需要重新分配及销毁task_struct结构。

### (2) 进程最多能创建的线程数

​		一个进程可以创建的线程数由可用虚拟空间和线程的栈的大小共同决定

- 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
- 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。

​		**一个线程占多大内存：**一个linux的线程大概占8M内存。linux的栈是通过缺页来分配内存的，不是所有栈地址空间都分配了内存。

### (3) 有了进程，为什么还要有线程

1. **原因**

   ​		进程在早期的多任务操作系统中是基本的**执行单元**。每次进程切换，都要先保存进程资源然后再恢复，这称为上下文切换。**但是进程频繁切换将引起额外开销，从而严重影响系统的性能。**

   ​		为了减少进程切换的开销，人们把两个任务放到一个进程中，每个任务用一个更小**粒度**的执行单元来实现并发执行，这就是**线程**。

2. **线程与进程对比**

   （1）**进程间的信息难以共享。**由于除去只读代码段外，父子进程并未共享内存，因此必须采用一些进程间通信方式，在进程间进行信息交换。

   ​			但**多个线程共享**进程的内存，如代码段、数据段、扩展段，线程间进行信息交换十分方便。

   （2）调用 fork() 来创建进程的代价相对较高，即便利用写时复制技术，仍然需要复制诸如内存页表和文件描述符表之类的多种进程属性，这意味着 fork() 调用在时间上的开销依然不菲。

   ​			**但创建线程比创建进程通常要快 10 倍甚至更多。**线程间是共享虚拟地址空间的，无需采用写时复制来复制内存，也无需复制页表。

### (4) 多线程和多进程的不同

（1）一个线程从属于一个进程；一个进程可以包含多个线程。

（2）一个线程挂掉，对应的进程挂掉，多线程也挂掉；一个进程挂掉，不会影响其他进程，多进程稳定。

（3）进程系统开销显著大于线程开销；线程需要的系统资源更少。

（4）多个进程在执行时拥有各自独立的内存单元，多个线程共享进程的内存，如代码段、数据段、扩展段；但每个线程拥有自己的栈段和寄存器组。

（5）多进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈；多线程切换时只需要切换硬件上下文和内核栈。

（6）通信方式不一样。

（7）多进程适应于多核、多机分布；多线程适用于多核

**另一种答案**

* 频繁修改：需要频繁创建和销毁的优先使用**多线程**

* 计算量：需要大量计算的优先使用**多线程**  因为需要消耗大量CPU资源且切换频繁，所以多线程好一点

* 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用多进程。因为线程之间的数据共享和同步比较简单。

* 多分布：可能要扩展到多机分布的用**多进程**，多核分布的用**多线程**。

  ​	但是实际中更常见的是进程加线程的结合方式，并不是非此即彼的。

### (5) 多线程和单线程有什么区别，多线程编程要注意什么

1. **区别**：

   （1）多线程从属于一个进程，单线程也从属于一个进程；一个线程挂掉都会导致从属的进程挂掉。

   （2）一个进程里有多个线程，可以并发执行多个任务；一个进程里只有一个线程，就只能执行一个任务。

   （3）多线程并发执行多任务，需要切换内核栈与硬件上下文，有切换的开销；单线程不需要切换，没有切换的开销。

   （4）多线程并发执行多任务，需要考虑同步的问题；单线程不需要考虑同步的问题。

2. 多线程编程需要考虑**同步**的问题。线程间的同步方式包括**互斥锁、信号量、条件变量、读写锁**。

3. 多线程加锁，主要需要注意**死锁**的问题。破坏死锁的必要条件从而避免死锁。

### (6) 进程为什么比线程慢

**参考回答**

1. 进程系统开销显著大于线程开销；线程需要的系统资源更少。
2. 进程切换开销比线程大。多进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈；多线程切换时只需要切换硬件上下文和内核栈。
3. 进程通信比线程通信开销大。进程通信需要借助管道、队列、共享内存，需要额外申请空间，通信繁琐；而线程共享进程的内存，如代码段、数据段、扩展段，通信快捷简单，同步开销更小。

## 9. 面试题

### 1 进程空间从高位到低位都有些什么

**从高地址到低地址，一个程序由命令行参数和环境变量、栈、文件映射区、堆、BSS段、数据段、代码段组成。**

1. **命令行参数和环境变量**
2. **栈区：**存储局部变量、函数参数值。栈从高地址向低地址增长。是一块连续的空间。
3. **文件映射区**，位于堆和栈之间。
4. **堆区：**动态申请内存用。堆从低地址向高地址增长。
5. **BSS 段**：存放程序中未初始化的全局变量和静态变量的一块内存区域。
6. **数据段**：存放程序中已初始化的全局变量和静态变量的一块内存区域。
7. **代码段：**存放程序执行代码的一块内存区域。只读，代码段的头部还会包含一些只读的常数变量。 

### 2 单核机器上写多线程程序，是否要考虑加锁，为什么

​		在单核机器上写多线程程序，仍然需要**线程锁**。

​		**原因**：因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，**不使用线程锁的前提下，可能会导致共享数据修改引起冲突。** 

### 3 说说sleep和wait的区别

1. **sleep**

   sleep是一个延时函数，让进程或线程进入休眠。休眠完毕后继续运行。

   在linux下面，sleep函数的参数是秒，而windows下面sleep的函数参数是毫秒。

   windows下面sleep的函数参数是毫秒。

   例如：

   ```c++
   #include <windows.h>// 首先应该先导入头文件 
   Sleep (500) ; //注意第一个字母是大写。 //就是到这里停半秒，然后继续向下执行。
   ```

   在 Linux C语言中 sleep的单位是秒

   例如：

   ```c++
   #include <unistd.h>// 首先应该先导入头文件 
   sleep(5); //停5秒 //就是到这里停5秒，然后继续向下执行。
   ```

2. **wait**

   wait是父进程回收子进程PCB资源的一个系统调用。进程一旦调用了wait函数，就立即阻塞自己本身，然后由wait函数自动分析当前进程的某个子进程是否已经退出，当找到一个已经变成僵尸的子进程，wait就会收集这个子进程的信息，并把它彻底销毁后返回；如果没有找到这样一个子进程，wait就会一直阻塞，直到有一个出现为止。函数原型如下：

   ```c++
   #include<sys/types.h>   
   #include<sys/wait.h>     
   pid_t wait(int* status);  
   ```

   子进程的结束状态值会由参数status返回，而子进程的进程识别码也会一起返回。如果不需要结束状态值，则参数status可以设成 NULL。

3. **区别**： （1）sleep是一个延时函数，让进程或线程进入休眠。休眠完毕后继续运行。

   ​			 （2）wait是父进程回收子进程PCB（Process Control Block）资源的一个系统调用。

### 4 原子操作的是如何实现的

​		处理器保证从系统内存中**读取或者写入一个字节是原子的**，意思是当一个处理器读取一个字节时，**其他处理器不能访问这个字节的内存地址**。

​		处理器使用基于对**缓存加锁**或**总线加锁**的方式来实现多处理器之间的**原子操作**。

# 4  Linux命令

## 1. Makefile

​		自动化编译 ，一旦写好，只需要一个 make 命令，整个工程完全自动编译， 极大的提高了软件开发的效率。

## 2. GDB调试

​		gdb调试的是可执行文件，在gcc编译时加入 -g ，告诉gcc在编译时加入调试信息，这样gdb才能调试这个被编译的文件 gcc -g tesst.c -o test

一般来说，GDB 主要帮助你完成下面四个方面的功能：

-  启动程序，可以按照自定义的要求随心所欲的运行程序
-  可让被调试的程序在所指定的调置的断点处停住（断点可以是条件表达式）
-  当程序被停住时，可以检查此时程序中所发生的事
-  可以改变程序，将一个 BUG 产生的影响修正从而测试其他 BUG

#### GDB常见的调试命令

```shell
quit  #退出gdb，结束调试
list  #查看程序源代码
list 5，10  #显示5到10行的代码
list test.c:5, 10  #显示源文件5到10行的代码，在调试多个文件时使用
list get_sum  #显示get_sum函数周围的代码
list test,c get_sum  #显示源文件get_sum函数周围的代码，在调试多个文件时使用
reverse-search  #字符串用来从当前行向前查找第一个匹配的字符串
run  #程序开始执行（遇到断点才停）
start  #程序开始执行（程序停在第一行）
help list/all  #查看帮助信息
break  #设置断点
break 7  #在第七行设置断点
break get_sum  #以函数名设置断点
break 行号或者函数名 if 条件  #以条件表达式设置断点 ————> 条件断点
c/continue  #继续运行，到下一个断点停
watch 条件表达式  #条件表达式发生改变时程序就会停下来
next  #继续执行下一条语句 ，会把函数当作一条语句执行
step  #继续执行下一条语句，会跟踪进入函数，一次一条的执行函数内的代码
set args 10 20  #给程序设置参数
show args  #获取设置参数
```

**多进程下如何调试：**在 fork 函数调用之前，通过指令设置 ，set follow-fork-mode child 调试子进程  或者  set follow-fork-mode parent 调试父进程（默认）

## 3. 静态库和动态库

​		**库文件有两种，静态库和动态库（共享库）**，区别是：静态库在程序的链接阶段被复制到了程序中；动态库在链接阶段没有被复制到程序中，而是程序在运行时由系统动态加载到内存中供程序调用。

​		静态库、动态库区别来自链接阶段如何处理，链接成可执行程序。分别称为静态链接方式和动态链接方式。

**静态库的优缺点：**

​		**优点：**静态库被打包到应用程序中加载速度快；发布程序无需提供静态库，移植方便

​		**缺点：**消耗系统资源，浪费内存；更新、部署、发布麻烦

**动态库的优缺点：**

​		**优点：**可以实现进程间资源共享（共享库），更新、部署、发布简单，可以控制何时加载动态库

​		**缺点：**加载速度比静态库慢，发布程序时需要提供依赖的动态库

### 软链接和硬链接的区别

1. **定义不同**

   软链接又叫符号链接，这个文件包含了另一个文件的路径名。可以是任意文件或目录，可以链接不同文件系统的文件。

   硬链接就是一个文件的一个或多个文件名。把文件名和计算机文件系统使用的节点号链接起来。因此我们可以用多个文件名与同一个文件进行链接，这些文件名可以在同一目录或不同目录。

2. **限制不同**

   硬链接只能对已存在的文件进行创建，不能交叉文件系统进行硬链接的创建；

   软链接可对不存在的文件或目录创建软链接；可交叉文件系统；

3. **创建方式不同**

   硬链接不能对目录进行创建，只可对文件创建；

   软链接可对文件或目录创建；

4. **影响不同**

   删除一个硬链接文件并不影响其他有相同 inode 号的文件。

   删除软链接并不影响被指向的文件，若被指向的原文件被删除，则相关软连接被称为死链接（若被指向路径文件被重新创建，死链接可恢复为正常的软链接）

### 静态库和动态库制作和使用

**静态库的制作：**

```shell
gcc hello.c  -c #这样就生成hello.o目标文件 
ar rcs libhello.a  hello.o #生成libhello.a静态库
```

**静态库的使用：**

```shell
gcc main.c -o app -I ./include/ -L ./lib/ -lhello
```

**动态库的制作：**

```shell
gcc -c –fpic/-fPIC a.c b.c  #gcc 得到 .o 文件，得到和位置无关的代码
gcc -shared a.o b.o -o libcalc.so #gcc 得到动态库
或
gcc -shared -fpic hello.c -o libhello.so -shared
```

**动态库的使用：**

```shell
#程序启动之后，动态库会被动态加载到内存中，通过 ldd （list dynamic dependencies）命令检 查动态库依赖关系
gcc main.c -lhello -L ./ -o app
#如何定位共享库文件：配置环境变量、链接动态库、/etc/ld.so.cache文件列表、lib 或者 /usr/lib
export  LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/nowcoder/Linux/lesson03/04_lib/library/lib
```

**区别：**

1. 静态库代码装载的速度快，执行速度略比动态库快。
2. 动态库更加节省内存，可执行文件体积比静态库小很多。
3. 静态库是在编译时加载，动态库是在运行时加载。
4. 生成的静态链接库，Windows下以.lib为后缀，Linux下以.a为后缀。生成的动态链接库，Windows下以.dll为后缀，Linux下以.so为后缀。

## 4. 常用命令

### (1) 查看进程运行状态的指令

```shell
ps #进程运行状态
ps -a # 显示当前所有进程
ps -aux | grep PID #用来查看某PID进程状态
ps -aux #查看进程
ps -ajx #查看线程
#a：显示终端上的所有进程，包括其他用户的进程
#u：显示进程的详细信息
#x：显示没有控制终端的进程
#j：列出与作业控制相关的信息
top #实时显示进程动态
```

### (2) 查看内存使用情况的指令

```shell
free
free -m #命令查看内存使用情况
```

### (3) tar解压文件的参数

五个命令中必选一个  ：   -c: 建立压缩档案      -x：解压      -t：查看内容      -r：向压缩归档文件末尾追加文件      -u：更新原压缩包中的文件

这几个参数是可选的   ：   -z：有gzip属性的      -j：有bz2属性的      -Z：有compress属性的      -v：显示所有过程      -O：将文件解开到标准输出

```shell
tar -zxvf #解压tar.gz包
```

### (4) 文件权限怎么修改

​		Linux文件的基本权限就有九个，分别是owner/group/others三种身份各有自己的read/write/execute权限

​		修改权限指令：**chmod**

​		文件的权限字符为 -rwxrwxrwx 时，这九个权限是三个三个一组。其中，我们可以使用数字来代表各个权限，各权限的分数对照如下：r - 4，w - 2，x - 1

​		每种身份各自的权限分数是需要累加，当权限为： [-rwxrwx---] ，则分数是：owner = rwx = 4+2+1 = 7，group = rwx = 4+2+1 = 7，others= --- = 0+0+0 = 0

```shell
chmod 770 test.c #即修改test.c文件的权限为770
```

### (5) 常用的Linux命令

```shell
cd  #用于切换当前目录
ls  #查看当前文件与目录
ll -h  #查看的是文件内容的实际大小  ll = ls -l
grep  #该命令常用于分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工。
cp  #复制命令
mv  #移动文件或文件夹命令
rm  #删除文件或文件夹命令
ps  #查看进程情况
kill  #向进程发送终止信号
tar  #对文件进行打包，调用gzip或bzip对文件进行压缩或解压
cat  #查看文件内容，与less、more功能相似
top  #可以查看操作系统的信息，如进程、CPU占用率、内存信息等
pwd  #命令用于显示工作目录。
```

### (6) 如何以root权限运行某个程序

```shell
sudo chown root app（文件名） #改变文件的所有者
sudo chmod u+s app（文件名） #修改权限
```

### (7) 查看网络性能

```shell
ip / ifconfig   #网络配置 属于net-tools包  网口的配置以及收发数据包的统计信息
netstat / ss #查看 socket、网络协议栈、网口以及路由表的信息
sar  #网络吞吐率和 PPS Packet Per Second（包 / 秒），表示以网络包为单位的传输速率，一般用来评估系统对于网络的转发能力
	sar -n DEV  #显示网口的统计数据；
	sar -n EDEV  #显示关于网络错误的统计数据；
	sar -n TCP  #显示 TCP 的统计数据
ethtool  #带宽
	ethtool eth0 | grep Speed   # Speed: 1000Mb/s
ping  #连通性和延时
```

## 5. Linux零拷贝的原理

### 1 直接内存访问DMA技术

​		在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/DRM%20I_O%20%E8%BF%87%E7%A8%8B.png" alt="img" style="zoom: 33%;" />

**具体过程：**

- 用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；
- 操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；
- DMA 进一步将 I/O 请求发送给磁盘；
- 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；
- **DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务**；
- 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；
- CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；

### 2 什么是零拷贝

​		**传统的文件传输—read+write** ：发生了 **4 次用户态与内核态的上下文切换**，因为发生了两次系统调用，一次是 `read()` ，一次是 `write()`，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。

​		所谓「零拷贝」描述的是计算机操作系统当中，CPU不执行将数据从一个内存区域，拷贝到另外一个内存区域的任务。通过网络传输文件时，这样通常可以节省 CPU 周期和内存带宽。

#### 零拷贝的好处

（1）节省了 CPU 周期，空出的 CPU 可以完成更多其他的任务

（2）减少了内存区域之间数据拷贝，节省内存带宽

（3）减少用户态和内核态之间数据拷贝，提升数据传输效率

（4）应用零拷贝技术，减少用户态和内核态之间的上下文切换

#### 零拷贝原理

零拷贝技术实现的方式通常有 2 种：

- mmap + write
- sendfile

在传统 IO 中，用户态空间与内核态空间之间的复制是完全不必要的，因为用户态空间仅仅起到了一种数据转存媒介的作用，除此之外没有做任何事情。

**（1）Linux 提供了 sendfile() 用来减少我们的数据拷贝和上下文切换次数。**

过程如图：

<img src="https://uploadfiles.nowcoder.com/images/20220225/4107856_1645789166048/4A87E5DF037724AD29149500F8535B8B" alt="img" style="zoom: 33%;" />

a. 发起 sendfile() 系统调用，操作系统由用户态空间切换到内核态空间（第一次上下文切换）

b. 通过 DMA 引擎将数据从磁盘拷贝到内核态空间的输入的 socket 缓冲区中（第一次拷贝）

c. 将数据从内核空间拷贝到与之关联的 socket 缓冲区（第二次拷贝）

d. 将 socket 缓冲区的数据拷贝到协议引擎中（第三次拷贝）

e. sendfile() 系统调用结束，操作系统由用户态空间切换到内核态空间（第二次上下文切换）

根据以上过程，一共有 2 次的上下文切换，3 次的 I/O 拷贝。我们看到从用户空间到内核空间并没有出现数据拷贝，**从操作系统角度来看，这个就是零拷贝**。

内核空间出现了复制的原因: 通常的硬件在通过DMA访问时期望的是连续的内存空间。

**（2）mmap 数据零拷贝原理**

​		如果需要对数据做操作，Linux 提供了mmap 零拷贝来实现。

​		`read()` 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 `mmap()` 替换 `read()` 系统调用函数。

​		`mmap()` 系统调用函数会直接把内核缓冲区里的数据「**映射**」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。

具体过程如下：

- 应用进程调用了 `mmap()` 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；
- 应用进程再调用 `write()`，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；
- 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。

我们可以得知，通过使用 `mmap()` 来代替 `read()`， 可以减少一次数据拷贝的过程。

# 5 项目

## 1. 阻塞/非阻塞、同步/异步(网络IO)

典型的一次IO的两个阶段是什么？数据就绪 和 数据读写

​		数据就绪：根据系统IO操作的就绪状态：阻塞、非阻塞

​			网络IO阶段1     操作系统：

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152404863.png" alt="image-20220313152404863" style="zoom: 50%;" />

​		数据读写：根据应用程序和内核的交互方式

​			同步     需要用户去缓存区搬运到用户区         效率低 但程序简单

​			异步    缓存区搬到用户区搬完了发个信号     效率高 程序麻烦

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313153841201.png" alt="image-20220313153841201" style="zoom:67%;" />

​		陈硕：在处理 IO 的时候，阻塞和非阻塞都是同步 IO，只有使用了特殊的 API 才是异步 IO。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313151803531.png" alt="image-20220313151803531" style="zoom:67%;" />

### 简述同步与异步的区别，阻塞与非阻塞的区别

1. **同步与异步的区别**：

   **同步**：是所有的操作都做完，才返回给用户结果。即**写完数据库**之后，**再响应用户**，用户体验不好。

   **异步**：不用等所有操作都做完，就响应用户请求。即**先响应用户请求**，然后**慢慢去写数据库**，用户体验较好。

2. **阻塞与非阻塞的区别**：

   **阻塞**：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。

   **非阻塞**：非阻塞等待，每隔一段时间就去检查IO事件是否就绪。没有就绪就可以做其他事情。

## 2.Unix/Linux上的五种IO模型

### a.阻塞 blocking

​		调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作。

​		同步的IO

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152159430.png" alt="image-20220313152159430" style="zoom:80%;" />




### b.非阻塞 non-blocking（NIO）

​		非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。非阻塞I/O执行系统调用总是立即返回，不管事件是否已经发生，若事件没有发生，则返回-1，此时可以根据 errno 区分这两种情况，对于accept，recv 和 send，事件未发生时，errno 通常被设置成 EAGAIN。

​		同步的IO、线程不会挂起，while循环 消耗资源多 如果进程非常多的话性能下降

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152551625.png" alt="image-20220313152551625" style="zoom: 80%;" />

### c.IO复用（IO multiplexing）

​		Linux 用 select/poll/epoll 函数实现 IO 复用模型，这些函数也会使进程阻塞，但是和阻塞IO所不同的是这些函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检测。直到有数据可读或可写时，才真正调用IO操作函数。

​		并不是处理高并发 而是一次性读取多个数据

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152605380.png" alt="image-20220313152605380" style="zoom:80%;" />


### d.信号驱动（signal-driven）

​		Linux 用套接口进行信号驱动 IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO事件就绪，进程收到SIGIO 信号，然后处理 IO 事件。

​		在多线程中不好处理，比较麻烦 所以一般不使用

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152615232.png" alt="image-20220313152615232" style="zoom:80%;" />

​		内核在第一个阶段是异步，在第二个阶段是同步；与非阻塞IO的区别在于它提供了消息通知机制，不需要用户进程不断的轮询检查，减少了系统API的调用次数，提高了效率。

### e.异步（asynchronous）

​		Linux中，可以调用 aio_read 函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。（一般不用 出错了很难排查 而且编程比较复杂）

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152623071.png" alt="image-20220313152623071" style="zoom:80%;" />

### BIO、NIO有什么区别

​		**BIO：阻塞IO。**调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才进行下一步动作。

​		**NIO**：**同时支持阻塞与非阻塞模式**，NIO的做法是叫一个线程不断的轮询每个IO的状态，看看是否有IO的状态发生了改变，从而进行下一步的操作。

### IO模型的类型

（1）阻塞IO：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。

（2）非阻塞IO：非阻塞等待，每隔一段时间就去检查IO事件是否就绪。没有就绪就可以做其他事情。

（3）信号驱动IO：Linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO事件就绪，进程收到SIGIO信号，然后处理IO事件。

（4）IO多路复用：Linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检查。知道有数据可读或可写时，才真正调用IO操作函数。

（5）异步IO：Linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。用户可以直接去使用数据。

前四种模型--阻塞IO、非阻塞IO、多路复用IO和信号驱动IO都属于**同步模式**，因为其中真正的IO操作(函数)都将会阻塞进程，只有**异步IO模型**真正实现了IO操作的异步性。

### 请介绍一下5种IO模型

**参考回答**

1. 阻塞IO：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。
2. 非阻塞IO：非阻塞等待，每隔一段时间就去检查IO事件是否就绪。没有就绪就可以做其他事情。
3. 信号驱动IO：Linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO事件就绪，进程收到SIGIO信号，然后处理IO事件。
4. IO多路复用：Linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检查。知道有数据可读或可写时，才真正调用IO操作函数。
5. 异步IO：Linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。用户可以直接去使用数据。

前四种模型--阻塞IO、非阻塞IO、多路复用IO和信号驱动IO都属于**同步模式**，因为其中真正的IO操作(函数)都将会阻塞进程，只有**异步IO模型**真正实现了IO操作的异步性。

**异步和同步的区别就在于**，异步是内核将数据拷贝到用户区，不需要用户再自己接收数据，直接使用就可以了，而同步是内核通知用户数据到了，然后用户自己调用相应函数去接收数据。

## 3.Web Server（网页服务器）

​		一个 Web Server 就是一个服务器软件（程序），或者是运行这个服务器软件的硬件（计算机）。其主要功能是通过 **HTTP 协议与客户端（通常是浏览器（Browser））进行通信**，来接收，存储，处理来自客户端的 HTTP 请求，并对其请求做出 HTTP 响应，返回给客户端其请求的内容（文件、网页等）或返回一个 Error 信息。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152856392.png" alt="image-20220313152856392" style="zoom:50%;" />

​		通常用户使用 Web 浏览器与相应服务器进行通信。在浏览器中键入“域名”或“IP地址:端口号”，浏览器则先将你的域名解析成相应的 IP 地址或者直接根据你的IP地址向对应的 Web 服务器发送一个 HTTP 请求。这一过程首先要通过 TCP 协议的三次握手建立与目标 Web 服务器的连接，然后 HTTP 协议生成针对目标 Web 服务器的 HTTP 请求报文，通过 TCP、IP 等协议发送到目标 Web 服务器上。

## 4.HTTP协议(应用层的协议)

### 简介

​		**超文本传输协议**（Hypertext Transfer Protocol，HTTP）是一个简单的**请求 - 响应协议**，它通常运行在**TCP** 之上。它指定了**客户端可能发送给服务器什么样的消息以及得到什么样的响应**。请求和响应消息的头以 **ASCII** 形式给出；而消息内容则具有一个类似 MIME 的格式。**HTTP是万维网的数据通信的基础。**

​		HTTP的发展是由蒂姆·伯纳斯-李于1989年在欧洲核子研究组织（CERN）所发起。HTTP的标准制定由万维网协会（World Wide Web Consortium，W3C）和互联网工程任务组（Internet Engineering TaskForce，IETF）进行协调，最终发布了一系列的RFC，其中最著名的是1999年6月公布的 RFC 2616，定义了HTTP协议中现今广泛使用的一个版本——HTTP 1.1。

### 概述

​		HTTP 是一个客户端终端（用户）和服务器端（网站）请求和应答的标准（TCP）。通过使用网页浏览器、网络爬虫或者其它的工具，客户端发起一个HTTP请求到服务器上指定端口（默认端口为80）。我们称这个客户端为用户代理程序（user agent）。应答的服务器上存储着一些资源，比如 HTML 文件和图像。我们称这个应答服务器为源服务器（origin server）。在用户代理和源服务器中间可能存在多个“中间层”，比如代理服务器、网关或者隧道（tunnel）。

​		尽管 TCP/IP 协议是互联网上最流行的应用，HTTP 协议中，并没有规定必须使用它或它支持的层。事实上，HTTP可以在任何互联网协议上，或其他网络上实现。HTTP 假定其下层协议提供可靠的传输。因此，任何能够提供这种保证的协议都可以被其使用。因此也就是其在 TCP/IP 协议族使用 TCP 作为其传输层。

​		通常，由HTTP客户端发起一个请求，创建一个到服务器指定端口（默认是80端口）的 TCP 连接。HTTP服务器则在那个端口监听客户端的请求。一旦收到请求，服务器会向客户端返回一个状态，比如"HTTP/1.1 200 OK"，以及返回的内容，如请求的文件、错误消息、或者其它信息。

### 工作原理

HTTP 协议定义 Web 客户端如何从 Web 服务器请求 Web 页面，以及服务器如何把 Web 页面传送给客户端。HTTP 协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。以下是 HTTP 请求/响应的步骤：

1. **客户端连接到 Web 服务器一个HTTP客户端**，通常是浏览器，与 Web 服务器的 HTTP 端口（默认为 80 ）建立一个 TCP 套接字连接。例如，http://www.baidu.com。（URL） 

2. **发送 HTTP 请求**

   通过 TCP 套接字，客户端向 Web 服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据 4 部分组成。

3. **服务器接受请求并返回 HTTP 响应**

   Web 服务器解析请求，定位请求资源。服务器将资源复本写到 TCP 套接字，由客户端读取。一个响应由状态行、响应头部、空行和响应数据 4 部分组成。

4. **释放连接 TCP 连接**

   若 connection 模式为 close，则服务器主动关闭 TCP连接，客户端被动关闭连接，释放 TCP 连接；若connection 模式为 keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求; 

5. **客户端浏览器解析 HTML 内容**

   客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的 HTML 文档和文档的字符集。客户端浏览器读取响应数据 HTML，根据HTML 的语法对其进行格式化，并在浏览器窗口中显示。

   ![image-20220313153317648](C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313153317648.png)

例如：在浏览器地址栏键入URL，按下回车之后会经历以下流程：

1. 浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址; 

2. 解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立 TCP 连接; 

3. 浏览器发出读取文件（ URL 中域名后面部分对应的文件）的 HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器; 

4. 服务器对浏览器请求作出响应，并把对应的 HTML 文本发送给浏览器; 

5. 释放 TCP 连接; 

6. 浏览器将该 HTML 文本并显示内容。

   ​		HTTP 协议是基于 TCP/IP 协议之上的应用层协议，基于 请求-响应 的模式。HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。

### HTTP请求方法

HTTP/1.1 协议中共定义了八种方法（也叫“动作”）来以不同方式操作指定的资源：

1. **GET**：向指定的资源发出“显示”请求。使用 GET 方法应该只用在读取数据，而不应当被用于产生“副作用”的操作中，例如在 Web Application 中。其中一个原因是 GET 可能会被网络蜘蛛等随意访问。

2. HEAD：与 GET 方法一样，都是向服务器发出指定资源的请求。只不过服务器将不传回资源的本文部分。它的好处在于，使用这个方法可以在不必传输全部内容的情况下，就可以获取其中“关于该资源的信息”（元信息或称元数据）。

3. **POST**：向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求本文中。这个请求可能会创建新的资源或修改现有资源，或二者皆有。

4. PUT：向指定资源位置上传其最新内容。

5. DELETE：请求服务器删除 Request-URI 所标识的资源。

6. TRACE：回显服务器收到的请求，主要用于测试或诊断。

7. OPTIONS：这个方法可使服务器传回该资源所支持的所有 HTTP 请求方法。用'*'来代替资源名称，向 Web 服务器发送 OPTIONS 请求，可以测试服务器功能是否正常运作。

8. CONNECT：HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接（经由非加密的 HTTP 代理服务器）。

### HTTP状态码

​		有HTTP响应的第一行都是状态行，依次是当前HTTP版本号，3位数字组成的状态代码，以及描述状态的短语，彼此由空格分隔。

​		状态代码的第一个数字代表当前响应的类型：

​				1xx消息——请求已被服务器接收，继续处理

​				2xx成功——请求已成功被服务器接收、理解、并接受

​				3xx重定向——需要后续操作才能完成这一请求

​				4xx请求错误——请求含有词法错误或者无法被执行

​				5xx服务器错误——服务器在处理某个正确请求时发生错误

​		虽然 RFC 2616 中已经推荐了描述状态的短语，例如"200 OK"，"404 Not Found"，但是WEB开发者仍然能够自行决定采用何种短语，用以显示本地化的状态描述或者自定义信息。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313153559296.png" alt="image-20220313153559296" style="zoom: 67%;" />

更多状态码：https://baike.baidu.com/item/HTTP%E7%8A%B6%E6%80%81%E7%A0%81/5053660?fr=aladdin

## 5.服务器编程基本框架

虽然服务器程序种类繁多，但其基本框架都一样，不同之处在于逻辑处理。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313153626943.png" alt="image-20220313153626943" style="zoom:67%;" />

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313153639247.png" alt="image-20220313153639247" style="zoom: 80%;" />

​		I/O 处理单元是服务器管理客户连接的模块。它通常要完成以下工作：等待并接受新的客户连接，接收客户数据，将服务器响应数据返回给客户端。但是数据的收发不一定在 I/O 处理单元中执行，也可能在逻辑单元中执行，具体在何处执行取决于事件处理模式。

​		一个逻辑单元通常是一个进程或线程。它分析并处理客户数据，然后将结果传递给 I/O 处理单元或者直接发送给客户端（具体使用哪种方式取决于事件处理模式）。服务器通常拥有多个逻辑单元，以实现对多个客户任务的并发处理。

​		网络存储单元可以是数据库、缓存和文件，但不是必须的。

​		请求队列是各单元之间的通信方式的抽象。I/O 处理单元接收到客户请求时，需要以某种方式通知一个逻辑单元来处理该请求。同样，多个逻辑单元同时访问一个存储单元时，也需要采用某种机制来协调处理竞态条件。请求队列通常被实现为池的一部分。

## 6.两种高效的事件处理模式

​		服务器程序通常需要处理三类事件：I/O 事件、信号及定时事件。有两种高效的事件处理模式：**Reactor和 Proactor**，同步 I/O 模型通常用于实现 Reactor 模式，异步 I/O 模型通常用于实现 Proactor 模式。

### Reactor模式

​		要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元），将 socket 可读可写事件放入请求队列，交给工作线程处理。除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成。

​		使用同步 I/O（以 epoll_wait 为例）实现的 Reactor 模式的工作流程是：

1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。
2. 主线程调用 epoll_wait 等待 socket 上有数据可读。
3. 当 socket 上有数据可读时， epoll_wait 通知主线程。主线程则将 socket 可读事件放入请求队列。
4. 睡眠在请求队列上的某个工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll内核事件表中注册该 socket 上的写就绪事件。
5. 当主线程调用 epoll_wait 等待 socket 可写。
6. 当 socket 可写时，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列。
7. 睡眠在请求队列上的某个工作线程被唤醒，它往 socket 上写入服务器处理客户请求的结果。

Reactor 模式的工作流程：

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313153902525.png" alt="image-20220313153902525" style="zoom: 80%;" />

### Proactor模式

Proactor 模式将所有 I/O 操作都交给主线程和内核来处理（进行读、写），工作线程仅仅负责业务逻辑。

​		使用异步 I/O 模型（以 aio_read 和 aio_write 为例）实现的 Proactor 模式的工作流程是：

1. 主线程调用 aio_read 函数向内核注册 socket 上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序（这里以信号为例）。

2. 主线程继续处理其他逻辑。

3. 当 socket 上的数据被读入用户缓冲区后，内核将向应用程序发送一个信号，以通知应用程序数据已经可用。

4. 应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求后，调用 aio_write 函数向内核注册 socket 上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序。

5. 主线程继续处理其他逻辑。

6. 当用户缓冲区的数据被写入 socket 之后，内核将向应用程序发送一个信号，以通知应用程序数据

已经发送完毕。

​	7. 应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭 socket。

**Proactor 模式的工作流程：**

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313154026324.png" alt="image-20220313154026324" style="zoom: 80%;" />

### 同步I/O模拟 Proactor 模式

使用同步 I/O 方式模拟出 Proactor 模式。原理是：主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一”完成事件“。那么从工作线程的角度来看，它们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

​		使用同步 I/O 模型（以 epoll_wait为例）模拟出的 Proactor 模式的工作流程如下：

1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。

2. 主线程调用 epoll_wait 等待 socket 上有数据可读。

3. 当 socket 上有数据可读时，epoll_wait 通知主线程。主线程从 socket 循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列。

4. 睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往 epoll 内核事件表中注册 socket 上的写就绪事件。

5. 主线程调用 epoll_wait 等待 socket 可写。

6. 当 socket 可写时，epoll_wait 通知主线程。主线程往 socket 上写入服务器处理客户请求的结果。

   **同步 I/O 模拟 Proactor 模式的工作流程：**

   <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313154125049.png" alt="image-20220313154125049" style="zoom:80%;" />

### 说说Reactor模式和Proactorm模式

在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中**Reactor模式用于同步I/O**，而**Proactor运用于异步I/O**操作。

1. **Reactor模式**：Reactor模式应用于同步I/O的场景。Reactor中读操作的具体步骤如下：

   读取操作：

   （1）应用程序注册读就需事件和相关联的事件处理器

   （2）事件分离器等待事件的发生

   （3）当发生读就需事件的时候，事件分离器调用第一步注册的事件处理器

   （4）事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理

2. **Proactor模式**：Proactor模式应用于异步I/O的场景。Proactor中读操作的具体步骤如下：

   （1）应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注读取就绪事件，而是关注读取完成事件，这是区别于Reactor的关键。

   （2）事件分离器等待读取操作完成事件

   （3）在事件分离器等待读取操作完成的时候，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中。这也是区别于Reactor的一点，Proactor中，应用程序需要传递缓存区。

   （4）事件分离器捕获到读取完成事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。

3. **区别**：从上面可以看出，Reactor中需要**应用程序自己读取或者写入数据**，而Proactor模式中，应用程序不需要用户再自己接收数据，直接使用就可以了，操作系统会将数据从**内核拷贝到用户区**。

## 7. 线程池

​		线程池是由服务器预先创建的一组子线程，**线程池中的线程数量应该和 CPU 数量差不多**。线程池中的所有子线程都运行着相同的代码。当有新的任务到来，主线程将通过某种方式选择线程池中的某一个子线程来为之服务。相比与动态的创建子线程，选择一个已经存在的子线程的代价显然要小得多。至于主线程选择哪个子线程来为新任务服务，则有多种方式：

​		**主线程使用某种算法来主动选择子线程。**最简单、最常用的算法是**随机算法**和 **Round Robin（轮流选取）**算法，但更优秀、更智能的算法将使任务在各个工作线程中更均匀地分配，从而减轻服务器的整体压力。

​		**主线程和所有子线程通过一个共享的工作队列来同步，子线程都睡眠在该工作队列上。**当有新的任务到来时，主线程将任务添加到工作队列中。这将唤醒正在等待任务的子线程，不过只有一个子线程将获得新任务的”接管权“，它可以从工作队列中取出任务并执行之，而其他子线程将继续睡眠在工作队列上。

**线程池的一般模型为：**

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313154321758.png" alt="image-20220313154321758" style="zoom:80%;" />

​		线程池中的线程数量最直接的限制因素是中央处理器(CPU)的处理器(processors/cores)的数量N ：如果你的CPU是4-cores的，对于CPU密集型的任务(如视频剪辑等消耗CPU计算资源的任务)来说，那线程池中的线程数量最好也设置为4（或者+1防止其他因素造成的线程阻塞）；对于IO密集型的任务(Web Server)，一般要多于CPU的核数，因为线程间竞争的不是CPU的计算资源而是IO，IO的处理一般较慢，多于cores数的线程将为CPU争取更多的任务，不至在线程处理IO的过程造成CPU空闲导致资源浪费。

​		空间换时间，浪费服务器的硬件资源，换取运行效率。

​		池是一组资源的集合，这组资源在服务器启动之初就被完全创建好并初始化，这称为**静态资源**。

​		当服务器进入正式运行阶段，开始处理客户请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配。

​		当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用释放资源。

1. **设计思路**：

   实现线程池有以下几个步骤： 

   （1）设置一个生产者消费者队列，作为临界资源。

   （2）初始化n个线程，并让其运行起来，加锁去队列里取任务运行

   （3）当任务队列为空时，所有线程阻塞。

   （4）当生产者队列来了一个任务后，先对队列加锁，把任务挂到队列上，然后使用条件变量去通知阻塞中的一个线程来处理。

2. **线程池中线程数量**：

   线程数量和哪些因素有关：CPU，IO、并行、并发

   如果是CPU密集型应用，则线程池大小设置为：CPU数目+1 如果是IO密集型应用，则线程池大小设置为：

   ```c++
   2 * CPU数目 + 1 最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目
   ```

   所以线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。

1. **为什么要创建线程池**：

   创建线程和销毁线程的花销是比较大的，这些时间有可能比处理业务的时间还要长。这样频繁的创建线程和销毁线程，再加上业务工作线程，消耗系统资源的时间，可能导致系统资源不足。**同时线程池也是为了提升系统效率。**

2. **线程池的核心线程与普通线程：**

   任务队列可以存放100个任务，此时为空，线程池里有10个核心线程，若突然来了10个任务，那么刚好10个核心线程直接处理；若又来了90个任务，此时核心线程来不及处理，那么有80个任务先入队列，再创建核心线程处理任务；若又来了120个任务，此时任务队列已满，不得已，就得创建20个普通线程来处理多余的任务。 **以上是线程池的工作流程。**



## 8. 面试题

### 1 服务器高并发的解决方案你知道多少？

- 应用数据与静态资源分离
  将静态资源（图片，视频，js，css等）单独保存到专门的静态资源服务器中，在客户端访问的时候从静态资源服务器中返回静态资源，从主服务器中返回应用数据。

- 客户端缓存
  因为效率最高，消耗资源最小的就是纯静态的html页面，所以可以把网站上的页面尽可能用静态的来实现，在页面过期或者有数据更新之后再将页面重新缓存。或者先生成静态页面，然后用ajax异步请求获取动态数据。

- 集群和分布式
  （集群是所有的服务器都有相同的功能，请求哪台都可以，主要起分流作用）<br>
  （分布式是将不同的业务放到不同的服务器中，处理一个请求可能需要使用到多台服务器，起到加快请求处理的速度。）<br>
  可以使用服务器集群和分布式架构，使得原本属于一个服务器的计算压力分散到多个服务器上。同时加快请求处理的速度。

- 反向代理
  在访问服务器的时候，服务器通过别的服务器获取资源或结果返回给客户端。

