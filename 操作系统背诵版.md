# 1 硬件结构

## 1. 硬件结构 (冯诺依曼模型)

#### (1) 冯诺依曼模型

​		存储器（内存、外存）、运算器、控制器（CPU）、输入设备、输出设备（键盘、显示屏等）

#### (2) 硬件结构

​		**CPU（中央处理器）：**运算器、控制器、寄存器（存储计算时的和数据—通用寄存器、程序计数器、指令寄存器）（内存管理器MMU）（32位CPU管理4G内存）（32位和64位主要区别于一次可以计算多少字节数据）

​				（CPU缓存 L1 cache L2 L3静态随机存储器）

​		**总线：**地址总线（32位CPU32条）、指令总线、数据总线

​		**内存：**数据和程序存储在内存（虚拟内存）（内核区、用户区（固定区（eg栈）、覆盖区（动态内存分配、内存交换）））

​		**硬盘：**固态硬盘SSD、机械硬盘HDD（交换空间、文件空间）

​		**输入输出设备：**键盘、显示屏等，按键通过控制总线与CPU交互

#### (3) 内核

##### ① 内核空间和用户空间

​		内核空间：只有内核程序可以访问，权限很高，可以访问所有内存空间。

​		用户空间：应用程序访问局部的内存空间，权限小。

##### ② 内核态和用户态

​		内核态和用户态是操作系统的**两种运行级别**，内核态拥有最高权限，可以访问所有的系统指令；用户态只能访问一部分指令。

##### ③ 进入内核态的方式

​		主动：系统调用          被动：异常、中断

###### 系统调用的过程

​		当应用程序进行系统调用时，会产生一个中断，CPU会中断当前的程序，转而跳转到内核程序中的中断处理程序，内核处理完之后，主动触发中断，然后把CPU的执行权限交回给应用程序，回到用户态继续工作。

###### 中断

​		外中断：由硬件触发中断（CPU执行指令以外的时间引起）（eg I/O中断，时钟中断）硬中断快速处理

​		软中断：由内核触发中断，异步处理硬中断未完成的工作，处理内核自定义事件，比如内核调度等

###### 异常

​		由CPU执行指令的内部事件引起，比如：非法操作，地址越界，算术溢出

## 2. 内存管理(虚拟内存)

### (1) 虚拟内存

![image-20220318124739676](file://C:/Users/zyy/AppData/Roaming/Typora/typora-user-images/image-20220318124739676.png?lastModify=1648534359)

​		**用户区：**代码区、未初始化数据区(BSS)、已初始化数据区（全局变量/静态常量）、栈区（局部变量和函数调用的上下文）、堆区(动态分配的内存)

#### ① 一个程序有哪些section

如上图，**从低地址到高地址，一个程序由代码段、数据段、BSS段、堆、共享区、栈等**组成。

1. **数据段：**存放程序中已初始化的全局变量和静态变量的一块内存区域。还会包含一些只读的常数变量。

2. **代码段：**存放程序执行代码的一块内存区域。

3. **BSS** 段：存放程序中未初始化的全局变量和静态变量的一块内存区域。

4. 可执行程序在运行时又会多出两个区域：堆区和栈区。

   **栈区：**存储局部变量、函数参数值、返回值。栈从高地址向低地址增长。是一块连续的空间。 栈的大小是固定的一般是 `8 MB`。系统也提供了参数可改变大小

   **堆区：**动态申请内存用。堆从低地址向高地址增长。

5. 最后还有一个**共享区**，位于堆和栈之间。  文件映射段，包括动态库、共享内存等，从低地址开始向上增长

   ​	堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 `malloc()` 或者 `mmap()` ，就可以分别在堆和文件映射段动态分配内存。

##### 初始化为0的全局变量在bss还是data

​		BSS段通常是指用来存放程序中未初始化的或者初始化为0的全局变量和静态变量的一块内存区域。特点是可读写的，在程序执行之前BSS段会自动清0。

#### ② 为什么要用虚拟内存

​		因为早期的内存分配方法存在以下问题：

（1）**进程地址空间不隔离**。会导致数据被随意修改。

（2）**内存使用效率低**。

（3）程序运行的地址不确定。操作系统**随机**为进程分配内存空间，所以**程序运行的地址是不确定的**。

#### ③ 使用虚拟内存的好处

（1）**扩大地址空间。**每个进程独占一个4G空间，虽然真实物理内存没那么多。

（2）**内存保护**：防止不同进程对物理内存的争夺和践踏，可以对特定内存地址提供写保护，防止恶意篡改。

（3）可以实现**内存共享**，方便进程通信。

（4）可以**避免内存碎片**，虽然物理内存可能不连续，但映射到虚拟内存上可以连续。

#### ④ 使用虚拟内存的缺点

（1）虚拟内存需要额外构建数据结构，**占用空间**。

（2）虚拟地址到物理地址的转换，**增加了执行时间**。

（3）**页面换入换出耗时**。

（4）一页如果只有一部分数据，**浪费内存**。

### (2) 内存管理

#### ① 操作系统如何管理内存

1. **物理内存**：物理内存有四个层次，分别是寄存器、高速缓存、主存、磁盘。

2. **虚拟内存**：操作系统为每一个进程分配一个独立的地址空间是虚拟内存。

   ​	虚拟内存与物理内存**存在映射关系**，通过**页表寻址**完成虚拟地址和物理地址的转换。

   ​	进程持有的虚拟地址会通过 CPU 芯片中的**内存管理单元（MMU）**的映射关系，来转换变成物理地址，然后再通过物理地址访问内存

#### ② 内存管理方式

​		操作系统通过**内存分段**和**内存分页**的方式管理虚拟地址与物理地址之间的关系。

​			**内存分段：**程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。存在**内存碎片**和**内存交换效率低**的问题，就出现了内存分页。

​			**内存分页：**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小，虚拟地址与物理地址之间通过**页表**来映射。

​			**段页式内存管理：**地址结构就由**段号、段内页号和页内位移**三部分组成。

#### ③ 页表

​		操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构**（映射表）**，叫页表。

​		**原因**：可以减小虚拟内存页对应物理内存页的映射表大小

#### ④ 内部碎片与外部碎片

​		**内碎片：**分配给某些进程的内存区域中有些部分没用上**（固定分区分配）**

​		**外碎片：**产生了多个不连续的小物理内存，导致新的程序无法被装载**（分段式存储管理）**

**如何消除碎片文件？**

​		**内碎片：**通过**紧凑技术**消除，就是操作系统不时地对进程进行移动和整理。但是这需要**动态重定位寄存器**地支持，且相对费时

​		**外碎片：**内存交换

#### ⑤ 分页是怎么解决分段的内存碎片、内存交换效率低的问题

​		（1）由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而采用了分页，那么**释放的内存都是以页为单位释放的**，也就不会产生无法给进程使用的小内存。

​		（2）如果内存空间不够，操作系统会把其他正在运行的进程中的**「LRU最近没被使用」**的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**。一旦需要的时候，再加载进来，称为**换入**。所以，**一次性写入磁盘的也只有少数的一个页或者几个页**，不会花太多时间，内存交换的效率就相对比较高。

​		（3）分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

### (3) 内存交换

#### ① 内存交换

​		**交换(对换)技术的设计思想**：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存(进程在内存与磁盘间动态调度)

​		换入：把准备好竞争CPU运行的程序从辅存移到内存。
​		换出：把处于等待状态（或CPU调度原则下被剥夺运行权力）的程序从内存移到辅存，把内存空间腾出来。

#### ② 什么时候会进行内存交换

​		内存交换通常在许多进程运行且内存吃紧（经常发生**缺页**）时进行，如果缺页率明显下降，就可以暂停换出。

#### ③ 交换空间


​		Linux 中的交换空间在**物理内存**被充满时被使用。如果系统需要更多的内存资源，而物理内存已经充满，内存中不活跃的页就会被移到交换空间去。交换空间位于**硬盘驱动器**上，它比进入物理内存要慢。 

##### 被换出的进程保存在哪里？

​		保存在磁盘中，也就是外存中。具有对换功能的操作系统中，通常把磁盘空间分为文件区（采用离散分配方式）和对换区（连续分配方式，I/O速度比文件区的更快）两部分。**被换出的进程数据就存放在对换区**

#### ④ 优先考虑交换的进程

​		可优先换出**阻塞进程**;可换出**优先级低的进程**;为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间…
**(注意: PCB 会常驻内存，不会被换出外存)**

#### ⑤ 内存交换和覆盖

​		交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中。

**覆盖**

​		不用将一个进程的全部信息装入内存后才能运行进程，内存分为**固定区**和**覆盖区**。将经常活跃的部分放在固定区，其余部分按照调用关系分段，首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统将其调入覆盖区，替换覆盖区中原有的段。

### (4) 内存分配

#### ① 常见内存分配方式

（1） **从静态存储区域分配**。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。

（2） **在栈上创建**。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。

（3） **从堆上分配，亦称动态内存分配。**程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

#### ② 常见内存分配内存错误

​		**（1）内存分配未成功，却使用了它**：定义指针时，先初始化为NULL；申请内存之后，应该立即检查指针值是否为NULL，防止使用指针值为NULL的内存；

​		**（2）内存分配虽然成功，但是尚未初始化就引用它：**不要忘记为数组和动态内存**赋初值**。防止将未被初始化的内存作为右值使用。

​		**（3）内存分配成功并且已经初始化，但操作越过了内存的边界：**避免数字或指针的下标**越界**，特别要当心发生“多1”或者“少1”操作

​		**（4）忘记了释放内存，造成内存泄露：**动态内存的申请与释放必须配对，防止**内存泄漏**

​		**（5）释放了内存却继续使用它：**用free或delete释放了内存之后，立即将指针**设置为NULL**，**防止“野指针”**；使用智能指针。

#### ③ 动态分配内存

##### malloc的实现原理

​		**malloc底层实现：**当开辟的空间小于 128K 时，调用 brk() 函数；当开辟的空间大于 128K 时，调用mmap()。malloc采用的是**内存池**的管理方式，以减少内存碎片。先申请大块内存作为堆区，然后将堆区分为多个内存块。当用户申请内存时，直接从堆区分配一块合适的空闲快。采用**隐式链表**将所有空闲块，每一个空闲块记录了一个未分配的、连续的内存地址。

​		**从操作系统层面上看，malloc是通过两个系统调用来实现的： brk和mmap**

* brk是将进程数据段(.data)的最高地址指针向高处移动，这一步可以扩大进程在运行时的堆大小；

* mmap是在进程的虚拟地址空间中寻找一块空闲的虚拟内存，这一步可以获得一块可以操作的堆内存。

  ​	通常，分配的内存小于128k时，使用brk调用来获得虚拟内存，大于128k时就使用mmap来获得虚拟内存。

  ​	进程先通过这两个系统调用获取或者扩大进程的虚拟内存，获得相应的虚拟地址，在访问这些虚拟地址的时候，通过**缺页中断**，让内核分配相应的物理内存，这样内存分配才算完成。

#### ④ 缺页中断

1. **缺页异常**：malloc和mmap函数在分配内存时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个**缺页异常，引发缺页中断**。

2. **缺页中断**：缺页异常后将产生一个缺页中断，此时操作系统会根据页表中的**外存地址**在外存中找到所缺的一页，将其调入**内存**。

3. **步骤：**保护CPU现场、分析中断原因、转入缺页中断处理程序、恢复CPU现场，继续执行。

4. **缺页中断与一般中断区别：** 

   ​	（1）在指令执行期间产生和处理缺页中断信号 

   ​	（2）一条指令在执行期间，可能产生多次缺页中断

   ​	（3）缺页中断返回的是执行产生中断的一条指令，而一般中断返回的是执行下一条指令。

#### ⑤ 动态分区分配算法

##### 1、首次适应算法

- **算法思想：**每次都从低地址开始查找，找到第–个能满足大小的空闲分区。
- **如何实现：**空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链( 或空闲分[表)，找到大小能满足要求的第-一个空闲分区。

##### 2、最佳适应算法

- **算法思想：**由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。
- **如何实现：**空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

##### 3、最坏适应算法

- **算法思想：**为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。又称最大适应算法(Largest Fit)
- **如何实现：**空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

##### 4、邻近适应算法

- **算法思想：**首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
- **如何实现：**空闲分区以地址递增的顺序排列(可排成-一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。

##### 5、总结

​		**首次适应不仅最简单，通常也是最好最快**，不过首次适应算法会使得内存低地址部分出现很多小的空闲分区，而每次查找都要经过这些分区，因此也增加了查找的开销。邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。

​		最佳导致大量碎片，最坏导致没有大的空间。

​		**首次适应**比最佳适应要好，他们都比最坏好。

| 算法         | 算法思想                                           | 分区排列顺序                                 | 优点                                                         | 缺点                                                         |
| ------------ | -------------------------------------------------- | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **首次适应** | 从头到尾找适合的分区                               | 空闲分区以地址递增次序排列                   | 综合看性能最好。**算法开销小**，回收分区后一.般不需要对空闲分区队列重新排序 |                                                              |
| 最佳适应     | 优先使用更小的分区，以保留更多大分区               | 空闲分区以容量递增次序排列                   | 会有更多的大分区被保留下来，更能满足大进程需求               | 会产生很多太小的、难以利用的碎片;**算法开销大**，回收分区后可能需要对空闲分区队列重新排序 |
| 最坏适应     | 优先使用更大的分区，以防止产生太小的不可用的碎片   | 空闲分区以容量递减次序排列                   | 可以减少难以利用的小碎片                                     | 大分区容易被用完，不利于大进程;**算法开销大**(原因同上)      |
| 邻近适应     | 由首次适应演变而来，每次从上次查找结束位置开始查找 | 空闲分区以地址递增次序排列(可排列成循环链表) | 不用每次都从低地址的小分区开始检索。**算法开销小**(原因同首次适应算法) | 会使高地址的大分区也被用完                                   |

### (5) 内存泄露及解决办法

##### ① 什么是内存泄露

​		申请了一块内存空间，使用完毕后没有释放掉，失去了对该段内存的控制。

​		（1）new和malloc申请资源使用后，没有用delete和free释放；

​		（2）子类继承父类时，父类析构函数不是虚函数。

​		（3）Windows句柄资源使用后没有释放。

​		只发生一次小的内存泄漏可能不被注意，但泄漏大量内存的程序将会出现各种证照：性能下降到内存逐渐用完，导致另一个程序失败；

##### ② 怎么避免内存泄露

**避免内存泄露的几种方式**

- 计数法：使用new或者malloc时，让该数+1，delete或free时，该数-1，程序执行完打印这个计数，如果不为0则表示存在内存泄露
- 一定要将基类的析构函数声明为**虚函数**
- 对象数组的释放一定要用**delete []**
- 有new就有delete，有malloc就有free，保证它们一定成对出现

**解决方法**

​		智能指针

**检测工具**

- Linux下可以使用**Valgrind工具**
- Windows下可以使用**CRT库**

### (6) 虚拟技术

​		虚拟技术把一个物理实体转换为多个逻辑实体。

​		主要有两种虚拟技术：**时（时间）分复用技术和空（空间）分复用技术**

​		多进程与多线程：**多个进程能在同一个处理器上并发执行使用了时分复用技术**，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

​		**虚拟内存使用了空分复用技术**，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

### (7) 栈和堆

#### ① 从堆和栈上建立对象哪个快

栈，从两方面来考虑：

- **分配和释放**，堆在分配和释放时都要调用函数（malloc,free)，比如分配时会到堆空间去寻找足够大小的空间（因为多次分配释放后会造成内存碎片），这些都会花费一定的时间，具体可以看看malloc和free的源代码，函数做了很多额外的工作，而栈却不需要这些。
- **访问时间**，访问堆的一个具体单元，需要两次访问内存，第一次得取得指针，第二次才是真正的数据，而栈只需访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的。
- 因为**操作系统会在底层对栈提供支持**，会分配专门的寄存器存放栈的地址，栈的入栈出栈操作也十分简单，并且有专门的指令执行，所以栈的效率比较高也比较快。而堆的操作是由C/C++函数库提供的，在分配堆内存的时候需要一定的算法寻找合适大小的内存。并且获取堆的内容需要两次访问，第一次访问指针，第二次根据指针保存的地址访问内存，因此堆比较慢。


#### ② 堆栈溢出

​		堆栈溢出就是不顾堆栈中分配的局部数据块大小，向该数据块写入了过多的数据，**导致数据越界**。常指调用堆栈溢出，本质上一种数据结构的满溢情况。

​		堆栈溢出可以理解为两个方面：**堆溢出和栈溢出。**

1. 堆溢出：比如不断的new 一个对象，一直创建新的对象，而不进行释放，最终导致内存不足。将会报错：OutOfMemory Error。
2. 栈溢出：一次函数调用中，栈中将被依次压入：参数，返回地址等，而方法如果递归比较深或进去死循环，就会导致栈溢出。将会报错：StackOverflow Error。

#### ③ 堆和栈的区别

​		**(1) 堆栈空间分配不同**。栈由操作系统自动分配释放 ，存放函数的参数值，局部变量的值等；堆一般由程序员分配释放。

​		**(2) 堆栈缓存方式不同**。栈使用的是一级缓存， 它们通常都是被调用时处于存储空间中，调用完毕立即释放；堆则是存放在二级缓存中，速度要慢些。

​		**(3) 堆栈数据结构不同**。堆类似数组结构；栈类似栈结构，先进后出。

​		**(4) 申请大小限制不同。**栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过ulimit -a查看，由ulimit -s修改。堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。栈空间默认是4M, 堆区一般是 1G - 4G

​		**(5) 申请效率不同。**由系统分配，速度快，不会有碎片。堆由程序员分配，速度慢，且会有碎片。

### (8) 内存池

​		内存池是在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块， 若内存块不够再继续申请新的内存。

​		优点是尽量避免了内存碎片，使得内存分配效率得到提升。

## 3. 调度算法

### (1) 内存页面置换算法

**缺页异常（缺页中断）**：CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。

- **最佳页面置换算法（OPT）：**置换在「未来」最长时间不访问的页面
- **先进先出置换算法（FIFO）：**选择在内存驻留时间很长的页面进行中置换
- **最近最久未使用的置换算法（LRU）：**选择最长时间没有被访问的页面进行置换
- **时钟页面置换算法（Lock）：**把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。
- **最不常用置换算法（LFU）：**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰

### (2) 磁盘调度算法

- **先来先服务算法：**先到来的请求，先被服务
- **最短寻道时间优先算法：**优先选择从当前磁头位置所需寻道时间最短的请求
- **扫描算法：**磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向
- **循环扫描算法：**只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，返回中途不处理任何请求
- **LOOK 与 C-LOOK 算法：**磁头在移动到「最远的请求」位置，然后立即反向移动，反向移动的途中会响应请求

###  (3) 简述LRU算法及实现方式

1. **最近最久未使用的置换算法LRU**：LRU算法用于缓存淘汰。思路是将缓存中最近最少使用的对象删除掉
2. **实现方式**：利用**链表和hashmap**。
   - 当需要插入新的数据项的时候，如果新数据项在链表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。
   - 在访问数据的时候，如果数据项在链表中存在，则把该节点移到链表头部，否则返回-1。这样一来在链表尾部的节点就是最近最久未访问的数据项。

## 4. 程序执行的过程

### (1) 程序启动的过程

1. **操作系统**首先**创建相应的进程**并**分配私有的进程空间**，然后操作系统的**加载器**负责把**可执行文件的数据段和代码段**映射到进程的虚拟内存空间中。
2. 加载器读入可执行程序的**导入符号表**，根据这些符号表可以查找出该可执行程序的**所有依赖的动态链接库**。
3. 加载器针对该程序的每一个动态链接库**调用LoadLibrary** ，调用对应动态链接库的初始化函数
4. **初始化应用程序的全局变量**，对于全局对象自动调用构造函数。
5. 进入应用**程序入口点函数开始执行**。

### (2) main执行前后的代码

**main函数执行之前**，主要就是初始化系统相关资源：

- 设置栈指针
- 初始化静态`static`变量和`global`全局变量，即`.data`段的内容
- 将未初始化部分的全局变量赋初值：数值型`short`，`int`，`long`等为`0`，`bool`为`FALSE`，指针为`NULL`等等，即`.bss`段的内容
- 全局对象初始化，在`main`之前调用构造函数，这是可能会执行前的一些代码
- 将main函数的参数`argc`，`argv`等传递给`main`函数，然后才真正运行`main`函数
- `__attribute__((constructor))`

**main函数执行之后**：

- 全局对象的析构函数会在main函数之后执行；
- 可以用 **`atexit`** 注册一个函数，它会在main 之后执行;
- `__attribute__((destructor))`

### (3) 主机完成一条指令的过程

​		将程序通过输入设备送至计算机，将程序首地址送入程序计数器，启动程序运行，取指令(数据)，程序计数器加一，分析指令，执行指令，打印结果，停机

### (4) CPU 执行一条程序

​		一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。

​		CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束

### (5) GCC编译



![image-20220318113544144](file://C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220318113544144.png?lastModify=1648356290)

​		**预处理：头文件的展开，注释的删除，宏的替换**（不检查语法，编译的时候检查）		

# 2  进程和线程

### 1.基本概念

##### (1) 程序

​		程序是**指令、数据以及其组织形式的描述**，这些信息描述了如何在运行时创建一个进程。

##### (2) 进程

​		进程是**程序的运行实例**，是**资源分配和拥有的基本单位**。

##### (3) 线程

​		操作系统**调度执行的最小单位**，是进程当中的一条执行流程，一个进程里包括多个线程并发执行任务。

​		同一个进程内多个线程之间共享同一份全局内存区域，但每个线程各自都有一套独立的寄存器和栈

##### (4) 轻量级进程 LWP

​		由一个内核线程支持的用户线程，一个进程可有一个或者多个LWP。

​		与普通进程的区别在于，**它只有一个最小的执行上下文和调度程序所需要的统计信息**。进程代表程序的一个实例，LWP代表程序的执行线程。

##### (5) 协程（轻量级线程）

​		协程是轻量级线程，在子程序内部执行，可在子程序内部中断，转而执行别的子程序，在适当的时候再返回来接着执行。协程是线程内部调度的基本单位。

##### (6) 进程控制块（PCB）

​		内核为每个进程分配一个PCB进程控制块，维护进程相关的信息。Linux内核的进程控制块是结构体。

##### (7) 单道、多道程序设计

​		单道程序，是指在计算机内存中只允许一个程序运行；多道程序设计，是指在计算机内存中同时放入多个互相独立的程序，使他们在管理程序的控制下相互穿插运行，为了提高CPU利用率。

##### (8) 时间片

​		操作系统分配给每个正在运行的进程微观上的一段CPU时间。首先内核会给每个进程分配相等的初始时间片，然后每个进程轮番执行相应的时间。

##### (9) 并行和并发

​		**并行：**是指同一时刻，有多个进程在多个处理器cpu上同时执行

​		**并发：**是指同一时刻，只能有一个进程执行，但是多个线程被快速的轮换执行，切换时间减少到纳秒数量级，使得宏观上具有多个任务同时执行的效果。

### 2. 比较

|          |                             进程                             |                        线程                        |                             协程                             |
| -------- | :----------------------------------------------------------: | :------------------------------------------------: | :----------------------------------------------------------: |
| 定义     |                   资源分配和拥有的基本单位                   |                 调度执行的基本单位                 |          用户态的轻量级线程，线程内部调度的基本单位          |
| 切换情况 | 进程CPU环境(栈、寄存器、页表和文件句柄等)的保存以及新调度的进程CPU环境的设置 |     保存和设置程序计数器、少量寄存器和栈的内容     |     先将寄存器上下文和栈保存，等切换回来的时候再进行恢复     |
| 切换者   |                           操作系统                           |                      操作系统                      |                             用户                             |
| 切换过程 |                    用户态->内核态->用户态                    |               用户态->内核态->用户态               |                     用户态(没有陷入内核)                     |
| 调用栈   |                            内核栈                            |                       内核栈                       |                            用户栈                            |
| 拥有资源 |             CPU资源、内存资源、文件资源和句柄等              |           程序计数器、寄存器、栈和状态字           |                  拥有自己的寄存器上下文和栈                  |
| 并发性   |        不同进程之间切换实现并发，各自占有CPU实现并行         |           一个进程内部的多个线程并发执行           | 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 |
| 系统开销 | 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 |  切换时只需保存和设置少量寄存器内容，因此开销很小  | 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 |
| 通信方面 |                  进程间通信需要借助操作系统                  | 线程间可以直接读写进程数据段(如全局变量)来进行通信 |                      共享内存、消息队列                      |

#### (1) 进程与线程的区别

- 进程是资源分配的基本单位，线程是 CPU 调度的基本单位；
- 多个进程在执行时拥有各自独立的内存单元，多个线程共享进程的内存，如代码段、数据段、扩展段；但每个线程拥有自己的栈段和寄存器组；
- 一个进程内多个线程可以并发（最好和CPU核数相等）；多个进程可以并发。
- 线程能减少并发执行的时间和空间开销；（系统开销小）
  - 创建线程比创建进程通常要快，终止时间也快，同一个进程内的线程切换比进程切换快
  - 线程之间能够方便、快速地共享信息。只需将数据复制到共享（全局或堆）变量中即可。
  - 线程间是共享虚拟地址空间的，无需采用写时复制来复制内存，也无需复制页表。

#### (2) 线程与协程的区别

​		① 线程是CPU调度执行的基本单位，协程是线程内部调度的基本单位，一个线程可以有多个协程

​		② 协程执行效率比线程高，切换开销小：协程直接操作栈基本没有内核切换的开销，并且协程不需要多线程的锁机制，所以上下文的切换非常快。

​		③ 协程占用内存少：执行协程只需要极少的栈内存。

#### (3) 进程最多能创建的线程数

​		一个进程可以创建的线程数由可用虚拟空间和线程的栈的大小共同决定

- 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
- 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。

​		**一个线程占多大内存：**一个linux的线程大概占8M内存。linux的栈是通过缺页来分配内存的，不是所有栈地址空间都分配了内存。

#### (4) 多线程和多进程的不同

​		（1）一个线程从属于一个进程；一个进程可以包含多个线程。

​		（2）一个线程挂掉，对应的进程挂掉，多线程也挂掉；一个进程挂掉，不会影响其他进程，多进程稳定。

​		（3）进程系统开销显著大于线程开销；线程需要的系统资源更少。

​		（4）多个进程在执行时拥有各自独立的内存单元，多个线程共享进程的内存，如代码段、数据段、扩展段；但每个线程拥有自己的栈段和寄存器组。

​		（5）多进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈；多线程切换时只需要切换硬件上下文和内核栈。

​		（6）通信方式不一样。

​		（7）多进程适应于多核、多机分布；多线程适用于多核

**另一种答案**

* 频繁修改：需要频繁创建和销毁的优先使用**多线程**

* 计算量：需要大量计算的优先使用**多线程**  因为需要消耗大量CPU资源且切换频繁，所以多线程好一点

* 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用多进程。因为线程之间的数据共享和同步比较简单。

* 多分布：可能要扩展到多机分布的用**多进程**，多核分布的用**多线程**。

  ​	但是实际中更常见的是进程加线程的结合方式，并不是非此即彼的。

#### (5) 多线程和单线程的区别

1. **区别**：

   （1）多线程从属于一个进程，单线程也从属于一个进程；一个线程挂掉都会导致从属的进程挂掉。

   （2）一个进程里有多个线程，可以并发执行多个任务；一个进程里只有一个线程，就只能执行一个任务。

   （3）多线程并发执行多任务，需要切换内核栈与硬件上下文，有切换的开销；单线程不需要切换，没有切换的开销。

   （4）多线程并发执行多任务，需要考虑同步的问题；单线程不需要考虑同步的问题。

2. 多线程编程需要考虑**同步**的问题。线程间的同步方式包括**互斥锁、信号量、条件变量、读写锁**。

3. 多线程加锁，主要需要注意**死锁**的问题。破坏死锁的必要条件从而避免死锁。

#### (6) 进程为什么比线程慢

1. 进程系统开销显著大于线程开销；线程需要的系统资源更少。
2. 进程切换开销比线程大。多进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈；多线程切换时只需要切换硬件上下文和内核栈。
3. 进程通信比线程通信开销大。进程通信需要借助管道、队列、共享内存，需要额外申请空间，通信繁琐；而线程共享进程的内存，如代码段、数据段、扩展段，通信快捷简单，同步开销更小。

### 3. 进程的状态

​		三态模型：就绪态、执行态、阻塞态

​		五态模型：新建态、就绪态、执行态、阻塞态、终止态

​				**就绪态：**进程具备运行条件，加入就绪队列，等待系统分配处理器以便运行

​				**运行态：**进程占有CPU正在运行

​				**阻塞态：**进程不具备运行条件，正在等待某个事件的完成

​				**新建态：**进程刚被创建时的状态，还没有加入就绪队列

​				**终止态：**进程完成任务到达正常结束点；或出现无法克服的错误而异常终止；或被操作系统及终止权的进程所终止时的状态

### 4. 进程线程的控制

#### (1) 创建进程

​		操作系统允许一个进程创建新进程，称作子进程，子进程还可以创建子进程，形成进程树结构模型。

​		Linux的fork()是通过写时拷贝实现，内核区拷贝，用户区资源的复制是在需要写入的时候才会进行，在此之前只有已读方式分享。

##### 创建进程的过程：

​		① 为新进程分配一个唯一的**进程识别号**，并申请一个空白的**PCB**，PCB是有限的若申请失败则创建失败；

​		② 为进程**分配资源**，如果资源不足就会进入等待状态以等待资源；

​		③ 初始化PCB

​		④ 如果进程的调度队列能够接纳新进程，就将进程插入到就绪队列，等待被调度运行。

#### (2) 阻塞进程

​		当进程需要等待另一件事件完成时，它可以调用阻塞语句把自己阻塞等待，只能由另一个进程唤醒。

​		通常会把阻塞状态的进程的物理内存空间换出到硬盘，描述进程没有占用实际的物理内存空间的情况，这个状态就是**挂起状态**。

##### 阻塞进程的过程：

​		① 找到将要被阻塞进程标识号对应的PCB；

​		② 如果该进程为运行状态则保护其现场，将其状态转为阻塞状态，停止运行；

​		③ 将该PCB插入阻塞队列中去。

#### (3) 唤醒进程

​		进程的阻塞和唤醒是一对功能相反的语句，如果调用阻塞语句，必有一个唤醒语句与之相对应。

##### 唤醒进程过程：

​		① 在该事件的阻塞队列中找到相应进程的PCB；

​		② 将其从阻塞队伍中移出，并设置为就绪态；

​		③ 把该PCB插入就绪队列中，等待调度程序调度。

#### (4) 终止进程

​		Linux的终止程序不会刷新I/O缓存，导致部分代码不执行

​		三种终止方式：正常结束、异常、外界干预（信号kill）

​		每个进程结束后，都会释放自己地址空间中的用户区数据，内核的PCB没有办法自己释放掉，需要父进程去释放。

##### 终止进程的过程：

​		① 查找需要终止的进程的PCB；

​		② 如果处于执行状态，立即终止该进程的执行，然后将CPU资源分配给其他进程；

​		③ 如果还有子进程，将所有子进程终止；

​		④ 将该进程所拥有的全部资源都归还给父进程或操作系统；

​		⑤ 将其从PCB所在队列中删除。

#### (5) 回收进程

​		在进程退出的时候，内核释放该进程所有的信息，但仍然保留一定的信息，主要指进程控制块的信息，父进程可以通过调用wait 或者waitpid 彻底清除掉这个进程。

#### (6) 进程的上下文切换

​		为了让不同进程可以在CPU执行，一个进程切换到另一个进程运行的行为。

​		CPU上下文：**CPU寄存器和程序计数器**，是在CPU运行任何任务前都必须依赖的环境

​		CPU上下文切换分为：进程上下文切换、线程上下文切换、中断上下文切换

##### 进程上下文切换资源和场景

​		进程是由内核管理和调度的，所以**进程的切换只能发生在内核态**，通常会把交换的信息保存在进程的PCB中

​		**资源：**不仅包含了虚拟内存、栈、全局变量等**用户空间的资源**，还包括了内核堆栈、寄存器等**内核空间的资源**。

​		**发生的场景：**进程调度、进程系统资源不足、进程通过睡眠函数sleep主动挂起、有优先级更高的就进程执行、硬件中断

##### 进程上下文中断切换的过程

​		① 保护进程的处理器现场信息

​		② 修改进程的进程控制块PCB的有关信息，如进程状态

​		③ 把进程的PCB加入有关队列

​		④ 选择下一个占有处理器运行的进程

​		⑤ 根据被选中进程设置操作系统用到的地址转换和存储保护信息

​				**切换页目录以使用新的地址空间**

​				**切换内核栈和硬件上下文**（包括分配的内存、数据段、堆栈段等）

​		⑥ 根据被选中的进程恢复处理器现场

#### (7) 线程上下文切换

​		若两个线程不属于同一进程，切换过程跟进程上下文切换一样；

​		若两个线程是属于同一进程，因为虚拟内存共享，所以只需要切换线程的私有数据、寄存器等不共享的数据

​		线程调度只需要保存线程栈、寄存器数据、程序计数器即可

##### 线程上下文切换的过程

​		① 保护线程的处理器现场信息

​		② 修改线程的线程控制块有关信息，如线程状态等

​		③ 把线程的线程控制块加入有关队列

​		④ 选择下一个运行的线程

​		 ⑤ 根据被选中线程设置操作系统用到的存储保护信息

​					**切换内核栈和硬件上下文**（切换堆栈、以及存储器）（不需要设置转换的地址）

​		⑥ 恢复处理器现场

#### (8) 线程的实现

##### 用户线程：

​		用户线程管理和调度操作系统不直接参与，是基于用户态的线程库完成线程的管理（包括线程控制块TCB，线程的创建、终止、同步、调度）

##### 内核线程：

​		在内核中实现的线程，是由内核管理的线程

### 5. 进程线程通信 

#### (1) 进程间的通信 IPC

​		**进程间通信的目的：**数据传输、通知事件、资源共享、进程控制

##### ① 管道

​		**管道**是一种两个进程间进行**单向通信**的机制。

- **无名管道（内存文件）：**管道是一种**半双工**的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程之间使用，通常是指父子进程关系。字节流
- **有名管道（FIFO文件，借助文件系统）：**有名管道也是半双工的通信方式，但是允许在没有亲缘关系的进程之间使用，管道是**先进先出**的通信方式。

###### 实现原理

​		操作系统在内核中开辟一块缓冲区（称为管道）用于通信，管道本质是一种文件。

##### ② 共享内存

​		共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。与信号量，配合使用来实现进程间的同步和通信。

##### ③ 内存映射

​		内存映射mmap：将磁盘文件的数据映射到内存，用户通过修改内存就能修改磁盘文件。每个进程在自己的虚拟地址空间中有一个独立的内存。

###### mmap的原理和使用场景

**原理：**

​		**mmap是一种内存映射文件的方法**，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。

**使用场景**：

​		(1) 对同一块区域频繁读写操作；

​		(2) 可用于实现用户空间和内核空间的高效交互

​		(3) 可提供进程间共享内存及相互通信

​		(4) 可实现高效的大规模数据传输。

###### 共享内存和内存映射的区别

​    1.共享内存可以直接创建，内存映射需要磁盘文件（匿名映射除外）

​    2.共享内存效果更高

​    3.内存
​        所有的进程操作的是同一块共享内存。
​        内存映射，每个进程在自己的虚拟地址空间中有一个独立的内存。

​    4.数据安全
​		- 进程突然退出：共享内存还存在、内存映射区消失
​		- 运行进程的电脑死机，宕机了：数据存在在共享内存中，没有了。内存映射区的数据 ，由于磁盘文件中的数据还在，所以内存映射区的数据还存在。

​	5.生命周期

​		内存映射区：进程退出，内存映射区销毁

​		共享内存：进程退出，共享内存还在，标记删除（所有的关联的进程数为0），或者关机：如果一个进程退出，会自动和共享内存进行取消关联。

##### ④ 消息队列

​		消息队列是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、**管道只能承载无格式字节流**以及缓冲区大小受限等缺点。（消息块）

##### ⑤ 信号

​		用于通知接收进程某个事件已经发生，进程间通信机制中**唯一的异步通信机制**。

##### ⑥ 信号量

​		信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问。

##### ⑦ 套接字

​		适用于**不同机器**间进程通信，在本地也可作为两个进程通信的方式。

#### (2) 线程同步

​		**线程同步：**即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作，其他线程才能对该内存地址进行操作，而其他线程则处于等待状态。

​		**临界区：**对临界资源进行访问的那段代码（临界资源是一次仅允许一个线程使用的共享资源）

​		**同步：**多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。

​		**互斥：**多个进程在同一时刻只有一个进程能进入临界区。

##### ① 互斥和同步的实现

###### 互斥量 mutex

​		采用互斥对象机制，只有拥有互斥对象的线程才可以访问，保证公共资源不会被多个线程同时访问。

​		用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

###### 条件变量 cond

​		通过条件变量通知操作的方式来保持多线程同步，用于阻塞线程的， 没有东西可以读的时候可以阻塞通知生产者生产后再通知消费者消费。

​		互斥锁 + 条件变量：只能用于线程同步

###### 读写锁 rwlock

- 如果有其它线程读数据，则允许其它线程执行读操作，但不允许写操作。
- 如果有其它线程写数据，则其它线程都不允许读、写操作。
- 写是独占的，写的优先级高。

###### 信号量 sem

​		信号量本质上是一个计数器，用于多进程对共享数据对象的读取，可用于进程同步，也可用于线程同步。

##### ③ 生产者消费者模型

- **生产者**在生成数据后，放在一个缓冲区中；
- **消费者**从缓冲区取出数据处理；
- 任何时刻，**只能有一个**生产者或消费者可以访问缓冲区；

##### ④  锁

​		**互斥锁：**（独占锁）加锁失败后，线程会**释放 CPU** ，给其他线程，会从用户态陷入到内核态，让内核帮我们切换线程，存在一定的性能开销成本

​		**自旋锁：**加锁失败后，线程会**忙等待**，直到它拿到锁；在「用户态」完成加锁和解锁操作，销小一些；一直自旋，利用 CPU 周期，直到锁可用

​		**读写锁：**读锁，允许其它线程执行读操作，不允许写操作。写锁，其它线程都不允许读、写操作。写是独占的，写的优先级高。

​		**乐观锁：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。

​		**悲观锁：** 互斥锁、自旋锁、读写锁，都是悲观锁。**乐观锁是先修改同步资源，再验证有没有发生冲突。悲观锁是修改共享数据前，都要先加锁，防止竞争。**

**互斥锁**用于临界区持锁时间比较长的操作，比如下面这些情况都可以考虑

​		（1）临界区有IO操作

​		（2）临界区代码复杂或者循环量大

​		（3）临界区竞争非常激烈

​		（4）单核处理器

**自旋锁就**主要用在临界区持锁时间非常短且CPU资源不紧张的情况下。

##### ② 死锁

​		两个或两个以上的进程在执行过程中，因争夺共享资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。  （是指多个进程在执行过程中，因争夺资源而造成了互相等待。）

###### 死锁的几种场景

- 忘记释放锁
- 重复加锁
- 多线程多锁，抢占锁资源

###### 满足条件

死锁只有**同时满足**以下四个条件才会发生：

（1）**互斥条件**：进程对所分配到的资源不允许其他进程访问，若其他进程访问，只能等待，直到进程使用完成后释放该资源；

（2）**请求保持条件**：进程获得一定资源后，又对其他资源发出请求，但该资源被其他进程占有，此时请求阻塞，而且该进程不会释放自己已经占有的资源；

（3）**不可剥夺条件**：进程已获得的资源，只能自己释放，不可剥夺；

（4）**环路等待条件**：若干进程之间形成一种头尾相接的循环等待资源关系。

###### 避免死锁

​		要破坏其中一个条件即可，最常用的方法就是使用**资源有序分配法**来破坏环路等待条件。（进程总是以相同的顺序申请自己想要的资源）

**如何解决**：

（1）资源一次性分配，从而解决请求保持的问题

（2）可剥夺资源：当进程新的资源未得到满足时，释放已有的资源；

（3）资源有序分配：资源按序号递增，进程请求按递增请求，释放则相反。  保证上锁的顺序一致。

**处理方法**

- 鸵鸟策略：忽略
- 死锁检测与死锁恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复，利用抢占恢复，利用回滚恢复，通过杀死进程恢复。
- 死锁预防：破坏互斥条件、破坏请求和保持条件、破坏不剥夺条件、破坏循环请求等待
- 死锁避免：
  - **安全状态：**如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕
  - **单个/多个资源的银行家算法：**算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

#### (3)  进程同步的方式

1. **信号量semaphore**：是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步。P操作(递减操作)可以用于阻塞一个进程，V操作(增加操作)可以用于解除阻塞一个进程。
2. **管道**：一个进程通过调用管程的一个过程进入管程。在任何时候，只能有一个进程在管程中执行，调用管程的任何其他进程都被阻塞，以等待管程可用。
3. **消息队列**：消息的链接表，放在内核中。消息队列独立于发送与接收进程，进程终止时，消息队列及其内容并不会被删除；消息队列可以实现消息的随机查询，可以按照消息的类型读取。

### 6. 进程的种类

#### (1) 孤儿进程

​		父进程运行结束后，子进程还在运行，会把子进程交给1号进程管理。

#### (2) 僵尸进程

​		子进程终止时，父进程尚未回收，子进程残留的资源PCB存放在内核中，变成僵尸进程。

​		**危害：**不能被kill -9杀死，会占用大量的进程号。

##### 如何解决：

​		① 父进程及时调用wait系统调用

​		② 使用kill -s SIGCHID 命令

#### (3) 守护进程

​		进程组是一组相关的进程的集合，会话是一组进程组的集合，会存在一个前台进程组，剩下的是后台进程组。

​		守护进程：后台服务进程，生命周期很长，它独立于控制终端，会在系统启动的时候被创建并一直运行到系统关闭。

##### 如何实现：

​		① 创建子进程，终止父进程，执行一个 fork()，之后父进程退出，子进程继续执行

​		② 子进程调用 setsid() 开启一个新会话。  //脱离控制终端

​		③ 清除进程的 umask 以确保当守护进程创建文件和目录时拥有所需的权限。

​		④ 修改进程的当前工作目录，通常会改为根目录（/）

​		⑤ 关闭守护进程从其父进程继承而来的所有打开着的文件描述符（0、1、2），守护进程通常会打开/dev/null (会被丢弃)并使用dup2() 使所有这些描述符指向这个设备。

### 7. 进程的调度

**调度原则：**CPU 利用率、系统吞吐量（单位时间内 CPU 完成进程的数量）、周转时间（进程运行和阻塞时间总和）、等待时间 (处于就绪队列的时间)、响应时间

**1.  先来先服务 （FCFS）**

​		非抢占式的调度算法，按照请求的顺序进行调度。

​		有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**2.  短作业优先（SJF）**

​		非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

​		长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**3. 最短剩余时间优先 （SRTN）**

​		最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。

​		如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**4.  时间片轮转**

​		将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。

​		当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

**5.  优先级调度**

​		为每个进程分配一个优先级，按优先级进行调度。

​		为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**6.  多级反馈队列**

​		一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。**各个队列优先级从高到低**，**优先级越高的时间片越短**。

​		多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。之前的进程只需要交换 7 次。每个队列优先权也不同最上面的优先权最高。只有上一个队列没有进程在排队，才能调度当前队列上的进程。

​		可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

**7. 分类**

​		**非抢占式（Nonpreemptive）：**让进程运行直到结束或阻塞的调度方式，容易实现，适合专用系统，不适合通用系统。 抢

​		**占式（Preemptive）：**允许将逻辑上可继续运行的在运行过程暂停的调度方式可防止单一进程长时间独占，CPU系统开销大

# 3  Linux

#### 1. 原子操作的是如何实现的

​		处理器保证从系统内存中**读取或者写入一个字节是原子的**，意思是当一个处理器读取一个字节时，**其他处理器不能访问这个字节的内存地址**。

​		处理器使用基于对**缓存加锁**或**总线加锁**的方式来实现多处理器之间的**原子操作**。

#### 2. Makefile

​		自动化编译 ，一旦写好，只需要一个 make 命令，整个工程完全自动编译， 极大的提高了软件开发的效率。

#### 3. GDB调试

-  启动程序，可以按照自定义的要求随心所欲的运行程序
-  可让被调试的程序在所指定的调置的断点处停住（断点可以是条件表达式）
-  当程序被停住时，可以检查此时程序中所发生的事
-  可以改变程序，将一个 BUG 产生的影响修正从而测试其他 BUG

**多进程下如何调试：**在 fork 函数调用之前，通过指令设置 ，set follow-fork-mode child 调试子进程  或者  set follow-fork-mode parent 调试父进程（默认）

#### 4. 静态库和动态库

​		**静态库：**在程序的链接阶段被复制到了程序中。

​				**优点：**静态库被打包到应用程序中加载速度快；发布程序无需提供静态库，移植方便

​				**缺点：**消耗系统资源，浪费内存；更新、部署、发布麻烦

​		**动态库：**程序在运行时由系统动态加载到内存中供程序调用。

​				**优点：**可以实现进程间资源共享（共享库），更新、部署、发布简单，可以控制何时加载动态库

​				**缺点：**加载速度比静态库慢，发布程序时需要提供依赖的动态库

**区别：**

1. 静态库代码装载的速度快，执行速度略比动态库快。
2. 动态库更加节省内存，可执行文件体积比静态库小很多。
3. 静态库是在编译时加载，动态库是在运行时加载。
4. 生成的静态链接库，Windows下以.lib为后缀，Linux下以.a为后缀。生成的动态链接库，Windows下以.dll为后缀，Linux下以.so为后缀。

#### 5. 软链接和硬链接的区别

1. **定义不同**

   软链接又叫符号链接，这个文件包含了另一个文件的路径名。可以是任意文件或目录，可以链接不同文件系统的文件。

   硬链接就是一个文件的一个或多个文件名。把文件名和计算机文件系统使用的节点号链接起来。因此我们可以用多个文件名与同一个文件进行链接，这些文件名可以在同一目录或不同目录。

2. **限制不同**

   硬链接只能对已存在的文件进行创建，不能交叉文件系统进行硬链接的创建；

   软链接可对不存在的文件或目录创建软链接；可交叉文件系统；

3. **创建方式不同**

   硬链接不能对目录进行创建，只可对文件创建；

   软链接可对文件或目录创建；

4. **影响不同**

   删除一个硬链接文件并不影响其他有相同 inode 号的文件。

   删除软链接并不影响被指向的文件，若被指向的原文件被删除，则相关软连接被称为死链接（若被指向路径文件被重新创建，死链接可恢复为正常的软链接）

#### 6. Linux零拷贝的原理

##### (1) 直接内存访问DMA技术

​		在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。

**具体过程：**

- 用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；
- 操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；
- DMA 进一步将 I/O 请求发送给磁盘；
- 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；
- **DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务**；
- 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；
- CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；

##### (2) 什么是零拷贝

​		描述的是计算机操作系统当中，CPU不执行将数据从一个内存区域，拷贝到另外一个内存区域的任务。

**好处：**

（1）节省了 CPU 周期，空出的 CPU 可以完成更多其他的任务

（2）减少了内存区域之间数据拷贝，节省内存带宽

（3）减少用户态和内核态之间数据拷贝，提升数据传输效率

（4）应用零拷贝技术，减少用户态和内核态之间的上下文切换

**原理：**

​		① Linux 提供了 sendfile() 用来减少我们的数据拷贝和上下文切换次数2次。

​		② mmap 数据零拷贝

​				应用进程调用了 `mmap()` 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；

​				应用进程再调用 `write()`，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；

​			最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。