### 1. 项目

#### (1) 项目介绍

​		这个项目主要实现了Linux环境下以C++开发语言来搭建轻量级的Web服务器，服务器可以支持相对数量的客户端并发访问并及时响应，如文字、图片、视频等。

​		主要功能是实现了Linux环境下以C++开发语言来搭建轻量级的Web服务器，可以通过http协议与相对数量的客户端(通常是浏览器)进行通信，来接收，储存，处理来自客户端的http请求，并对其请求做出http响应，返回给客户端其请求的内容（文件、网页等）或返回一个error信息。



**通信：**服务器后端使用 socket 套接字实现不同主机间的通信，具体socket采用TCP 流式协议进行可靠通信；

**并发模型：**利用I/O多路复用技术epoll可以同时处理多个请求，请求的解析使用预先准备好的线程池进行多线程并发执行以及reactor或者proactor的事件处理模式实现并发模型；

**请求处理：**主线程负责监听I/O，获取I/O请求后把请求对象放入请求队列，交给工作线程，等待在请求队列上的工作线程被唤醒进行处理；

**解析报文：**利用状态机解析HTTP请求报文，支持解析GET/POST请求。

#### (2) 项目流程

**主线程：**

- 主线程中，epoll监听socket套接字，处理socket上的外部I/O事件，包括客户端请求连接报文，以及连接的客户端的发送报文（写请求）。
  - TCP socket创建流程：① 创建socket(用于监听的套接字)（设置协议族ipv4和协议类型流式协议 TCP通信）② 构建socket套接字地址（绑定ip地址 和设置的端口号 ）（一般ip地址设置为 INADDER_ANY 则 表示0.0.0.0 本机所有ip） ③ 设置优雅关闭连接 ④ 设置端口复用 ⑤ 绑定 套接字地址到 socket ⑥ 监听socket
  - 创建一个epoll，将socket文件描述符注册读事件到epoll中（注册epoll事件：EOPLLIN|EOPLLRDHUP|EPOLLET/默认LT  无EPOLLONESHOT），设置socket文件描述符非阻塞
- 如果事件文件描述符是socket套接字，则是新客户端的连接请求，处理新到的客户连接
  - 构建客户端的套接字地址，socket监听套接字绑定接受客户端地址；
  - 初始化客户端数据，将客户端文件描述符注册读时间到epoll中，开启oneshut，设置非阻塞
  - 创造定时器临时变量，设置回调函数和超时时间，绑定客户端数据，将定时器添加到链表中
- 如果事件描述符是管道读端且发生读事件，则处理信号
- 如果发生事件EPOLLRDHUP、EPOLLERR、EPOLLHUP，服务器关闭连接，移除对应的定时器
  - 调用回调函数，删除非活动连接在socket上的epoll事件，关闭文件描述符，减少连接数
  - 如果有定时器，则移除对应的定时器（链表上）
- 如果发生读事件，处理读
  - 若reactor事件模式：
    - 首先调整定时器，定时器往后延迟3个单位，并对新的定时器在链表上的位置进行调整
    - 若监测到读事件，将该事件放入请求队列（线程池添加客户端http），等待分配线程
    - while循环，直到一次性读完（读多少处理多少），然后移除定时器，跳出循环
  - 若proactor事件模式：
    - 先读事件，然后再将事件放入请求队列，然后分配线程处理事件，调整定时器
    - 读完之后，移除定时器
- 如果发生写事件，处理写
  - 若reactor事件模式：
    - 首先调整定时器，定时器往后延迟3个单位，并对新的定时器在链表上的位置进行调整
    - 若监测到写事件，将该事件放入请求队列（线程池添加客户端http），等待分配线程
    - while循环，直到一次性写完，然后移除定时器，跳出循环
  - 若proactor事件模式：
    - 先写事件，然后调整定时器
    - 写完之后，移除定时器

### 2. TCP通信

​		Web服务器端会通过创建一个绑定了服务器本地IP和端口的套接字 `socket()` 监听来自客户端的请求，客户端可以通过 `connect()` 连接服务器IP和端口，发送连接请求，然后通过TCP三次握手后，监听到的这些连接会排队等待被`accept()`。

#### (1) TCP通信流程

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312201250423.png" alt="image-20220312201250423" style="zoom: 80%;" />

**服务器端：**

1. 创建一个用于监听的socket套接字（设置协议族ipv4和协议类型流式协议默认为TCP通信）
2. 构建socket套接字地址设置ip地址和端口号（ip地址设置为INADDER_ANY 表示本机所有ip）（套接字地址是客户端连接服务器时使用的服务器地址信息）
3. 绑定套接字地址到socket监听文件描述符
4. 设置端口复用
5. 设置监听，监听的socket文件描述符开始工作
6. 阻塞等待，当有客户端发起连接，接受客户端的连接，会得到一个用于通信的客户端socket文件描述符
7. 通信（收发数据）
8. 通信结束，断开连接

**客户端：**

1. 创建一个用于通信的套接字socket
2. 连接服务器，需要指定连接的服务器的ip和端口
3. 连接成功了，客户端可以直接和服务器通信
4. 通信结束，断开连接

##### ① socket是什么

​		套接字是网络中不同应用进程之间进行双向通信的端点的抽象，是应用程序通过网络协议进行通信的接口，通信时可以将传输信息写入对方socket中，通过网卡进行信息传输。

​		由于数据链路层、网络层、传输层协议是在内核中实现的，操作系统需要提供一组系统调用，使得应用程序能够访问这些协议提供的服务。socket就是实现这组系统调用的API（应用程序编程接口）

**功能：**

- 将应用程序数据从用户缓冲区复制到内核TCP/UDP内核发送缓冲区，以交付内核来**发送数据**；或者从内核复制数据到用户缓冲区，**读取数据**
- 应用程序可以通过他们修改内核中层协议的某些头部信息或数据结构，从而**控制底层通信行为**

##### ② 端口号的设置

​		2字节，一个IP地址可以有2^16个端口号，具体端口类型有周知端口（0-1023）、注册端口（1024-49151）（48128个）、动态端口/私有端口（49152-65535）

​		一台机器可以使用的端口号上限：理论上65535-1024，实际受限于Linux可以打开的文件数量，可以通过maxuserport参数设置。

##### ③ 端口复用

​		防止服务器重启时之前绑定的端口还未释放；

​		程序突然退出而系统没有释放端口。

#### (2) TCP三次握手和四次挥手

##### ① TCP三次握手

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312202007088.png" alt="image-20220312202007088" style="zoom: 80%;" />

**目的：**为了保证双方之间建立了连接，初始化socket、序列号和窗口大小

**过程：**在客户端连接的时候（调用connect()），底层会通过TCP协议进行三次握手，一开始客户端和服务器端都处于closed状态，服务器主动监听某个端口，处于listen状态

​		**第一次握手：**客户端给服务器发送一个TCP请求报文（SYN报文），报文首部SYN置1，序号设置随机初始化数据ISN，然后处于SYN_SEND状态；

​		**第二次握手：**服务器收到客户端的SYN报文，给客户端回一个ACK-SYN应答请求报文，TCP首部 ACK置1，确认号设置客户端的序号ISN+1，SYN置1，序号设置随机化数字，然后处于SYN_RCVD状态；

​		**第三次握手：**客户端收到服务器的回应报文后，给服务器再回一个应答报文，TCP首部ACK置1，确认号设置服务器序号+1，然后处于established状态，服务器收到后也处于established状态。

##### ② TCP四次挥手

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzMwLmpwZw?x-oss-process=image/format,png" alt="客户端主动关闭连接 —— TCP 四次挥手" style="zoom:50%;" />

​		调用close()就会使用TCP协议进行四次挥手，因为连接的时候双向连接，所以需要实现双向断开。

​		**第一次挥手：**客户端给服务器端发送一个FIN置1的报文，然后进入FIN_WAI_1状态（若close关闭表示不发不收，若shutdown关闭表示不发能收）

​		**第二次挥手：**服务器端收到报文后，回一个ACK置1的回应报文，然后进入CLOSED_WAIT状态，客户端收到后，进入FIN_WAIT_2半关闭状态

​		**第三次挥手：**服务器端处理完数据后，给客户端发送FIN置1的报文，然后进入LAST_ACK状态（数据处理完了，请求关闭）

​		**第四次挥手：**客户端收到服务器的FIN报文后给服务器发送ACK置1的回应报文，然后进入TIME_WAIT状态，经过2MSL事件后自动进入closed状态，服务器收到回应报文后进入closed关闭状态。

##### ③ 为什么握手3次挥手4次

- **三次握手：**
  - 三次握手才能保证双方具有接受和发送的能力；
  - 三次握手可以阻止重复历史连接的初始化（两次握手没有中间状态阻止延迟的历史连接，导致建立一个历史连接，资源浪费）
  - 三次握手可以避免资源浪费（两次握手会造成客户SYN阻塞了，重复发送多次SYN报文，服务器会建立多个冗余的无效连接，重复分配资源）
  - 三次握手才可以可靠的同步双方初始序列号（两次握手只能保证一方的初始序列号被对方确认接收）
- **四次挥手：**
  - 因为服务端通常需要等待完成数据的发送和处理。
  - 关闭连接时，仅仅表示客户端不再发送数据了但是还能接收数据，当服务器收到请求关闭报文时，先回一个收到报文，因为服务器端可能还有数据处理和发送，等服务器端不再发送数据时，才发送FIN报文同意关闭连接。

##### ④ 握手或挥手一次消息丢失

- **三次握手：**
  - **第一次握手信息丢失：**客户端收不到服务器端的请求应答SYN_ACK报文，就会触发超时重传机制，重传SYN报文，最大重传次数由内核参数控制
  - **第二次握手信息丢失：**客户端和服务器端都会重传报文，客户端会重传SYN报文，服务器端会重传SYN_ACK报文
  - **第三次握手信息丢失：**服务器端重传SYN_ACK报文，直到收到第三次握手，或达到最大重传次数
  - ACK报文不会重传，当ACK报丢失了，就由对方重传对应的报文
- **四次挥手：**
  - **第一次挥手信息丢失：**触发超时重传机制，重传FIN报文，重发次数由内核参数控制
  - **第二次挥手信息丢失：**服务器不会重传ACK报文，客户端就会触发超时重传，重传FIN报文，直到收到第二次挥手或者最大重传次数
  - **第三次挥手信息丢失：**服务器收不到ACK报文，就会重发FIN报文
  - **第四次挥手信息丢失：**服务器收不到ACK报文，就会重发FIN报文

##### ⑤ 三次握手携带数据

​		第一次、第二次不可以，是因为会让服务器更加容易受到攻击。第三次可以，因为客户端已经知道服务器可以收发数据。

##### ⑥ ISN

- **序号的作用**
  - 接收方可以**去除重复的数据**   （ISN）
  - 接收方可以根据序号**按序接收** （ISN）
  - 可以标识发送出去哪些数据被对方收到（ACK）

- **为什么随机生成ISN**
  - 防止历史报文被服务器进程重启的连接接收后，造成的数据错乱
  - 为了安全性，防止黑客伪造相同序列号的TCP报文被对方接收
- **ISN 是如何随机产生的**
  - 基于时钟，每4微妙+1（可以看作计时器）

##### ⑦ SYN攻击

- **什么是SYN攻击**
  - 攻击者在短时间内伪造大量不存在IP地址的SYN报文，并向服务器端不断发送SYN包，服务器则回复确认包，并等待确认，由于源地址不存在，因此服务器不断重发直至超时，这些伪造的SYN包将长时间占用半连接队伍，导致正常的SYN请求会因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。（Dos/DDos攻击）
  - 如果不断受到 SYN 攻击，就会导致 SYN 队列（半连接队列）被占满，从而导致无法在建立新的连接。
- **如何防御SYN攻击**
  - 缩短超时时间、增加最大半连接数（还需一同增大接收队列长度）、过滤网关防护
  - **SYN cookie技术**
    - 当半连接队列满之后，后续服务器收到的SYN包，不进入半连接队列，计算一个cookie值，再以SYN+ACK中的序列号返回客户端、
    - 服务器端收到客户端的应答报文时，服务器会检查这个ACK包的合法性，如果合法直接放入全连接队列

##### ⑧ TIME_WAIT

- **为什么需要TIME_WAIT**
  - 保证客户端发送的最后一个ACK报文能够到达服务器（用来重发可能丢失的ACK报文）
  - 防止历史连接中的数据，被后面重新连接的服务器错误接收
  - （可靠地终止TCP连接）（保证让迟来地TCP报文段有足够的时间被识别并丢弃）
- **为什么是2MSL**
  - MSL是报文最大生存时间，超过这个时间报文被丢弃（2MSL默认为60秒）
  - 若服务器没有收到第四次挥手ACK报文，就会重发FIN报文，客户端会重发ACK给服务器端，这一来一回需要等待2倍的时间，相当于至少允许ACK报文丢一次（若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。）
- **如何优化TIME_WAIT**
  - TIME_WAIT太多会导致内存资源的占用，端口资源的占用
  - 若**打开对TCP时间戳的支持**，则不需要2msl；TCP选项中8个字节，第一个字节保存发送该数据包的时间，第二个保存最近一次接收对方发送到达数据时间；由于有时间戳，重复的数据包会因为时间戳过期而被自然丢弃，则不需要2msl。
  - **使用优雅关闭**，若有数据待发则延迟关闭。也可以设置强制RST关闭，不会发送未发送完成的数据。

##### ⑨ TCP keepalive

- **原理：**
  - 定义一个时间段，在这个时间段内，如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。
  - TCP 保活机制可以在双方没有数据交互的情况，**通过探测报文，来确定对方的 TCP 连接是否存活**。

**没有数据传输的情况：**

- **若建立了连接，但是客户端突然出现故障了怎么办？**
  - TCP 有一个机制是保活机制，通过探测报文，来确定对方的 TCP 连接是否存活。
- **在没有开启 TCP keepalive，如果客户端的「主机崩溃」了，会发生什么？**
  - 客户端主机崩溃了，服务端是无法感知到的，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态，直到服务端重启进程。
- **拔掉网线后， 原本的 TCP 连接还存在吗？**
  - 双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
  - 双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。

##### ⑩ RST复位报文

- **复位报文**
  - 携带RST标志地报文段，用来通知对方关闭连接或重新建立连接
- **产生RST报文的情况**
  - **访问不存在的端口**
    - 若端口处于TIME_WAIT状态，客户端也会收到RST
  - **异常终止连接**
    - 应用程序可以使用socket选项SO_LINGER发送复位段文报，来异常终止一个连接，发送端所有排队等待发送的数据都会被丢弃
  - **处理半打开连接**
    - **半打开状态：**服务器(或客户端)关闭或异常终止了连接，对方没有收到结束报文段(网络故障、拔掉网线)，还维持原来的连接，此时处于半打开状态，而服务器(或客户端)即使重启，也已经没有该连接的任何信息。若一方处于半打开状态的连接写入数据，则对方会回应一个复位报文段。

#### (3) TCP和UDP比较

- **UDP**
  - 用户数据报协议，面向无连接，可以单播，多播，广播，面向数据报，不可靠
  - **数据报：**发送端应用程序执行一次写操作，UDP模块就将其封装为一个UDP数据报发送，接收端必须及时对每一个UDP数据报执行读操作，否则会丢包（用户没有足够的应用程序缓冲区来读取UDP数据，UDP数据将会被截断）
- **TCP**
  - 传输控制协议，面向连接的，可靠的，基于字节流，仅支持单播传输，全双工
  - 使用TCP协议通信的双方必须先建立连接，然后才能开始数据的读写，双方都必须为该连接分配必要的内核资源，以管理连接的状态和连接上数据的传输，完成数据交换后必须断开连接释放系统资源。
  - **字节流：**数据的发送和接收没有边界限制值，且发送端执行的写操作次数和接收端执行的读操作次数没有任何数量关系

**TCP和UDP区别：**

- **是否创建连接：**TCP协议是有连接的，UDP是无连接的
- **是否可靠：**TCP协议是可靠的（发送应答机制和超时重传机制保证数据无差错、不重复、不丢失、按序到达(会对TCP报文段数据段重排、整理)），UDP是不可靠的（尽最大努力交付，不保证可靠交付）
- **连接的对象个数：**TCP是一对一的连接，UDP支持一对一，多对多，一对多，多对一的通信
- **传输数据：**TCP面向字节流，没有边界，UDP面向数据报，有边界
- **首部开销：**TCP最少需要20字节，UDP首部8个字节
- **发送速率：**TCP有流量控制和拥塞控制机制，保证数据传输的安全性；UDP网络拥堵不会影响发送端的发送速率，所以TCP传输速度慢，UDP快
- **使用场景：**TCP适用可靠性高的应用（FTP文件传输、HTTP/HTTPS），UDP适用实时应用（视频会议，直播，广播通信）

#### (4) 网络结构体系

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312194916849.png" alt="image-20220312194916849" style="zoom:50%;" />

##### ① 七层模型

- **物理层：**建立物理连接，实现比特流的透明传输，利用传输介质为数据链路层提供物理连接
- **数据链路层：**建立逻辑连接，实现数据的封帧和差错检测以及MAC寻址
- **网络层：**定义IP地址，路由功能，进行逻辑地址寻址，负责数据的路由、转发、分片
- **传输层：**定义了传输协议和端口号、在端到端之间提供可靠的透明数据传输
- **会话层：**负责建立、管理和终止网络中两节点之间的通信
- **表示层：**处理用户信息的表示问题，数据的编码、压缩和解压缩、数据的加密和解密，把数据转换成兼容另一个系统能识别的格式
- **应用层：**应用软件，负责给应用程序提供同一的接口

##### ② TCP/IP协议族

​		现在因特网主流的协议族是TCP/IP协议族，**它是一个分层、多协议的通信体系**。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413092726739.png" alt="image-20220413092726739" style="zoom:67%;" />

- **应用层：直接为应用进程提供服务，可以加密、解压、格式化数据，也可以建立或解除与其他节点的通信**
  - **常见协议：**
    - **FTP** (文件传输协议)、**HTTP** (超文本传输协议)、**TELNET** (远程登录服务协议)、**NFS** (网络文件系统协议)、**OSPF**（开放最短路径优先协议、动态路由更新协议）、**DNS**（域名服务协议，实现域名到IP地址的转换）
- **传输层：定义了传输协议和端口号，负责端到端的通信**
  - 常见协议：
    - **TCP** (传输控制协议，为应用层提供可靠的，面向连接的和基于流的服务，使用超时重传、数据确认等方式保证可靠)
    - **UDP** (用户数据报协议，为应用层提供不可靠、无连接和基于数据报的服务)
- **网络层：负责数据包的封装、分片、路由、转发，可以进行网络的连接和终止以及IP地址寻址等功能**
  - **常见协议：**
    - **IP** (因特网互联协议，根据数据包的目的IP地址使用逐跳的方式确定通信路径)
      - 为上层协议提供**无状态**(不同步通信双方传输数据的状态，简单高效但无法处理乱序和重复的IP数据报)、**无连接**(不长久地维持对方的信息，每次发送必须明确)、**不可靠**(不保证准确到达)服务
    - **ICMP** 
      - 因特网控制报文协议，是IP协议的重要补充，主要用于检测网络连接；
      - 错误侦测与回报机制，让我们能够检测到网络的连线状况，是ping的工作协议；
      - 分为差错报文（回应网络错误：目标不可达、重定向）和查询报文（查询网络信息(ping)）) 、
    - **IGMP** (因特网组管理协议，用于实现组播、广播等通信)、
    - **RIP** (路由信息协议，使用跳数来衡量到达目的地址的路由距离)
- **网络接口层：兼并了物理层和数据链路层，是传输数据的物理媒介，实现了网卡接口的网络驱动程序，隐藏了不同物理网络的不同电气特性**
  - **常见协议：**
    - **ARP** (地址解析协议，根据IP地址获取物理地址)
      - **工作原理：**主机向自己所在的网络广播一个ARP请求，该请求包含目标机器的网络地址，此网络上的其他机器都收到这个请求，但只有被请求的目标机器会回应一个ARP应答，包含自己的物理地址。
      - **ARP高速缓存**：包含经常访问/最近访问的机器的IP地址到物理地址的映射，避免了重复的ARP请求，提高了发送数据包的速度
    - **RARP** (反向地址解析协议)

#### (5) TCP可靠性保证

##### ① 检验和

- 由发送端填充，接收端对 TCP 报文段执行 CRC 算法以校验TCP 报文段在传输过程中是否损坏。
- TCP在计算检验和时，会在TCP首部加上一个12字节的伪首部。检验和总共计算3部分：TCP首部、TCP数据、TCP伪首部。通过检验和，可以检测出来数据是否有差错和异常，若有错误就直接丢弃TCP段。

##### ② 序列号/确认应答

- 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。只要接收端没有回应确认包（ACK包），都会重发。或者接收端的应答包，发送端没有收到也会重发数据。这就可以保证数据的完整性。

- **累计应答**指的是：为了保证**顺序性**，每一个包都有一个**ID**（序号），在建立连接的时候，会商定起始的ID是多少，然后按照ID一个个发送。而为了保证不丢包，对应发送的包都要进行应答，但不是一个个应答，而是会**应答某个之前的ID**，该模式称为**累计应答**

##### ③ 最大消息长度 MSS

- 在建立TCP连接的时候，双方约定一个最大的长度（MSS）作为发送的单位，重传的时候也是以这个单位来进行重传。理想的情况下是该长度的数据刚好不被网络层分块。

##### ④ 重传机制

- **超时重传**
  - 在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据。（数据包丢失、确认应答丢失）
  - 超时重传时间`RTO`
    - `RTT` （往返时延）是数据从发送到接收到对方响应之间的时间间隔，也就是包的往返时间。
    - `RTO`（超时重传时间）应该**略大于报文往返 RTT 的值**
      - 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**
      - 重传次数到达上限之后停止重传。

- **快速重传**
  - 当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
- **Duplicate SACK**
  - **SACK 方法**
    - 选择性确认，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。如果要支持 `SACK`，必须双方都要支持。（TCP 头部「选项」）
  - 主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。（内核设置参数）
  - 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了；可以知道是不是「发送方」的数据包被网络延迟了；可以知道网络中是不是把「发送方」的数据包给复制了。

##### ⑤ 滑动窗口

- **实现传输控制**：接收端告诉发送端自己还有多少缓冲区可以接收数据，发送方可以通过接收方滑动窗口的大小来确定应该发送多少字节的数据（缓冲区大小）
- **滑动窗口过小怎么办**：当传输比较大的数据的时候需要不停的对数据进行确认，这个时候就会**造成很大的延迟**。

##### ⑥ 流量控制

- **流量控制：**接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，可以控制发送方发送速率，保证接收方来得及接收。

- **发送窗和接收窗**

  - TCP是双工协议，双方可以同时通信，所以发送方接收方各自维护一个发送窗和接收窗。
  - 发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会**被操作系统调整**。如果发生了**先减少缓存，再收缩窗口，就会出现丢包的现象**。

- **窗口关闭—死锁**

  - 如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是**窗口关闭**。
  - 当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个报文在网络中丢失了，这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。
  - **解决：**TCP 为每个连接设有一个持续定时器，若收到零窗口通知就启动持续计时器，如果超时就会发送**窗口探测报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。窗口探测的次数一般为 3 次，如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。

- **糊涂窗口综合症**

  - 如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。

  - **解决：**

    - **让接收方不通告小窗口给发送方**

      - 当窗口大小小于 min( MSS，缓存空间/2 ) ，就会向发送方通告窗口为 `0`，阻止了发送方再发数据过来。
      - 等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。

    - **让发送方避免发送小数据**
      
      - **Nagle 算法**
        
        - 要求一个TCP连接的通信双方在任意时刻最多只能发送一个未被确认的TCP报文段，在该TCP报文段的确认到达之前不能发送其他的TCP报文段；发送方在等待确认的同时收集本段需要发送的微量数据，并在确认到来时以一个TCP报文段将他们全部发出
        - 没有已发送未确认报文时，立刻发送数据。
        - 存在未确认报文时，直到「没有已发送未确认报文」或「数据长度/窗口达到 MSS 大小」时，再发送数据。
        - Nagle 算法默认是打开的，对于需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，需要关闭 Nagle 算法。
        
      - **延迟确认**
      
        - 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
      
        - 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送
        - 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK

##### ⑦ 拥塞控制

- **目的：**防止数据被过多注网络中导致网络资源（路由器、交换机等）过载。

- **拥塞窗口 cwnd**

  - 发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。
  - 发送窗口 = 拥塞窗口和接收窗口中的最小值
  -  **`cwnd` 变化的规则：**
    - 只要网络中没有出现拥塞，`cwnd` 就会增大；
    - 但网络中出现了拥塞，`cwnd` 就减少；

- **怎么知道出现了拥塞**

  - 发送方没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了用拥塞。

- **拥塞控制的控制算法**

  <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220410155504593.png" alt="image-20220410155504593" style="zoom:80%;" />

  - **慢启动**
    - TCP 在刚建立连接完成后，进行慢启动，一点一点的提高发送数据包的数量，试探一下网络的承受能力，以免直接扰乱了网络通道的秩序。
    - 连接建好的开始，先初始化拥塞窗口cwnd大小为1，表明可以传一个MSS大小的数据；当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1；每当过了一个往返延迟时间RTT，cwnd大小直接翻倍，乘以2，呈指数让升。
    - 有一个叫慢启动门限 `ssthresh`状态变量
      - 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
      - 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」
  - **拥塞避免**
    - 每当收到一个 ACK 时，cwnd 增加 1/cwnd；每当过了一个往返延迟时间RTT，cwnd大小加一。**将原本慢启动算法的指数增长变成了线性增长**，还是增长阶段，但是增长速度缓慢了一些。
    - 网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传，当触发了重传机制，就进入了「拥塞发生算法」
  - **拥塞发生**
    - **发生超时重传的拥塞发生算法：**`ssthresh` 设为 `cwnd/2`，`cwnd` 重置为 `1`，重新开始慢启动，慢启动是会突然减少数据流的，这种方式太激进了，反应也很强烈，会造成网络卡顿。
    - **发生快速重传的拥塞发生算法：**`cwnd = cwnd/2` ，也就是设置为原来的一半;`ssthresh = cwnd`；进入快速恢复算法。
  - **快速恢复**
    - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；重传丢失的数据包；如果再收到重复的 ACK，那么 cwnd 增加 1；如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

##### ⑧ TCP 如何保证可靠传输

- **确认和重传**：接收方收到报文就会确认，发送方没有收到确认就会重传。标志位确保通信实体的存在，序号和确认号确保了数据是按序、完整到达。
- **数据校验**：TCP报文头有校验和，用于校验报文是否损坏。
- **数据合理分片和排序**：TCP会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层。
- **流量控制**：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，避免过量发送，防止包丢失。
- **拥塞控制**：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

#### (6) TCP 粘包和拆包

- **TCP粘包：**

  - **TCP粘包**是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。（不知道用户消息的边界在哪）
  - **出现原因：**
    - 由TCP**连接复用**造成的粘包问题。
    - 因为TCP默认会使用**Nagle算法**，此算法会导致粘包问题。
      - 只有上一个分组得到确认，才会发送下一个分组；
      - 收集多个小分组，在一个确认到来时一起发送。
    - **数据包过大**造成的粘包问题。
    - 流量控制，**拥塞控制**也可能导致粘包。
    - 接收方不及时接收缓冲区的包，造成多个包接收

- **分包和拆包**：因为TCP是无边界的流传输，所以需要对TCP进行封包和拆包，确保发送和接收的数据不粘连。

  - **分包：**在发送数据报的时候为每个TCP数据包加上一个包头，将数据报分为包头和包体。包头是一个固定长度的结构体，里面包含该数据包的总长度。
    - 分包的方式：

      - **固定长度的消息；**
        - 每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
        - 这种方式灵活性不高，实际中很少用。
      - **特殊字符作为边界；**
        - 我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。
        - HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。
        - 如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。
      - **自定义消息结构。**
        - 我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。
- **拆包：**接收方在接收到报文后提取包头中的长度信息进行截取。

### 3. I/O多路复用

#### (1) 什么是I/O多路复用

​		**单个线程/进程**可监听**多个**文件描述符，一旦某个fd就绪，就可以进行相应的读写操作。通过减少运行的进程，有效的减少**上下文切换**的消耗。

​		但是select、poll、epoll本质都是同步I/O，他们都需要在读写事件就绪之后自己负责读写，即这个数据读写过程是阻塞的。

#### (2) 为什么使用IO多路复用

​		为实现**高性能服务器**。阻塞IO接口会**阻塞**直到有数据copy完成，如果是**单线程**的话会导致**主线程被阻塞**，即整个程序永远**锁死**。同一时间只能处理一个操作，效率低。可以通过**多线程**解决，即一个连接分配一个线程来处理，但是线程或进程会消耗系统资源，进程或线程调度会消耗CPU资源，本质还是阻塞I/O。

​		**IO多路复用技术可以单线程监听多个网络连接，通过减少运行的进程，有效的减少上下文切换的消耗。**虽然也会阻塞进程，但是和阻塞I/O不同的是它可以同时阻塞多个I/O操作，而且同时对多个读操作、写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O函数。

​		服务器通过**epoll**这种I/O复用技术（还有select和poll）**来实现对监听socket（`listenfd`）和连接socket（客户请求）的同时监听**。

#### (3) IO多路复用技术

- **select**

  - **工作流程：**
    - 首先构造一个关于文件描述符的列表`readfds`，将要监听的文件描述符添加到该列表中，通过`FD_SET`将`readfds`中对应的文件描述符设为1。
    - 调用`select`，将文件描述符列表`readfds` copy到内核空间，监听该列表中的文件描述符，`轮询`感兴趣的fd，**没有数据到来则select阻塞**，直到这些文件描述符中的一个或者多个进行IO操作时，内核将对应位置为1并将结果返回用户空间。
    - 用户空间**遍历**文件描述符列表`readfds`，通过`FD_ISSET`检测对应的fd是否置位，如果置位则调用read读取数据。
  - **优点**：可以监听多个文件描述符
  - **缺点**：
    - **最大可监听文件描述符**有上限，由`fd_set`决定（一般为1024）
    - 需要将`fd_set`在用户态和内核态之间进行copy，开销大
    - 无法精确知道哪些fd准备就绪，每次都需要遍历所有的fd
    - 文件描述符列表集合不能重用，每次都需要重置。

- **poll**

  - `poll`跟`select`实现方式差不多，效率也差不多。只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构。这个结构体`struct pollfd`，里面有`fd`是委托内核检测的文件描述符，`events`是委托内核检测文件描述符的什么事件，`revents`是文件描述符实际发生的事件。
  - **区别在于**
    - **没有最大可监听fd限制**，因为其底层通过**链表**实现；
    - `poll`内核通过`revents`来设置某些事件是否触发，所有每次不需要再重置。

- **epoll**

  - `epoll`是一种比`select`，`poll`更加高效的IO多路复用技术。epoll有三个重要接口：`epoll_create`, `epoll_ctl`, `epoll_wait`。（系统调用）
  - 首先通过`epoll_create`在**内核**创建一个新的创建`eventpoll`结构体。
    - 这个在**内核**创建的结构体有两个重要的数据，一个是需要检测的文件描述符信息，底层是**红黑树，** **增删改时间复杂度都为logn**。另一个是就绪列表，存放所有有IO事件到来的fd（其共用红黑树的节点），底层是**双向链表**。
  - `epoll_ctl`是对这个实例进行管理，包括**插入**，**删除**和**更新**三个操作。
    - 其中**插入**是使用socket fd及其关注的事件构造结构体，并插入到`eventpoll`中，同时会给内核中断处理程序注册一个**回调函数**，告诉内核，如果这个句柄的中断到了，就把它放到**准备就绪list链表**中。**删除**就是将socket fd对应的节点从`eventpoll`中删除，**更新**就是修改socket fd相关的信息，比如更改其所监听的事件等。
  - `epoll_wait`为检测函数，是一个**阻塞**的接口。
    - 如果就绪列表中有事件到来，就会将**就绪事件**copy到用户空间（通过`epoll_event`结构体），并返回事件的数量。没有数据就sleep，等到timeout时间到了即使没有数据也返回。

- **epoll与select, poll对比**

  - **调用函数**

    - select和poll都是一个函数，epoll是一组函数

  - **文件描述符数量**

    - **select**通过**线性表**描述文件描述符集合，文件描述符有上限，一般是1024

    - **poll**是**链表描述**，突破了文件描述符上限，最大可以打开文件的数目
    - **epoll**通过**红黑树**描述，最大可以打开文件的数目，可以通过命令ulimit -n number修改，仅对当前终端有效。

  - **将文件描述符从用户传给内核**

    - select和poll，所有文件描述符都是在**用户态被加入其文件描述符集合**的，每次调用都需要**将整个集合拷贝到**内核态

    - epoll则将**整个文件描述符集合维护在内核态**，通过epoll_create建立一棵红黑树，通过epoll_ctl将要监听的文件描述符注册到红黑树上。

  - **内核判断就绪的文件描述符**

    - select和poll，采用**遍历**的方式，遍历整个文件描述符集合去判断各个文件描述符是否有活动（最大开销）

    - epoll当有活动产生时，会自动**触发epoll回调函数通知epoll文件描述符**，然后**内核将这些就绪的文件描述符放到就绪链表**中等待epoll_wait调用后被处理。
      - epoll_create时，内核除了帮我们在epoll文件系统里建了个红黑树用于存储以后epoll_ctl传来的fd外，还会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。

  - **应用程序索引就绪文件描述符**

    - select/poll只返回发生了事件的文件描述符的个数，若知道是哪个发生了事件，同样需要遍历

    - epoll返回的发生了事件的个数和结构体数组，结构体包含socket的信息，因此直接处理返回的数组即可

  - **工作模式**

    - select和poll都只能工作在相对低效的LT模式下

    - epoll则可以工作在ET高效模式，并且epoll还支持EPOLLONESHOT事件，该事件能进一步减少可读、可写和异常事件被触发的次数。 

  - **应用场景**

    - 当所有的fd都是活跃连接，使用epoll，系统调用的开销是很大的，需要建立文件系统，红黑书和链表对于此来说，效率反而不高，不如selece和poll
    - 当监测的fd数目较小，且各个fd都比较活跃，建议使用select或者poll
    - 当监测的fd数目非常大，成千上万，且单位时间只有其中的一部分fd处于就绪状态，这个时候使用epoll能够明显提升性能
  - ![image-20220413130100977](C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413130100977.png)

#### (4) epoll事件类型

- **EPOLLIN**：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）

- **EPOLLOUT**：表示对应的文件描述符可以写

- **EPOLLPRI**：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）

- **EPOLLERR**：表示对应的文件描述符发生错误

- **EPOLLHUP**：表示对应的文件描述符被挂断；
  - 通过EPOLLRDHUP属性，**来判断是否对端已经关闭，这样可以减少一次系统调用**。在2.6.17的内核版本之前，只能再通过调用一次recv函数来判断

    - `EPOLLHUP` 表示对等端关闭了连接端.**对连接的写入已关闭**，并且在使用任何(可能的)可读数据后，从连接中读取的数据也会关闭.
    - `EDPOLLRDHUP` 仅表示对等方关闭了它们的连接，或仅关闭了一半的连接.如果它只是半关闭，则流套接字将变成单向、只写连接.**对连接的写入可能仍处于打开状态**，但在消耗了任何(可能的)可读数据后，将从连接中读取的数据关闭。
    
  - 在对端关闭时，对于poll和epoll来说会一直触发POLLIN + POLLRDHUP事件，是否一直触发要看epoll是工作在LT模式下还是ET模式下。所以，当我们使用POLLRDHUP事件来判断对端是否关闭时，**POLLRDHUP事件的处理应放在POLLIN事件的前面**，避免将对端关闭当做一次读事件，而无法处理POLLRDHUP事件。

- **EPOLLET**：将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)而言的

- **EPOLLONESHOT**：
  - 通过epoll_ctl对该文件描述符注册epolloneshot事件，只监听/触发一次事件，一个线程处理socket时，其他线程将无法处理，当该线程处理完后，若还需要继续监听这个socket的话，需要通过epoll_ctl重置epolloneshot事件，再次把这个socket加入到EPOLL队列里。
  - 一个线程读取某个socket上的数据后开始处理数据，在处理过程中该socket上又有新数据可读，此时另一个线程被唤醒读取，此时出现两个线程处理同一个socket，我们期望的是**一个socket连接在任一时刻都只被一个线程处理**，可以使用 epoll + EPOLLONESHOT 实现。

#### (5) epoll触发模式

​	`Epoll`对文件操作符的操作有两种模式：LT（电平触发）和ET（边缘触发），二者的区别在于当你调用`epoll_wait`的时候内核里面发生了什么

- **LT水平触发模式**
  - epoll_wait检测到文件描述符有事件发生，则将其通知给应用程序，应用程序可以不立即处理该事件；当下一次调用epoll_wait时，epoll_wait还会再次向应用程序报告此事件，直至被处理。
  - **只要缓冲区有数据，就一直触发，直到缓冲区无数据**
- **ET边缘触发模式**
  - epoll_wait检测到有事件发生，则将其通知给应用程序，应用程序必须立即处理该事件；必须要一次性将数据读取完，使用非阻塞I/O，读取到出现eagain
  - **缓冲区从无数据到有数据时，epoll检测到了会给用户通知**；如果用户不读数据/只读了部分数据，数据一直在缓冲区，`epoll_wait`不通知，直到下一次客户端有新的数据包到达时，`epoll_wait`才会再次被唤醒。
  - **ET在很大程度上减少了epoll事件被重复触发的次数，因此效率比LT高。**
  - **为什么ET模式下一定要设置为非阻塞模式？**
    - 因为ET模式，当有数据时，只会被触发一次，所以每次读取数据时，一定要一次性把数据读取完（必须等到它们返回**EWOULDBLOCK**（确保所有数据都已读完或写完），所以我们需要设置一个whlie循环read数据，但**如果read是阻塞模式，那么如果没有数据时，将会阻塞，导致程序卡死。**所以这里read只允许非阻塞模式，如果没有数据，read将会跳出循环，继续执行其他程序。
    - epoll工作在ET模式的时候，必须使用非阻塞接口，**以避免一个文件描述符的阻塞的读/写操作，把多个文件描述符的任务饿死**。
- **优缺点**
  - **ET模式**
    - 缺点：应用层业务逻辑复杂，容易遗漏事件，很难用好。
    - 优点：相对LT模式效率比较高。一触发立即处理事件。
  - **LT模式**
    - 优点：编程更符合用户直觉，业务层逻辑更简单。
    - 缺点：效率比ET低。
- **具体实现**
  - LT（电平触发）：类似`select`，LT会去遍历在epoll事件表中每个文件描述符，来观察是否有我们感兴趣的事件发生，如果有（触发了该文件描述符上的回调函数），`epoll_wait`就会以非阻塞的方式返回。若该epoll事件没有被处理完（没有返回`EWOULDBLOCK`），该事件还会被后续的`epoll_wait`再次触发。
  - ET（边缘触发）：ET在发现有我们感兴趣的事件发生后，立即返回，并且`sleep`这一事件的`epoll_wait`，不管该事件有没有结束。

#### (6) 五种I/O模型

- **阻塞IO**（同步I/O）：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作
  - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152159430.png" alt="image-20220313152159430" style="zoom:80%;" />
- **非阻塞IO**（同步I/O）：非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。非阻塞I/O执行系统调用总是立即返回，不管事件是否已经发生，若事件没有发生，则返回-1，此时可以根据errno区分这两种情况，对于accept，recv和send，事件未发生时，errno通常被设置成eagain
  - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152551625.png" alt="image-20220313152551625" style="zoom: 80%;" />
- **信号驱动IO**：linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当I/O时间就绪，进程收到SIGIO信号。然后处理I/O事件。
  - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152615232.png" alt="image-20220313152615232" style="zoom:80%;" />
  - 内核在第一个阶段是异步，在第二个阶段是同步；与非阻塞IO的区别在于它提供了消息通知机制，不需要用户进程不断的轮询检查，减少了系统API的调用次数，提高了效率。在多线程中不好处理，比较麻烦 所以一般不使用
- **IO复用**：linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检测。知道有数据可读或可写时，才真正调用IO操作函数
  - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152605380.png" alt="image-20220313152605380" style="zoom:80%;" />
  - 并不是处理高并发 而是一次性读取多个数据
- **异步IO**：linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。
  - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313152623071.png" alt="image-20220313152623071" style="zoom:80%;" />
- 注意：阻塞I/O，非阻塞I/O，信号驱动I/O和I/O复用都是同步I/O。

##### 同步I/O和异步I/O

- **同步I/O**指内核向应用程序通知的是就绪事件，比如只通知有客户端连接，**要求用户代码自行执行I/O操作；**
  - 同步（阻塞）I/O：在一个线程中，CPU执行代码的速度极快，然而，一旦遇到IO操作，如读写文件、发送网络数据时，就需要等待IO操作完成，才能继续进行下一步操作。这种情况称为同步IO。
- **异步I/O**是指内核向应用程序通知的是完成事件，比如读取客户端的数据后才通知应用程序，**由内核完成I/O操作。**
  - 异步（非阻塞）I/O：当代码需要执行一个耗时的IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时，再通知CPU进行处理。
- ![image-20220413113613069](C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413113613069.png)

### 4. 并发模式

#### (1) 高效的事件处理模式

​		服务器程序通常需要处理三类事件：I/O 事件、信号及定时事件。有两种高效的并发事件处理模式：**Reactor和 Proactor**，同步 I/O 模型通常用于实现 Reactor 模式，异步 I/O 模型通常用于实现 Proactor 模式。并发模式指I/O处理单元与逻辑单元的协同完成任务的方法

​		当接收端收到一个或多个TCP报文后，TCP模块将它们携带的应用程序数据按照TCP报文段的序号依次放入TCP接收缓冲区中，并通知应用程序读取数据，可以一次性读完可以多次读取。

- **Reactor**
  - **reactor模式中**，主线程(**I/O处理单元**)只负责监听文件描述符上是否有事件发生，有的话立即通知工作线程(**逻辑单元** )，读写数据、接受新连接及处理客户请求均在工作线程中完成。通常由**同步I/O**实现。
  - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313153902525.png" alt="image-20220313153902525" style="zoom: 80%;" />
  - **使用同步 I/O（以 epoll_wait 为例）实现的 Reactor 模式的工作流程：**
    - 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件，调用 epoll_wait 等待，当 socket 上有数据可读时， epoll_wait 通知主线程。
    - 主线程则将 socket 可读事件放入请求队列，睡眠在请求队列上的某个工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll内核事件表中注册该 socket 上的写就绪事件。
    - 当主线程调用 epoll_wait 等待 socket 可写，当 socket 可写时，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列，睡眠在请求队列上的某个工作线程被唤醒，它往 socket 上写入服务器处理客户请求的结果。
  - **基于reactor模式的I/O框架库**
    - **组件：**
      - **句柄(Handle)：**I/O框架库要处理的对象，I/O事件、信号和定时事件，统称为事件源。一个事件源通常和一个句柄绑定在一起，句柄的作用是，当内核检测到就绪事件时，它将通过句柄来通知应用程序这一事件。Linux下，I/O事件对应的句柄是**文件描述符**，信号事件对应的句柄是信号值。
      - **事件多路分发器：**事件的到来是异步的，随机的，所以程序需要循环地等待并处理事件，这就是事件循环。在事件循环中，等待事件一般使用I/O复用技术实现。I/O框架库将系统支持的各种I/O复用系统调用封装成统一的接口，称为事件多路分发器。
      - **事件处理器和具体事件处理器：**执行事件对应的业务逻辑，包括一个或多个handle_event回调函数，这些回调函数在事件循环中被执行。I/O框架库提供的事件处理器通常是一个接口，用户需要继承它来实现自己的事件处理器，即具体事件处理器。因此回调函数一般被声明为虚函数，支持用户的扩展。一般还提供一个get_handle方法返回句柄。
-  **Proactor**
  - **proactor模式中**，主线程和内核负责处理读写数据、接受新连接等I/O操作，工作线程仅负责业务逻辑，如处理客户请求。通常由**异步I/O**实现。
  - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313154026324.png" alt="image-20220313154026324" style="zoom: 80%;" />
  - **使用异步 I/O 模型（以 aio_read 和 aio_write 为例）实现的 Proactor 模式的工作流程：**
    - 主线程调用 aio_read 函数向内核注册 socket 上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序。主线程继续处理其他逻辑。
    - 当 socket 上的数据被读入用户缓冲区后，内核将向应用程序发送一个信号，以通知应用程序数据已经可用。
    - **应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。**工作线程处理完客户请求后，调用 aio_write 函数向内核注册 socket 上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序。主线程继续处理其他逻辑。
    - 当用户缓冲区的数据被写入 socket 之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕。应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭 socket。
  - **同步I/O模拟proactor模式**
    - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313154125049.png" alt="image-20220313154125049" style="zoom:80%;" />
    - **同步I/O模型的工作流程如下（epoll_wait为例）：**
      - 主线程往epoll内核事件表注册socket上的读就绪事件，调用epoll_wait等待，当socket上有数据可读，epoll_wait通知主线程，主线程从socket循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列。
      - 睡眠在请求队列上某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件。
      - 主线程调用epoll_wait等待socket可写，当socket上有数据可写，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。

#### (2) 高效的并发模式

​		并发编程的目的是让程序“同时”执行多个任务。如果程序是计算密集型的，并发编程并没有优势。反而由于任务的切换使效率降低；如果程序是I/O密集型的，比如经常读写文件，访问数据库等，情况就不同了。由于I/O操作的速度远没有CPU的计算速度快，所以让程序阻塞于I/O操作将浪费大量的CPU时间。如果程序有多个执行线程，则当前被I/O操作所阻塞的执行线程可主动放弃CPU（或由操作系统来调度），并将执行权转移到其他线程，这样CPU可以用来做更加有意义的事儿（除非所有线程都同时被I/O操作所阻塞），而不是等待I/O操作完成，因此CPU的利用率显著提升。

- **两种并发编程模式：**
  - **半同步/半异步模式**
    - **I/O模型中，**同步和异步的区分是内核向应用程序通知的是何种I/O事件（是就绪事件还是完成事件），以及由谁来完成读写（是应用程序还是内核）
    - **并发模式中，**同步是指程序完全按照代码序列的顺序执行，异步是指程序的执行需要由系统事件来驱动
      - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413114724679.png" alt="image-20220413114724679" style="zoom:67%;" />
      - **半同步/半异步模式**
        - 同步线程用于处理客户逻辑，异步程序监听到客户请求后，就将其封装成请求对象并插入请求队列中，请求队列将通知某个工作在同步模式的工作线程来读取并处理该请求对象。
        - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413115132150.png" alt="image-20220413115132150" style="zoom:67%;" />
      - **半同步/半反应堆模式（变体）**
        - 异步线程只有一个，由主线程来充当，它负责监听所有socket上的事件，如果有可读事件发生，即有新的连接请求进来，主线程就接受以得到新的连接socket，然后往epoll内核事件表中注册该socket的读写事件。如果连接socket上有读写事件发生，主线程就将该连接socket插入请求队列中。所有工作线程都睡眠在请求队列上，当有任务到来时，通过竞争获得任务接管权。
        - 缺点：主线程和工作线程共享请求队列。主线程往请求队列中添加任务，或者工作线程从请求队列中取出任务，都需要对请求队列加锁保护，浪费CPU时间；每个工作线程同一时间只能处理一个客户请求。如果客户数量较多，工作线程较少，则请求队列中将堆积很多任务对象，客户端的响应速度越来越慢。如果通过增加工作线程来解决这一问题，则工作线程的切换也消耗CPU时间
        - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413115228893.png" alt="image-20220413115228893" style="zoom:67%;" />
      - **高效的半同步/半异步模式**
        - 它的每个工作线程都能同时处理多个客户连接
        - 主线程只管理监听socket，连接socket由工作线程来管理，当有新的连接到来时，主线程就接受它并将新返回的连接socket派发给某个工作线程，此后该socket上的任何I/O操作都由被选中的工作线程来处理，直到客户关闭连接。主线程向工作线程派发socket的最简单的方式，就是往它和工作线程之间的管道里写数据。工作线程检测到管道上有数据可读时，就分析是否是一个新的客户连接请求到来。如果是就把该新socket上的读写事件注册到自己的epoll内核事件表中。
        - 每个线程都维持自己的事件循环，他们各自独立地监听不同的事件。
        - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413120354451.png" alt="image-20220413120354451" style="zoom:67%;" />
  - **领导者/追随者模式**
    - 多个工作线程轮流获得事件源集合，轮流监听、分发并处理事件的一种模式。在任意时间点，程序都仅有一个领导者线程，它负责监听I/O事件。而其他线程则都是追随者，他们休眠在线程池中等待成为新的领导者线程，然后处理I/O事件。此时，新的领导者等待新的I/O事件，而原来的领导者则处理I/O事件，两者实现了并发
    - 组件：句柄集(HandleSet)、线程集(ThreadSet)、事件处理器(EventHandler)、具体的事件处理器(ConcreteEventHandler)
    - <img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220413123817646.png" alt="image-20220413123817646" style="zoom:67%;" />

### 5. 线程与线程池

#### (1) 线程池

​		使用多线程充分利用**多核CPU**，并使用线程池**避免线程频繁创建**、**销毁加大系统开销。**

**具体实现：**

- 使用线程池并发处理用户请求，主线程负责监听事件的发生，（如果是proactor模式则主线程也负责读写），工作线程负责处理逻辑（如果是reactor模式则工作线程需要先读写再处理逻辑）。

- 创建一个线程池来管理多线程，线程池中主要包含**任务队列** 和**工作线程**集合，将任务添加到队列中，然后在创建线程后，自动启动这些任务。使用了一个固定线程数的工作线程，限制线程最大并发数。（充分利用多核CPU，并使用线程池避免线程频繁创建、销毁加大系统开销。）
- 多个线程共享任务队列，所以需要进行线程间同步，工作线程之间对任务队列的竞争采用**信号量**和**互斥锁**结合使用。
  - 线程池的实现还需要依靠**锁机制**以及**信号量**机制来实现线程同步，保证操作的原子性。
  - **工作队列**一定要加**互斥锁**，因为它被所有线程共享。
  - **队列中的请求数**用**信号量**来标识，用于等待一个请求队列中待处理的HTTP请求，然后交给线程池中的空闲线程来处理。
- 一个工作线程**先加互斥锁**，当任务队列中任务数量为0时候，阻塞在**信号量**，当任务数量大于0时候，用信号量通知阻塞在条件变量下的线程，这些线程来继续竞争获取任务。
  - 加入队列：先加互斥锁，若队列满了则退出解锁，若没有满则加入队列中，解锁，阻塞在信号量
  - 信号量收到通知，队列加锁，将队列的头节点取出来，队列解锁，然后执行任务
- 对任务队列中任务的调度采用**先来先服务**算法。

**为什么要使用线程池：**

​		因为创建和销毁线程都会带来性能开销，为了充分利用多核CPU进行任务的并发执行，我们可以将这些任务任务传递到线程池，而不是为每个任务动态开启一个新的线程。

​		使用线程池避免线程频繁创建、销毁加大系统开销，避免了服务器对内核的频繁访问。

**线程池特点：**

- **池的概念：**空间换时间,浪费服务器的硬件资源,换取运行效率；池是一组资源的集合,这组资源在服务器启动之初就被完全创建好并初始化,这称为静态资源；当服务器进入正式运行阶段,开始处理客户请求的时候,如果它需要相关的资源,可以直接从池中获取,无需动态分配，因为分配系统资源的系统调用都是很费时的这样快得多。
- 当服务器处理完一个客户连接后,可以把相关的资源放回池中,无需执行系统调用释放资源。
- 线程池的设计模式为半同步/半反应堆，其中反应堆具体为Proactor事件处理模式。
  - 主线程为异步线程，负责监听文件描述符，接收socket新连接，若当前监听的socket发生了读写事件，然后将任务插入到请求队列。工作线程从请求队列中取出任务，完成读写数据的处理。

**线程池的一般模型为：**

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313154321758.png" alt="image-20220313154321758" style="zoom:80%;" />

线程池是由服务器预先创建的一组子线程，**线程池中的线程数量应该和 CPU 数量差不多**。线程池中的所有子线程都运行着相同的代码。当有新的任务到来，主线程将通过某种方式选择线程池中的某一个子线程来为之服务。相比与动态的创建子线程，选择一个已经存在的子线程的代价显然要小得多。

**至于主线程选择哪个子线程来为新任务服务**，则有多种方式：

​		**主线程使用某种算法来主动选择子线程。**最简单、最常用的算法是**随机算法**和 **Round Robin（轮流选取）**算法，但更优秀、更智能的算法将使任务在各个工作线程中更均匀地分配，从而减轻服务器的整体压力。

​		**主线程和所有子线程通过一个共享的工作队列来同步，子线程都睡眠在该工作队列上。**当有新的任务到来时，主线程将任务添加到工作队列中。这将唤醒正在等待任务的子线程，不过只有一个子线程将获得新任务的”接管权“，它可以从工作队列中取出任务并执行之，而其他子线程将继续睡眠在工作队列上。


#### (2) 线程池的使用

> 1. 高并发、任务执行时间短的业务怎样使用线程池？
>
> 2. 并发不高、任务执行时间长的业务怎样使用线程池？
>
> 3. 并发高、业务执行时间长的业务怎样使用线程池？

线程池本质上是**生产者和消费者**模型，包括三要素：

- 往线程池队列中投**递任务的生产者**；
- **任务队列**；
- 从任务队列取出任务执行的**工作线程（消费者）**。

要想合理的配置线程池的大小，得分析线程池任务的特性，可以从以下几个方面来分析：

- 根据任务的性质来分：CPU 密集型任务；IO 密集型任务；混合型任务。
- 根据任务的优先级：高、中、低
- 根据任务的执行时间：长、中、短

不同性质的任务可以交给不同配置的线程池执行。

#### (4) 线程池的线程数量

最直接的限制因素是CPU处理器的个数。

- 如果CPU是4核的，那么**对于CPU密集的任务**，线程池的线程数量最好也为4，或者+1防止其他因素导致阻塞。
- 如果是**IO密集的任务**，一般要多于CPU的核数，因为 IO 操作不占用 CPU，线程间竞争的不是CPU资源而是IO，IO的处理一般比较慢，多于核数的线程将为CPU争取更多的任务，不至于在线程处理IO的时候造成CPU空闲导致资源浪费。
- 而**对于混合型的任务**，如果可以拆分，拆分成 IO 密集型和 CPU 密集型分别处理，前提是两者运行的时间是差不多的，如果处理时间相差很大，则没必要拆分了。

如果**任务执行时间长**，在工作线程数量有限的情况下，工作线程很快就很被任务占完，导致后续任务不能及时被处理，此时应适当**增加工作线程数量**；反过来，如果**任务执行时间短**，那么**工作线程数量不用太多**，太多的工作线程会导致过多的时间浪费在线程上下文切换上。

回到这个问题本身来，这里的“高并发”应该是生产者生产任务的速度比较快，此时需要适当**增大任务队列上限**。

但是对于第三个问题并发高、业务执行时间长这种情形单纯靠线程池解决方案是不合适的，即使服务器有再高的资源配置，每个任务长周期地占用着资源，最终服务器资源也会很快被耗尽，因此对于这种情况，应该配合**业务解耦**，做些模块拆分优化整个系统结构。

#### (5) 线程同步机制

​		**线程同步**：当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作，其他线程才能对该内存地址进行操作，而其他线程则处于等待状态。

###### ① 信号量 sem

信号量是一种特殊的变量，它只能取自然数值并且只支持两种操作：等待(P)和信号(V).假设有信号量SV，对其的P、V操作如下：

> - P，如果SV的值大于0，则将其减一；若SV的值为0，则挂起执行
> - V，如果有其他进行因为等待SV而挂起，则唤醒；若没有，则将SV值加一

信号量的取值可以是任何自然数，最常用的，最简单的信号量是二进制信号量，只有0和1两个值.

> - sem_init函数用于初始化一个未命名的信号量
> - sem_destory函数用于销毁信号量
> - sem_wait函数将以原子操作方式将信号量减一,信号量为0时,sem_wait阻塞
> - sem_post函数以原子操作方式将信号量加一,信号量大于0时,唤醒调用sem_post的线程

以上，成功返回0，失败返回errno

###### ② 互斥量

互斥锁,也成互斥量,可以保护关键代码段,以确保独占式访问.当进入关键代码段,获得互斥锁将其加锁;离开关键代码段,唤醒等待该互斥锁的线程.

> - pthread_mutex_init函数用于初始化互斥锁
> - pthread_mutex_destory函数用于销毁互斥锁
> - pthread_mutex_lock函数以原子操作方式给互斥锁加锁
> - pthread_mutex_unlock函数以原子操作方式给互斥锁解锁

以上，成功返回0，失败返回errno

###### ③ 条件变量

条件变量提供了一种线程间的通知机制,当某个共享数据达到某个值时,唤醒等待这个共享数据的线程.

> - pthread_cond_init函数用于初始化条件变量
> - pthread_cond_destory函数销毁条件变量
> - pthread_cond_broadcast函数以广播的方式唤醒**所有**等待目标条件变量的线程
> - pthread_cond_wait函数用于等待目标条件变量.该函数调用时需要传入 **mutex参数(加锁的互斥锁)** ,函数执行时,先把调用线程放入条件变量的请求队列,然后将互斥锁mutex解锁,当函数成功返回为0时,互斥锁会再次被锁上. **也就是说函数内部会有一次解锁和加锁操作**.

#### (6) 锁机制的功能

- 实现多线程同步，通过锁机制，确保任一时刻只能有一个线程能进入关键代码段

#### (7) 进程与线程



### 6. HTTP报文解析

#### (1) HTTP报文格式

HTTP报文分为请求报文和响应报文两种，每种报文必须按照特有格式生成，才能被浏览器端识别。其中，浏览器端向服务器发送的为请求报文，服务器处理后返回给浏览器端的为响应报文。

##### ① 请求报文

HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据四个部分组成。

其中，请求分为两种，GET和POST，具体的：（POST的请求内容不为空）

- **GET和POST的区别**
  - 最直观的区别就是GET把参数包含在URL中，POST通过request body传递参数。
  - GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
  - GET请求在URL中传送的参数是有长度限制。（大多数）浏览器通常都会限制url长度在2K个字节，而（大多数）服务器最多处理64K大小的url。
  - GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100（指示信息—表示请求已接收，继续处理）continue，浏览器再发送data，服务器响应200 ok（返回数据）。

- **报文组成部分**
  - **请求行**：用来说明请求类型,要访问的资源以及所使用的HTTP版本。
  - **请求头部**：紧接着请求行（即第一行）之后的部分，用来说明服务器要使用的附加信息。
    - HOST，给出请求资源所在服务器的域名。
    - User-Agent，HTTP客户端程序的信息，该信息由你发出请求使用的浏览器来定义,并且在每个请求中自动发送等。
    - Accept，说明用户代理可处理的媒体类型。
    - Accept-Encoding，说明用户代理支持的内容编码。
    - Accept-Language，说明用户代理能够处理的自然语言集。
    - Content-Type，说明实现主体的媒体类型。
    - Content-Length，说明实现主体的大小。
    - Connection，连接管理，可以是Keep-Alive或close。
  - **空行**：请求头部后面的空行是必须的即使第四部分的请求数据为空，也必须有空行。
  - **请求数据**也叫主体，可以添加任意的其他数据。

##### ② 响应报文

HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。

- **状态行**：由HTTP协议版本号， 状态码， 状态消息 三部分组成。
  - 第一行为状态行，（HTTP/1.1）表明HTTP版本为1.1版本，状态码为200，状态消息为OK。
- **消息报头**：用来说明客户端要使用的一些附加信息。
  - 第二行和第三行为消息报头，Date:生成响应的日期和时间；Content-Type:指定了MIME类型的HTML(text/html),编码类型是UTF-8。
- **空行**：消息报头后面的空行是必须的。
- **响应正文**：服务器返回给客户端的文本信息。空行后面的html部分为响应正文。

##### ③ HTTP状态码

HTTP有5种类型的状态码，具体的：

- 1xx：指示信息--表示请求已接收，继续处理。

- 2xx：成功--表示请求正常处理完毕。

  - 200 OK：客户端请求被正常处理。

  - 206 Partial content：客户端进行了范围请求。

- 3xx：重定向--要完成请求必须进行更进一步的操作。

  - 301 Moved Permanently：永久重定向，该资源已被永久移动到新位置，将来任何对该资源的访问都要使用本响应返回的若干个URI之一。

  - 302 Found：临时重定向，请求的资源现在临时从不同的URI中获得。

- 4xx：客户端错误--请求有语法错误，服务器无法处理请求。

  - 400 Bad Request：请求报文存在语法错误。

  - 403 Forbidden：请求被服务器拒绝。
  - 404 Not Found：请求不存在，服务器上找不到请求的资源。

- 5xx：服务器端错误--服务器处理请求出错。

  - 500 Internal Server Error：服务器在执行请求时出现错误。

#### (2) http处理流程

- 浏览器端发出http连接请求，主线程创建http对象接收请求并将所有数据读入对应buffer，将该对象插入任务队列，工作线程从任务队列中取出一个任务进行处理。
- 工作线程取出任务后，调用process_read函数，通过**主从状态机**对请求报文进行解析。
- 解析完之后，跳转do_request函数生成响应报文，通过process_write写入buffer，返回给浏览器端。

##### ① 有限状态机

​		有限状态机，是一种抽象的理论模型，它能够把有限个变量描述的状态变化过程，以可构造可验证的方式呈现出来。比如，封闭的有向图。

​		有限状态机可以通过if-else,switch-case和函数指针来实现，从软件工程的角度看，**主要是为了封装逻辑**。

​		有限状态机一种逻辑单元内部的一种高效编程方法，在服务器编程中，服务器可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂。

##### ② 解析HTTP报文

**从状态机负责读取报文的一行，主状态机负责对该行数据进行解析**，主状态机内部调用从状态机，从状态机驱动主状态机。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBH2ZO50WrURwTiaNKTH7tCia3AR4WeKu2EEzSgKibXzG4oa4WaPfGutwBqCJtemia3rc5V1wupvOLFjzQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"  />

###### **主状态机**

三种状态，标识解析位置。

- CHECK_STATE_REQUESTLINE，解析请求行
- CHECK_STATE_HEADER，解析请求头
- CHECK_STATE_CONTENT，解析消息体，仅用于解析POST请求

###### **从状态机**

三种状态，标识解析一行的读取状态。

- LINE_OK，完整读取一行
- LINE_BAD，报文语法有误
- LINE_OPEN，读取的行不完整

###### 解析报文流程

process_read通过while循环，将主从状态机进行封装，对报文的每一行进行循环处理。

- 判断条件

  - 主状态机转移到CHECK_STATE_CONTENT，该条件涉及解析消息体

  - 从状态机转移到LINE_OK，该条件涉及解析请求行和请求头部
  - 两者为或关系，当条件为真则继续循环，否则退出

- 循环体

  - 从状态机读取数据

  - 调用get_line函数，通过m_start_line将从状态机读取数据间接赋给text
  - 主状态机解析text

###### 从状态机逻辑

在HTTP报文中，每一行的数据由\r\n作为结束字符，空行则是仅仅是字符\r\n。因此，可以通过查找\r\n将报文拆解成单独的行进行解析，项目中便是利用了这一点。

从状态机负责读取buffer中的数据，将每行数据末尾的\r\n置为\0\0，并更新从状态机在buffer中读取的位置m_checked_idx，以此来驱动主状态机解析。

- 从状态机从m_read_buf中逐字节读取，判断当前字节是否为\r

  - 接下来的字符是\n，将\r\n修改成\0\0，将m_checked_idx指向下一行的开头，则返回LINE_OK

  - 接下来达到了buffer末尾，表示buffer还需要继续接收，返回LINE_OPEN
  - 否则，表示语法错误，返回LINE_BAD

- 当前字节不是\r，判断是否是\n（**一般是上次读取到\r就到了buffer末尾，没有接收完整，再次接收时会出现这种情况**）

  - 如果前一个字符是\r，则将\r\n修改成\0\0，将m_checked_idx指向下一行的开头，则返回LINE_OK

- 当前字节既不是\r，也不是\n

  - 表示接收不完整，需要继续接收，返回LINE_OPEN

###### **主状态机逻辑**

​		主状态机初始状态是解析行CHECK_STATE_REQUESTLINE，通过调用从状态机来驱动主状态机，在主状态机进行解析前，从状态机已经将每一行的末尾\r\n符号改为\0\0，以便于主状态机直接取出对应字符串进行处理。

- **CHECK_STATE_REQUESTLINE  解析行**
  - 解析函数从m_read_buf中解析HTTP请求行，获得请求方法、目标URL及HTTP版本号
    - 在HTTP报文中，请求行用来说明请求类型,要访问的资源以及所使用的HTTP版本，其中各个部分之间通过\t或空格分隔。
    - 如果不符合格式条件 返回 BAD_REQUEST  所都符合 则 返回 NO_REQUEST
  - 解析完成后主状态机的状态变为CHECK_STATE_HEADER
    - 解析完请求行后，主状态机继续分析请求头。在报文中，请求头和空行的处理使用的同一个函数，这里通过判断当前的text首位是不是\0字符，若是，则表示当前处理的是空行，若不是，则表示当前处理的是请求头。
  - 解析请求行，也就是GET中的`GET /562f25980001b1b106000338.jpg HTTP/1.1`这一行，或者POST中的`POST / HTTP1.1`这一行。通过请求行的解析我们可以判断该HTTP请求的类型（GET/POST），而请求行中最重要的部分就是`URL`部分，我们会将这部分保存下来用于后面的生成HTTP响应。

- **CHECK_STATE_HEADER 解析头**
  - 判断是空行还是请求头
    - 若是空行，进而判断content-length是否为0
      - 如果不是0，表明是POST请求，则状态转移到CHECK_STATE_CONTENT 且返回 NO_REQUEST
      - 如果是0，说明是GET请求，返回GET_REQUEST 则报文解析结束。
    - 若不是空行，则解析的是请求头部字段，然后分析字段
      - connection字段判断是keep-alive还是close，决定是长连接还是短连接
      - content-length字段，这里用于读取post请求的消息体长度
      - 然后返回 NO_REQUEST
  - 判断返回若是GET_REQUEST，跳转到报文响应函数
  - 解析请求头部，GET和POST中`空行`以上，请求行以下的部分。

- **CHECK_STATE_CONTENT 解析消息体**
  - 仅用于解析POST请求，调用parse_content函数解析消息体，用于保存post请求消息体，为后面的登录和注册做准备
    - 若读完消息体，则返回GET_REQUEST，否则NO_REQUEST
  - 判断返回若是GET_REQUEST，跳转到报文响应函数
  - 解析请求数据，对于GET来说这部分是空的，因为这部分内容已经以明文的方式包含在了请求行中的`URL`部分了；只有POST的这部分是有数据的，项目中的这部分数据为用户名和密码，我们会根据这部分内容做登录和校验，并涉及到与数据库的连接。
- 经过上述解析，当得到一个完整的，正确的HTTP请求时，就到了`do_request`代码部分，我们需要首先对GET请求和不同POST请求（登录，注册，请求图片，视频等等）做不同的预处理，然后分析目标文件的属性，若目标文件存在、对所有用户可读且不是目录时，则使用`mmap`将其映射到内存地址`m_file_address`处，并告诉调用者获取文件成功。

##### ③ HTTP请求的处理结果

HTTP_CODE表示HTTP请求的处理结果，在头文件中初始化了八种情形，在报文解析与响应中只用到了七种。

- NO_REQUEST

  - 请求不完整，需要继续读取请求报文数据

  - 跳转主线程继续监测读事件

- GET_REQUEST

  - 获得了完整的HTTP请求

  - 调用do_request完成请求资源映射

- NO_RESOURCE

  - 请求资源不存在

  - 跳转process_write完成响应报文

- **BAD_REQUEST  //404**

  - HTTP请求报文有语法错误或请求资源为目录

  - 跳转process_write完成响应报文

- **FORBIDDEN_REQUEST  //403**

  - 请求资源禁止访问，没有读取权限

  - 跳转process_write完成响应报文

- **FILE_REQUEST  //200**

  - 请求资源可以正常访问

  - 跳转process_write完成响应报文

- **INTERNAL_ERROR  //500**

  - 服务器内部错误，该结果在主状态机逻辑switch的default下，一般不会触发

#### (3) 同步实现注册登录

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBF79BLANEZ6cQoucgxyIz8B0Mz7VGZVTv4MpQC7pLL2bZiaic7sAVz2lhyk8ibL95apWmSE8AfGxAx6A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

#### (4) HTTP

##### ① 在浏览器中输入url地址后显示主页的过程?

- 根据域名url，进行DNS域名解析；   （向DNS服务器发送DNS请求，查询本地DNS服务器，这其中用的是UDP的协议）                
- 拿到解析的IP地址，建立TCP连接；    
- 向IP地址，发送HTTP请求；
- 服务器处理请求；
- 返回响应结果；
- 关闭TCP连接；
- 浏览器解析HTML；
- 浏览器布局渲染

##### ② GET请求和 POST 请求

- **GET和 POST 的区别**
  - **语义：**
    - GET 的语义是从服务器获取指定的资源，是「只读」操作
    - POST 的语义是根据请求负荷（报文body）对指定的资源做出处理，是「新增或提交数据」的操作
  - **携带数据：**
    - GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制
    - POST 请求携带数据的位置一般是写在报文 body 中， 数据可以是任意格式的数据，只要客户端与服务端协商好即可，浏览器不会对 body 大小做限制
    - **GET 请求可以带 body 吗**
      - RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。
    - **GET和POST的长度限制**
      - 网络上都会提到浏览器地址栏输入的参数是有限的。
      - 首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。
      - 浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。
      - get 限制是**特定的浏览器及服务器对它的限制**，比如IE对URL长度的限制是2083字节(2K+35字节)。对于其他浏览器，如FireFox，Netscape等，则没有长度限制，这个时候其限制**取决于服务器的操作系统**；即如果url太长，服务器可能会因为安全方面的设置从而拒绝请求或者发生不完整的数据请求。
      - post 理论上讲是没有大小限制的，HTTP协议规范也没有进行大小限制，但实际上**post所能传递的数据量大小取决于服务器的设置和内存大小**。
  - **安全和幂等：**
    - GET 方法是安全且幂等的，可以对 GET 请求的数据做缓存，缓存可以做到浏览器或者代理上，而且在浏览器中 GET 请求可以保存为书签。
    - POST 方法是不安全且不幂等的，会修改服务器的资源，多次提交数据会创建多个资源，浏览器一般不会缓存 POST 请求，也不把 POST 请求保存为书签
      - 可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。
      - 可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。
    - **POST 方法比 GET 方法安全**
      - 有人说POST 比 GET 安全，因为数据在地址栏上不可见。		然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。要想安全传输，就只有加密，也就是 HTTPS。
  
- **POST 产生两个 TCP 数据包**
    - 有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。
    - HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。
    - 所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。

##### ③ HTTP 与 HTTPS 的区别

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

##### ④ HTTP 1.0，1.1，2.0

http/1.0 :

1. 默认不支持长连接，需要设置keep-alive参数指定
2. 强缓存expired、协商缓存last-modified\if-modified-since 有一定的缺陷

http 1.1 :

1. 默认长连接(keep-alive)，http请求可以复用Tcp连接，但是同一时间只能对应一个http请求(http请求在一个Tcp中是串行的)
2. 增加了强缓存cache-control、协商缓存etag\if-none-match 是对http/1 缓存的优化

http/2.0 :

1. 多路复用，一个Tcp中多个http请求是并行的 (雪碧图、多域名散列等优化手段http/2中将变得多余)
2. 二进制格式编码传输
3. 使用HPACK算法做header压缩
4. 服务端推送

### 7. 信号与定时器

#### (1) 概念

- **非活跃** (设置定时器的原因)
  - 是指客户端（这里是浏览器）与服务器端建立连接后，长时间不交换数据，一直占用服务器端的文件描述符，导致连接资源的浪费。
  - 这时候就应该利用定时器把这些超时的非活动连接释放掉，关闭其占用的文件描述符。
- **定时任务处理函数**
  - 该函数封装在容器类中，具体的，函数遍历升序链表容器，根据超时时间，处理对应的定时器。
  - 使用统一事件源，SIGALRM信号每次被触发，主循环中调用一次定时任务处理函数，处理链表容器中到期的定时器。具体的逻辑如下，

    - 遍历定时器升序链表容器，从头结点开始依次处理每个定时器，直到遇到尚未到期的定时器
    - 若当前时间小于定时器超时时间，跳出循环，即未找到到期的定时器
    - 若当前时间大于定时器超时时间，即找到了到期的定时器，执行回调函数，然后将它从链表中删除，然后继续遍历
- **定时器容器**
  - 是指使用某种容器类数据结构，将上述多个定时器组合起来，便于对定时事件统一管理。具体的，项目中使用升序链表将所有定时器串联组织起来。
  - 项目中的定时器容器为带头尾结点的升序双向链表，具体的为每个连接创建一个定时器，将其添加到链表中，并按照超时时间升序排列。执行定时任务时，将到期的定时器从链表中删除。
    - 从实现上看，主要涉及**双向链表的插入，删除操作，其中添加定时器的事件复杂度是O(n),删除定时器的事件复杂度是O(1)。**
    - 升序双向链表主要逻辑如下，具体的，
      - 创建头尾节点，其中头尾节点没有意义，仅仅统一方便调整
      - add_timer函数，将目标定时器添加到链表中，添加时按照升序添加，若当前链表中只有头尾节点，直接插入，否则，将定时器按升序插入
      - adjust_timer函数，当定时任务发生变化,调整对应定时器在链表中的位置，客户端在设定时间内有数据收发,则当前时刻对该定时器重新设定时间，这里只是往后延长超时时间，被调整的目标定时器在尾部，或定时器新的超时值仍然小于下一个定时器的超时，不用调整，否则先将定时器从链表取出，重新插入链表
      - del_timer函数将超时的定时器从链表中删除，常规双向链表删除结点
- **定时器**
  - 是指利用结构体或其他形式，将多种定时事件进行封装起来。具体的，这里只涉及一种定时事件，即定期检测非活跃连接，这里将该定时事件与连接资源封装为一个结构体定时器。
  - 将连接资源和定时事件等封装起来，具体包括连接资源、超时时间和回调函数，这里的回调函数指向定时事件。
    - **定时事件**是指固定一段时间之后触发某段代码，由该段代码处理一个事件，如从内核事件表删除事件，并关闭文件描述符，释放连接资源。
  - 项目中将连接资源、定时事件和超时时间封装为定时器类，具体的，

    - 连接资源包括客户端套接字地址、文件描述符和定时器
    - 定时事件为回调函数，将其封装起来由用户自定义，这里是删除非活动socket上的注册事件，并关闭
    - 定时器超时时间 = 浏览器和服务器连接时刻 + 固定时间(TIMESLOT)，可以看出，定时器使用绝对时间作为超时值，这里alarm设置为5秒，连接超时为15秒。

#### (2) 定时的方法

本项目中，服务器主循环为每一个连接创建一个定时器，并对每个连接进行定时。另外，利用升序时间链表容器将所有定时器串联起来，若主循环接收到定时通知，则在链表中依次执行定时任务。

`Linux`下提供了三种定时的方法:

- socket选项SO_RECVTIMEO和SO_SNDTIMEO
- SIGALRM信号
- I/O复用系统调用的超时参数

三种方法没有一劳永逸的应用场景，也没有绝对的优劣。由于**项目中使用的是`SIGALRM`信号来实现定时器**。

具体的，利用`alarm`函数周期性地触发`SIGALRM`信号，信号处理函数利用管道通知主循环（每当监测到有这个信号的时候，都会将这个信号写到`pipefd[1]`里面，传递给主循环），主循环接收到该信号后对升序链表上所有定时器进行处理（当我们在读端`pipefd[0]`读到这个信号的的时候，就会将`timeout`变量置为`true`并跳出循环，让`timer_handler()`函数取出来定时器容器上的到期任务，该定时器容器是通过升序链表来实现的，从头到尾对检查任务是否超时，若超时则调用定时器的回调函数`cb_func()`，关闭该socket连接，并删除其对应的定时器`del_timer`），若该段时间内没有交换数据，则将该连接关闭，释放所占用的资源。

#### (3) 信号通知流程

Linux下的信号采用的**异步处理机制**，信号处理函数和当前进程是两条不同的执行路线。具体的，当进程收到信号时，操作系统会中断进程当前的正常流程，转而进入信号处理函数执行操作，完成后再返回中断的地方继续执行。

为避免信号竞态现象发生，信号处理期间系统不会再次触发它。所以，为确保该信号不被屏蔽太久，信号处理函数需要尽可能快地执行完毕。

一般的信号处理函数需要处理该信号对应的逻辑，当该逻辑比较复杂时，信号处理函数执行时间过长，会导致信号屏蔽太久。

这里的解决方案是，信号处理函数仅仅发送信号通知程序主循环，将信号对应的处理逻辑放在程序主循环中，由主循环执行信号对应的逻辑代码。

##### **信号通知逻辑**

- 创建管道，其中管道写端写入信号值，管道读端通过I/O复用系统监测读事件
- 设置信号处理函数SIGALRM（时间到了触发）和SIGTERM（kill会触发，Ctrl+C）
  - 通过struct sigaction结构体和sigaction函数注册信号捕捉函数
  - 在结构体的handler参数设置信号处理函数，具体的，从管道写端写入信号的名字
- 利用I/O复用系统监听管道读端文件描述符的可读事件
- 信息值传递给主循环，主循环再根据接收到的信号值执行目标信号对应的逻辑代码

#### (4) 信号处理机制

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBF4pFdWIo9AHPnib7HCeX9t4u3DhF2ywtNlamuVEDmd0IGDI3klPTJpPvjvric8U490RvzueCe7icTOg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 67%;" />

每个进程之中，都有存着一个表，里面存着每种信号所代表的含义，内核通过设置表项中每一个位来标识对应的信号类型。

- **信号的接收**

  ​		接收信号的任务是由内核代理的，当内核接收到信号后，会将其放到对应进程的信号队列中，同时向进程发送一个中断，使其陷入内核态。注意，此时信号还只是在队列中，对进程来说暂时是不知道有信号到来的。

- **信号的检测**

  - 进程从内核态返回到用户态前进行信号检测
  - 进程在内核态中，从睡眠状态被唤醒的时候进行信号检测
  - 进程陷入内核态后，有两种场景会对信号进行检测：
  - 当发现有新信号时，便会进入下一步，信号的处理。

- **信号的处理**

  - ( **内核** )信号处理函数是运行在用户态的，调用处理函数前，内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器（eip）将其指向信号处理函数。
  - ( **用户** )接下来进程返回到用户态中，执行相应的信号处理函数。
  - ( **内核** )信号处理函数执行完成后，还需要返回内核态，检查是否还有其它信号未处理。
  - ( **用户** )如果所有信号都处理完成，就会将内核栈恢复（从用户栈的备份拷贝回来），同时恢复指令寄存器（eip）将其指向中断前的运行位置，最后回到用户态继续执行进程。

至此，一个完整的信号处理流程便结束了，如果同时有多个信号到达，上面的处理流程会在第2步和第3步骤间重复进行。

**为什么管道写端要非阻塞？**

​		send是将信息发送给套接字缓冲区，如果缓冲区满了，则会阻塞，这时候会进一步增加信号处理函数的执行时间，为避免信号竞态现象发生，将其修改为非阻塞。

**没有对非阻塞返回值处理，如果阻塞是不是意味着这一次定时事件失效了？**

​		是的，但定时事件是非必须立即处理的事件，可以允许这样的情况发生。

**管道传递的是什么类型？switch-case的变量冲突？**

​		信号本身是整型数值，管道中传递的是ASCII码表中整型数值对应的字符。

​		switch的变量一般为字符或整型，当switch的变量为字符时，case中可以是字符，也可以是字符对应的ASCII码。

#### (5) 如何使用定时器

- 浏览器与服务器连接时，创建该连接对应的定时器，并将该定时器添加到链表上
- 处理异常事件时，执行定时事件，服务器关闭连接，从链表上移除对应定时器
- 处理定时信号时，将定时标志设置为true
- 处理读事件时，若某连接上发生读事件，将对应定时器向后移动，否则，执行定时事件
- 处理写事件时，若服务器通过某连接给浏览器发送数据，将对应定时器向后移动，否则，执行定时事件

**有小伙伴问，连接资源中的address是不是有点鸡肋？**

确实如此，项目中虽然对该变量赋值，但并没有用到。类似的，可以对比HTTP类中address属性，只在日志输出中用到。

但不能说这个变量没有用，因为我们可以找到客户端连接的ip地址，用它来做一些业务，比如通过ip来判断是否异地登录等等。

**这个基于升序双向链表实现的定时器存在着其固有缺点：**

- 每次遍历添加和修改定时器的效率偏低(O(n))，使用最小堆结构可以降低时间复杂度降至(O(logn))。
- 每次以固定的时间间隔触发`SIGALRM`信号，调用`tick`函数处理超时连接会造成一定的触发浪费，举个例子，若当前的`TIMESLOT=5`，即每隔5ms触发一次`SIGALRM`，跳出循环执行`tick`函数，这时如果当前即将超时的任务距离现在还有`20ms`，那么在这个期间，`SIGALRM`信号被触发了4次，`tick`函数也被执行了4次，可是在这4次中，前三次触发都是无意义的。对此，我们可以动态的设置`TIMESLOT`的值，每次将其值设置为**当前最先超时的定时器与当前时间的时间差**，这样每次调用`tick`函数，超时时间最小的定时器必然到期，并被处理，然后在从时间堆中取一个最先超时的定时器的时间与当前时间做时间差，更新`TIMESLOT`的值。

### 8. 数据库登录注册

#### (1) 什么是数据库连接池

​		池是一组资源的集合，这组资源在服务器启动之初就被完全创建好并初始化。通俗来说，池是资源的容器，本质上是对资源的复用。顾名思义，连接池中的资源为一组数据库连接，由程序动态地对池中的连接进行使用，释放。

​		当系统开始处理客户请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配；当服务器处理完一个客户连接后,可以把相关的资源放回池中，无需执行系统调用释放资源。

#### (2) 数据库访问的一般流程

​		当系统需要访问数据库时，先系统创建数据库连接，完成数据库操作，然后系统断开数据库连接。

#### (3) 连接池的创建

​		从一般流程中可以看出，若系统需要频繁访问数据库，则需要频繁创建和断开数据库连接，而创建数据库连接是一个很耗时的操作，也容易对数据库造成安全隐患。

​		在程序初始化的时候，集中创建多个数据库连接，并把他们集中管理，供程序使用，可以保证较快的数据库读写速度，更加安全可靠。

​		池可以看做资源的容器，所以多种实现方法，比如数组、链表、队列等。这里，**使用单例模式和链表创建数据库连接池，实现对数据库连接资源的复用。**

​		项目中的数据库模块分为两部分，其一是数据库连接池的定义，其二是利用连接池完成登录和注册的校验功能。具体的，工作线程从数据库连接池取得一个连接，访问数据库中的数据，访问完毕后将连接交还连接池。

​		**RAII机制释放数据库连接**，描述连接释放的封装逻辑。

##### 单例模式创建

​		使用**局部静态变量懒汉模式**创建连接池。

##### 连接池代码实现

​		连接池的功能主要有：初始化，获取连接、释放连接，销毁连接池。

**初始化**

​		值得注意的是，销毁连接池没有直接被外部调用，而是通过**RAII机制**来完成自动释放；使用信号量实现多线程争夺连接的同步机制，这里将信号量初始化为数据库的连接总数。

**获取、释放连接**

​		当线程数量大于数据库连接数量时，使用**信号量**进行同步，每次取出连接，信号量原子减1，释放连接原子加1，若连接池内没有连接了，则阻塞等待。

​		另外，由于多线程操作连接池，会造成竞争，这里使用**互斥锁**完成同步，具体的同步机制均使用lock.h中封装好的类。

**销毁连接池**

​		通过迭代器遍历连接池链表，关闭对应数据库连接，清空链表并重置空闲连接和现有连接数量。

##### RAII机制释放数据库连接

​		将数据库连接的获取与释放通过RAII机制封装，避免手动释放。

​		在获取连接时，通过有参构造对传入的参数进行修改。其中数据库连接本身是指针类型，所以参数需要通过双指针才能对其进行修改。不直接调用获取和释放连接的接口，将其封装起来，通过RAII机制进行获取和释放。

### 9. 日志系统

#### (1) 概念

- **日志**
  - 由服务器自动创建，并记录运行状态，错误信息，访问数据的文件。
- **同步日志**
  - 日志写入函数与工作线程串行执行，由于涉及到I/O操作，当单条日志比较大的时候，同步模式会阻塞整个处理流程，服务器所能处理的并发能力将有所下降，尤其是在峰值的时候，写日志可能成为系统的瓶颈。
- **异步日志**
  - 将所写的日志内容先存入阻塞队列，写线程从阻塞队列中取出内容，写入日志。
  - 其中异步写入方式，将生产者-消费者模型封装为阻塞队列，创建一个写线程，工作线程将要写的内容push进队列，写线程从队列中取出内容，写入日志文件。
  - **生产者-消费者模型**
    - 并发编程中的经典模型。以多线程为例，为了实现线程间数据同步，生产者线程与消费者线程共享一个缓冲区，其中生产者线程往缓冲区中push消息，消费者线程从缓冲区中pop消息。
    - 生产者和消费者是互斥关系，两者对缓冲区访问互斥，同时生产者和消费者又是一个相互协作与同步的关系，只有生产者生产之后，消费者才能消费。当队列为空时，从队列中获取元素的线程将会被挂起；当队列是满时，往队列里添加元素的线程将会挂起。
  - **阻塞队列**
    - 将生产者-消费者模型进行封装，使用循环数组实现队列，作为两者共享的缓冲区。
- **单例模式**
  - 最简单也是被问到最多的设计模式之一，**保证一个类只创建一个实例，同时提供全局访问的方法。**

#### (2) 单例模式

- **单例模式**
  - 单例模式作为最常用的设计模式之一，保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。
- **实现思路**
  - 私有化它的构造函数，以防止外界创建单例类的对象；使用类的私有静态指针变量指向类的唯一实例，并用一个公有的静态方法获取该实例。
- **实现方法**
  - **懒汉模式**
    - 顾名思义，懒汉模式，即非常懒，不用的时候不去初始化，所以在第一次被使用时才进行初始化；
    - **经典的线程安全懒汉模式**
      - 使用**双检测锁模式**。 使用的时候需要加锁
      - **为什么要用双检测，只检测一次不行吗？**如果只检测一次，在每次调用获取实例的方法时，都需要加锁，这将严重影响程序性能。双层检测可以有效避免这种情况，仅在第一次创建单例的时候加锁，其他时候都不再符合NULL == p的情况，直接返回已创建好的实例。
    - **局部静态变量之线程安全懒汉模式**
      - 前面的双检测锁模式，写起来不太优雅，另一种更优雅的单例模式实现，使用函数内的局部静态对象，这种方法不用加锁和解锁操作。
      - **这种方法不加锁会不会造成线程安全问题？**如果使用C++11之前的标准，还是需要加锁，这里同样给出加锁的版本。
  - **饿汉模式**
    - 饿汉模式，即迫不及待，在程序运行时立即初始化。
    - 饿汉模式不需要用锁，就可以实现线程安全。原因在于，在程序运行时就定义了对象，并对其初始化。之后，不管哪个线程调用成员函数getinstance()，都只不过是返回一个对象的指针而已。所以是线程安全的，不需要在获取实例的成员函数中加锁。
    - 饿汉模式虽好，但其存在隐藏的问题，在于非静态对象（函数外的static对象）在不同编译单元中的初始化顺序是未定义的。如果在初始化完成之前调用getInstance() 方法会返回一个未定义的实例。

#### (3) 线程间的通知机制

- **条件变量**
  - 条件变量提供了一种线程间的通知机制，当某个共享数据达到某个值时,唤醒等待这个共享数据的线程。
- **使用前要加锁，为什么要加锁？**
  - 线程访问，为了避免资源竞争，所以要加锁，使得每个线程互斥的访问公有资源。
- **pthread_cond_wait内部为什么要解锁？**
  - 如果while或者if判断的时候，满足执行条件，线程便会调用pthread_cond_wait阻塞自己，此时它还在持有锁，如果他不解锁，那么其他线程将会无法访问公有资源。
  - 具体到pthread_cond_wait的内部实现，当pthread_cond_wait被调用线程阻塞的时候，pthread_cond_wait会自动释放互斥锁。
- **为什么要把调用线程放入条件变量的请求队列后再解锁？**
  - 线程是并发执行的，如果在把调用线程A放在等待队列之前，就释放了互斥锁，这就意味着其他线程比如线程B可以获得互斥锁去访问公有资源，这时候线程A所等待的条件改变了，但是它没有被放在等待队列上，导致A忽略了等待条件被满足的信号。
  - 倘若在线程A调用pthread_cond_wait开始，到把A放在等待队列的过程中，都持有互斥锁，其他线程无法得到互斥锁，就不能改变公有资源。
- **为什么最后还要加锁？**
  - 将线程放在条件变量的请求队列后，将其解锁，此时等待被唤醒，若成功竞争到互斥锁，再次加锁。
- **为什么判断线程执行的条件用while而不是if？**
  - 一般来说，在多线程资源竞争的时候，在一个使用资源的线程里面（消费者）判断资源是否可用，不可用，便调用pthread_cond_wait，在另一个线程里面（生产者）如果判断资源可用的话，则调用pthread_cond_signal发送一个资源可用信号。
  - 在wait成功之后，资源就一定可以被使用么？答案是否定的，如果同时有两个或者两个以上的线程正在等待此资源，wait返回后，资源可能已经被使用了。
  - 再具体点，有可能多个线程都在等待这个资源可用的信号，信号发出后只有一个资源可用，但是有A，B两个线程都在等待，B比较速度快，获得互斥锁，然后加锁，消耗资源，然后解锁，之后A获得互斥锁，但A回去发现资源已经被使用了，它便有两个选择，一个是去访问不存在的资源，另一个就是继续等待，那么继续等待下去的条件就是使用while，要不然使用if的话pthread_cond_wait返回后，就会顺序执行下去。
  - 如果只有一个消费者，那么使用if是可以的。

#### (4) 日志类的定义与使用

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBEOjicsa8vpoLAlODicrC7AoM1h2eq9sDMdQY8TNYQoVckCRDd0m8SDH1myuB4gEJfejvznfZuJ3cpQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

- **日志文件**

  - 局部变量的懒汉模式获取实例

  - 生成日志文件，并判断同步和异步写入方式
    - 写入方式通过初始化时**是否设置队列大小**（表示在队列中可以放几条数据）来判断，若队列大小为0，则为同步，否则为异步。

- **同步**

  - 判断是否分文件

  - 直接格式化输出内容，将信息写入日志文件

- **异步**

  - 判断是否分文件

  - 格式化输出内容，将内容写入阻塞队列，创建一个写线程，从阻塞队列取出内容写入日志文件

##### **日志分级与分文件**

日志分级的实现大同小异，一般的会提供五种级别，具体的，

- Debug，调试代码时的输出，在系统实际运行时，一般不使用。
- Warn，这种警告与调试时终端的warning类似，同样是调试代码时使用。
- Info，报告系统当前的状态，当前执行的流程或接收的信息等。
- Error和Fatal，输出系统的错误信息。

上述的使用方法仅仅是个人理解，在开发中具体如何选择等级因人而异。项目中给出了除Fatal外的四种分级，实际使用了Debug，Info和Error三种。

超行、按天分文件逻辑，具体的，

- 日志写入前会判断当前day是否为创建日志的时间，行数是否超过最大行限制

- - 若为创建日志时间，写入日志，否则按当前时间创建新log，更新创建时间和行数
  - 若行数超过最大行限制，在当前日志的末尾加count/max_lines为后缀创建新log

将系统信息格式化后输出，具体为：格式化时间 + 格式化内容

### 10. 压测

**Webbench是什么，介绍一下原理**
父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。

|                      | 1000                                       | 9500                                       |
| -------------------- | ------------------------------------------ | ------------------------------------------ |
| LT+LT reactor        | 668904<br />684024<br />681768             | 349644<br />353340<br />586548             |
| **LT + ET reactor**  | 634344<br />681576<br />694224             | 577452<br />594252<br />474588             |
| ET + LT reactor      | 594096<br />602220<br />596412             | 426960<br />551520<br />460716             |
| ET + ET reactor      | 612216<br />603840<br />607500             | 460068<br />510468<br />530616<br />496692 |
| ET + ET  proactor    | 761412<br />837360<br />861972             | 586428<br />782576<br />724884<br />777540 |
| ET + LT proactor     | 875784<br />855684<br />885084             | 589872<br />786828<br />794868             |
| **LT + ET proactor** | 848988<br />846168<br />823164             | 772500<br />701388<br />796200             |
| LT + LT proactor     | 791040<br />825528<br />856428<br />875868 | 714480<br />780768<br />695292             |



### 11. 概念



