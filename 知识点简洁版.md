### 1  C++

#### 1. C++和C的关系（区别）

​		① C++是C语言的增强，在C语言的基础上增加了面向对象编程和泛型编程的支持，并且可以很好兼容C语言。

​		② C++是面向对象的编程语言，具有封装、继承、多态的特性，减少了重复代码的重写的过程；C语言是面向过程的语言，根据业务逻辑从上到下编写代码。

​		③ C++增加了很多特性来改善安全性，如const常量、引用、cast转换、智能指针等

​		④ C++引入了模板库的概念，实现了方便开发的STL，相对于C语言更加灵活通用。

​		⑤ C++支持函数重载，C++和C语言对同一个函数编译后的函数名是不一样的，C++会加上参数类型。

#### 2. 面向对象的三大特性

​		① 封装：把**客观事实**封装成类，也就是将属性和操作合成一个整体，可以作为对象使用，程序是由多个对象组成，并且可以进行访问控制

​		② 继承：一个类可以继承另一个类的属性和操作，并且可以对其进行拓展

​		③ 多态：一个接口，多种方法。函数重载和运算符重载实现**编译时多态**，虚函数和派生类实现**运行时多态**。

#### 3. C++对C的扩展

​		(1) 检测：全局变量检测增强；函数检测增强（参数类型、参数个数、返回值）；类型检测增强（变量、函数必须有类型，类型转换更加严格）

​		(2) 作用域：C++可以在使用时再定义变量，C语言是在作用域开始时定义；引入作用域运算符::，命名空间namespace using 可以区分全局变量和局部变量

​		(3) 类型：增加bool类型；struct类型增强（定义时，可以包含函数，增加访问权限控制和继承多态特性；使用时，不用加struct可以直接使用）

​		(4) 运算符：三目运算符增强（返回的不是值而是地址）

​		(5) 关键字：register关键字增强（可以取地址，但取地址时失效，有自己的优化方式）；

​							 const常量（定义时必须初始化，取代define宏定义变量时，不必分配内存空间，若extern或取地址则分配）

​		(6) 引用：必须初始化；不能直接对数组引用；常量引用作为函数形参使用，函数只能返回静态变量的引用；本质是一个指针常量

​		(7) 内联函数：取代宏函数，由编译器处理，直接将编译后的函数插入调用的地方（宏函数由预处理器处理）；函数声明和函数体必须在一起

​		(8) 函数：默认参数、占位参数、函数重载

#### 4. 关键字

##### (1) static 静态

​		静态变量只能在本源文件中使用，不加static的全局变量和函数具有全局可见性。

​		**非类：**全局静态变量、局部静态变量（作用域不一样，函数退出后仍然存在，但不能使用）、静态函数

​		**类：**静态成员变量、静态成员函数（实现类对象的共享）

##### (2) const 常量

​		它用来限定一个变量不允许改变，它将一个对象转换成一个常量。

​		定义时必须初始化、替代宏定义、内存分配：一般不分配内存，若使用extern或者取地址 (用一个变量初始化、自定数据类型) 时会分配内存

​		**mutable**  突破const的限制

##### (3) volatile

​		类型修饰符，防止优化编译器把变量从内存装入CPU寄存器，系统总是从内存读取数据，多线程中被几个任务共享的变量定义为volatile

##### (4) explicit

​		修饰类的单个参数的构造函数，不能发生隐式类型转换

#### 5. 宏定义、内联函数、常量

​		**宏函数（define）：**只是把宏名用宏体替代，字符串的替代，不检查语法错误，不检查参数类型

​		**内联函数（inline）：**是编译器将函数插入到调用的地方，且有返回值，有参数类型的检查（避免了函数调用的开销，用空间换时间）

​		**宏常量：**只做替换，不做类型的检查和计算，不分配内存空间。

​		**const常量：**有数据类型，会做类型检查和计算，取地址或者extern时会分配内存空间。

#### 6. 深拷贝和浅拷贝

​		浅拷贝：只是拷贝一个指针，拷贝的指针和原来的指针指向同一块地址，如果原指针指向的资源被释放了，再释放浅拷贝指针指向的资源就会出现错误

​		深拷贝：不仅拷贝值，还开辟一块新的内存空间存放这个值

#### 7.指针

##### (1) 常量指针和指针常量

​		指针常量是一个指向常量的指针，可以修改指针指向；常量指针是一个不能改变指向的指针，可以修改变量值。

##### (2) 数组名和指针

​		两者均可以通过增减偏移量来访问数组中的数据

​		数组名不是真正意义上的指针，可以理解为常指针，不能做自增自减操作，当数组名当作形参传递给函数时，会退化为一般指针，多了自增自减操作。

##### (3) 野指针和悬空指针

​		都是指向无效内存区域的指针，访问行为会导致未定义行为

​		**野指针：**没有被初始化的指针；解决：定义指针变量及时初始化，要么置空

​		**悬空指针：**指针最初指向的内存已经被释放了；解决：free或delete后立即置空。

##### (4) 函数指针和指针函数

​		函数指针：指向函数的指针变量（函数的入口地址）；应用场景：回调（别人的库里调用我们的函数）

​		指针函数：是一个函数，返回值为指针

##### (5) 指针和引用的区别

​		① 指针是一个具体变量，存储的是指向变量的地址，引用本质是一个常量指针，代表的是指向变量的别名

​		② 指针可以为空，可以用NULL初始化指针；引用不能为空，并且必须初始化；指针可以在初始化之后改变指向，引用不可以

​		③ 指针可以多级，引用不可以

​		④ 函数传参时，指针是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一变量指针，若在函数内改变指针的指向不影响实参，但引用变量的地址还是原变量的地址。

##### (6) 使用函数过程中，什么时候该使用指针、引用？

​		① 对栈的大小比较敏感的时候用引用（如递归）使用引用不用创造临时变量，开销要小，但指针需要创造临时变量

​		② 类对象作为函数形参时要使用引用，这是标准方式。

#### 8. class和struct的异同

​		相同： class和struct都有成员变量和成员函数，都有权限访问控制，有继承和多态

​		不同： ① struct一般作为数据结构的集合，class是作为属性和操作封装的对象

​					② struct的默认访问权限是public、class是private；struct默认是公有继承、class默认是私有继承

​					③ struct**不能作为定义模板参数**，class可以

#### 9. 构造函数和析构函数

​		**构造函数：**创建对象时为对象成员属性赋值，如果成员是const、引用或者某种未提供默认构造类型的类类型，通过构造函数**初始值列表**初始化；

​							没有返回值，由编译器自动调用，可以重载

​							分为有参构造函数、无参构造函数（默认构造函数）、拷贝构造函数、移动构造函数（都是用一个对象的值设置另一个对象的值）

​		**析构函数：**对象销毁前系统自动调用，执行清理工作，没有返回值，不能有参数，不能重载

​		（必须写在public下才能调用到）

​		**拷贝构造函数：**是对非静态成员的浅拷贝，如果析构函数释放堆中成员变量时，这个成员变量已经被释放了，就会释放堆空间两次，造成重复释放内存错误。

​									解决方法：① 显示提供拷贝构造函数，分配内存空间，实现深拷贝；重载 = 操作，不使用系统提供的浅拷贝。

​									调用：用已经创建好的对象去初始化新对象；作为函数的形参，以值传递的方式给函数形参传值。

​		**移动构造函数：**是对象值得真实转移，原对象将失去内容，被目标对象占用，不用分配新内内存，节省拷贝时间和内存

​									不同：拷贝构造函数的形参是一个左值引用；移动构造函数的形参是一个右值引用（只能赋值和销毁）。

#### 10. 动态对象创建

​		**(1) malloc + free**：必须确定对象长度；返回(void *)类型，C++必须强转；必须判断返回值来确认是否创建成功；使用对象前必须初始化因为不调用构造函数

​		**(2) new + delete**：new先分配内存，然后调用构造函数；delete先调用析构函数，再释放内存。是运算符，堆区开辟。

​										 当创建一个对象数组时，必须对每个对象调用构造函数，需要提供一个默认的构造函数。

#### 11. 类的成员

​		(1) 成员变量：普通成员变量、静态成员变量

​		(2) 成员函数：普通成员函数、静态成员函数、虚函数、构造函数、析构函数

##### static静态成员

​		**static成员变量**：属于某个类，类对象之间共享；**类内声明，类外定义（除const）**；可以通过类名直接调用

​		**static成员函数**：只能访问静态成员变量，不能访问普通成员变量；普通成员函数都可以访问（不能声明为const，虚函数和volatile）

##### const 常量修饰

​		**const static成员变量：**类内初始化；实现类对象间的共享常量，不能改变。

​		**const成员函数**：const修饰的是this指针指向的内存区域，**不能修改**任何普通成员变量，但用**mutable**修饰的例外。

​		**const对象**：const对象不能调用普通成员函数，只能调用const成员变量函数；可以访问成员变量，不能修改，但用**mutable**修饰的例外。

##### this指针

​		当调用一个对象的非静态成员时，系统会把**该对象的起始指针**给成员函数的this指针。静态成员函数没有this指针，不能操作非静态成员变量。

​		当形参和成员变量重名时，可以用this指针来区分；若需要返回对象本身，可以用 return *this;

##### 可以定义引用数据成员吗

​		可以，但是要遵循以下三个原则：必须提供构造函数来初始化引用成员变量，构造函数的形参必须是引用，必须在初始化列表中初始化。

#### 12. friend友元

​		友元函数是一种特权函数，可以访问其他类的私有成员。

​		① friend关键字只出现在声明处，其他类，类成员函数，全局函数都可以声明为友元。

​		② 友元函数不是类的成员，没有this指针

​		③ 友元关系是单向的，不具有传递性，不能被继承

#### 13. 运算符重载

​		目的：自定义数据类型可以进行运算；一般一元运算符用成员函数重载，二元函数用全局函数+友元

​				= [] () -> 只能用成员函数重载

​				>> << 只能通过全局+友元

​				++通过占位参数进行前置和后置重载

​				不能重载&& ||

#### 14. 继承和派生

​		三种**继承方式**

​		**构造函数：**子类对象在创建时先调用父类的构造函数再调用子类的，析构顺序相反；若父类构造函数有参，子类需要在初始化初始列表显示调用父类构造函数

​		**同名成员：**默认访问子类的，可以用::访问父类的；若子类重载了基类函数，则其他类型的被隐藏。

​		**多继承带来的问题：**若函数同名，则无法分清父类是谁，必须显示指定调用哪个基类

​		**菱形继承和虚继承：**两个派生类继承一个基类，又有某个类继承这两个派生类；**问题**：对基类成员访问不明确，重复继承（浪费存储空间）

​											采用**虚基类**：使用virtual修饰继承的父类，具体实现是一个虚基类指针，指向一张虚基类表。不能解决没有公共祖先你的多继承。

#### 15. 多态

​		**虚函数virtual：**允许子类重写（覆盖）父类方法，用于通过父类的指针或引用指向子类对象的方法。 不能虚构造函数。

​		**如何实现动态绑定：**当编译器发现类中有虚函数时，编译器会为这个类建立一张虚函数表，把每个虚函数的入口地址放到虚函数表中，并且在类中加一个指针指向虚函数表，在多态调用的时候，会根据指针找到虚函数来实现动态绑定。

​											虚函数表是在编译阶段生成，对象内存空间开辟后，写入指向虚函数表的指针(vptr指针)，然后再调用构造函数

​		**向上类型转换**：对象可以作为它自己的类或者它的基类的对象来使用，能通过基类的地址来操作它。

​		**纯虚函数：**是在基类中声明的虚函数，在基类中没有定义，要求派生类要定义自己的实现方法，告诉编译器留个位置，但不放地址

​		**抽象类**：希望基类只是派生类的一个接口，在基类中加入至少一个纯虚函数，这个基类就被称为抽象类，不能被实例化。

​		**虚析构函数**：为了解决普通构造函数不能调用子类的析构。  **纯虚析构函数**：必须提供函数体，**类内声明，类外实现**。

##### 为什么不能虚构造函数

​		构造函数是创建对象时，系统自动调用的，不能通过父类指针或引用调用；虚函数表在构造函数调用前创建。

##### 重写 重载 重定义

​		重写：覆盖，子类重写父类的虚函数，函数返回值，参数、函数名字必须一致

​		重载：同一作用域的同名函数；参数个数、参数类型、参数顺序不同

​		重定义：隐藏，子类继承父类的同名非虚函数

##### 不能声明为虚函数

​		非成员函数、静态成员函数、内联成员函数、构造函数、友元函数（没有继承特性）

#### 16. STL标准模板库

##### 组成部分

​		广义上分为三种：算法、容器、迭代器

​		详细：算法、容器（数据结构）、适配器、迭代器、仿函数、空间配置器

**容器底层结构和特点**

​		**vector**：(线性)数组，支持快速随机访问         迭代器：随机访问迭代器    

​		**list**：双向链表，支持快速增删                          迭代器：双向迭代器         空间配置器：alloc

​		**deque**：双向队列（内部有一个指针指向map，每个元素作为一个节点指向较大连续空间的缓冲区）list+vector    迭代器：随机访问迭代器    

​		**set：**红黑树、有序、不重复                            不允许迭代器修改元素的值          迭代器：双向迭代器   

​				multiset：红黑树，有序，可重复                                                                    迭代器：双向迭代器   

​				unordered_set：hash表，无序，不重复                                                       迭代器：前向迭代器   

​				unordered_multiset：hash表，无序，可重复                                              迭代器：前向迭代器   

​		**map：**红黑树，有序，不重复                       空间配置器：alloc                            迭代器：双向迭代器   

​				multimap： 红黑树，有序，可重复                                                                 迭代器：双向迭代器   

​				unordered_map：hash表，无序，不重复                                                     迭代器：前向迭代器   

​				unordered_multimap：hash表，无序，可重复                                            迭代器：前向迭代器   

**容器适配器**

​		**stack**：deque或者list实现，封闭头部即可；不用vector的原因应该是容量大小有限制，扩容耗时；不具有遍历功能，没有迭代器。

​		**queue**：deque或者list实现；不用vector的原因应该是容量大小有限制，扩容耗时；不具有遍历功能，没有迭代器。

​		**heap**：heap算法常见有的插入、弹出、排序和构造算法；使用一个array和一组heap算法来实现大根堆和小根堆。

​		**priority_queue**：vector，堆heap为处理规则来管理底层容器实现；它没有遍历功能，也不提供迭代器

##### 红黑树

​		红黑树的查询和维护时间复杂度均为$O(logn)$，但是空间占用比较大，因为每个节点要保持父节点、孩子节点及颜色的信息

- 是二叉搜索树

- 每个节点不是红色就是黑色

- 根结点为黑色

- 如果节点为红色，其子节点必为黑

- 任一节点至（NULL）树尾端的任何路径，所含的黑节点数量必相同

#### 17. C++11新特性

（1）统一的初始化方法：初始化列表可以用于任何类型对象的初始化

（2）成员变量默认初始化：构建一个类的对象不需要用构造函数初始化成员变量

（3）**auto**：用于定义**变量**，编译器可以自动判断的类型（前提：定义一个变量时对其进行初始化）（迭代器）

（4）**decltype**：求**表达式**的类型，都用来在编译时期进行自动类型推导。

（5）智能指针 **shared_ptr**：多个 shared_ptr 智能指针可以共同使用同一块堆内存。

（6）空指针 **nullptr**（原来NULL 现在NULL=0）：用于初始化空类型指针，可以被隐式转换成任意的指针类型

（7）基于范围的for循环

（8）右值引用**&&**和**move**语义：move就是将某个左值强制转化为右值

​			右值引用也必须立即进行初始化操作，且只能使用右值进行初始化， 和常量左值引用不同的是，右值引用还可以对右值进行修改。

（9）无序容器（哈希表）：用法和功能同map一模一样，区别在于哈希表的效率更高

（10）正则表达式：可以认为正则表达式实质上是一个字符串，该字符串描述了一种特定模式的字符串

（11）Lambda表达式：可以编写内嵌的匿名函数；当定义一个lambda后，编译器会自动生成一个匿名类，我们称为闭包类型；

​										 [外部变量访问方式说明符] (参数) mutable noexcept/throw() -> 返回值类型     {      函数体;     };

#### 18. 智能指针

​		智能指针是一个类，用来存储指向动态分配对象的指针，**负责自动释放动态分配的对象，防止堆内存泄漏**。动态分配的资源，交给一个类对象去管理，当类对象声明周期结束时，自动调用析构函数释放资源。

##### (1) 智能指针和指针的区别

1. 智能指针

   ​		如果在程序中使用new从堆（自由存储区）分配内存，等到不需要时，应使用delete将其释放。C++引用了智能指针auto_ptr，以帮助自动完成这个过程。C++11摒弃了auto_ptr，并新增了三种智能指针：unique_ptr、shared_ptr和weak_ptr。所有新增的智能指针都能与STL容器和移动语义协同工作。

2. 指针

   ​		C 语言规定所有变量在使用前必须先定义，指定其类型，并按此分配内存单元。指针变量不同于整型变量和其他类型的变量，它是专门用来存放地址的，所以必须将它定义为“指针类型”。

3. 智能指针和普通指针的区别

    		**智能指针和普通指针的区别**在于智能指针实际上是对普通指针加了一层封装机制，区别是它**负责自动释放所指的对象**，这样的一层封装机制的目的是为了使得智能指针**可以方便的管理一个对象的生命期**。

##### (2) 为什么要使用智能指针

1. C++中的智能指针有4种，分别为：**shared_ptr、unique_ptr、weak_ptr、auto_ptr**，其中auto_ptr被C++11弃用。  

2. **为什么要使用智能指针**：智能指针的作用是管理一个指针，**因为存在申请的空间在函数结束时忘记释放，造成内存泄漏的情况**。使用智能指针可以很大程度上避免这个问题，因为智能指针就是一个类，当超出了类的作用域时，类会自动调用析构函数，自动释放资源。  		


##### (3) 智能指针内存泄露

1. 智能指针发生内存泄露的情况

   ​		当两个对象同时使用一个shared_ptr成员变量指向对方，会造成**循环引用**，使引用计数失效，从而导致内存泄露。

2. 智能指针的内存泄漏如何解决？ 

   ​		为了解决循环引用导致的内存泄漏，引入了弱指针weak_ptr，weak_ptr的构造函数不会修改引用计数的值，从而不会对对象的内存进行管理，其类似一个普通指针，但是不会指向引用计数的共享内存，但是可以检测到所管理的对象是否已经被释放，从而避免非法访问。

##### (4) 四个智能指针

**(1) auto_ptr** 

​		主要是为了解决“有异常抛出时发生内存泄漏”的问题 。因为发生异常而无法正常释放内存。

​		auto_ptr有拷贝语义，拷贝后源对象变得无效，这可能引发很严重的问题；而unique_ptr则无拷贝语义，但提供了移动语义，这样的错误不再可能发生，因为很明显必须使用std::move()进行转移。

​		auto_ptr不支持拷贝和赋值操作，不能用在STL标准容器中。STL容器中的元素经常要支持拷贝、赋值操作，在这过程中auto_ptr会传递所有权，所以不能在STL中使用。

​		auto指针存在的问题是，两个智能指针同时指向一块内存，就会两次释放同一块资源，自然报错。

**(2) shared_ptr** 

​		采用**引用计数器**的方法，允许多个智能指针指向同一个对象，每当多一个指针指向该对象时，指向该对象的所有智能指针内部的引用计数加1，每当减少一个智能指针指向对象时，引用计数会减1，当计数为0的时候会自动的释放动态分配的资源。 

​		 **实现原理：**有一个引用计数的指针类型变量，专门用于引用计数，使用拷贝构造函数和赋值拷贝构造函数时引用计数加1，当引用计数为0时释放资源。

**(3) unique_ptr** 

​		unique_ptr采用的是独享所有权语义，一个非空的unique_ptr总是拥有它所指向的资源。转移一个unique_ptr将会把所有权全部从源指针转移给目标指针，源指针被置空；所以unique_ptr不支持普通的拷贝和赋值操作，不能用在STL标准容器中；局部变量的返回值除外（因为编译器知道要返回的对象将要被销毁）；如果你拷贝一个unique_ptr，那么拷贝结束后，这两个unique_ptr都会指向相同的资源，造成在结束时对同一内存指针多次释放而导致程序崩溃。

​		  unique指针规定一个智能指针独占一块内存资源。当两个智能指针同时指向一块内存，编译报错。

​		  **实现原理：**将拷贝构造函数和赋值拷贝构造函数申明为private或delete。不允许拷贝构造函数和赋值操作符，但是支持移动构造函数，通过std:move把一个对象指针变成右值之后可以移动给另一个unique_ptr

**(4) weak_ptr** 

​		weak_ptr：弱引用。 引用计数有一个问题就是互相引用形成环（环形引用），这样两个指针指向的内存都无法释放。需要使用weak_ptr打破环形引用。weak_ptr是一个弱引用，它是为了配合shared_ptr而引入的一种智能指针，它指向一个由shared_ptr管理的对象而不影响所指对象的生命周期，也就是说，它只引用，不计数。如果一块内存被shared_ptr和weak_ptr同时引用，当所有shared_ptr析构了之后，不管还有没有weak_ptr引用该内存，内存也会被释放。所以weak_ptr不保证它指向的内存一定是有效的，在使用之前使用函数lock()检查weak_ptr是否为空指针。

**weak_ptr 能不能知道对象计数为 0，为什么？**

​		  不能。 weak_ptr是一种不控制对象生命周期的智能指针，它指向一个shared_ptr管理的对象。进行该对象管理的是那个引用的shared_ptr。weak_ptr只是提供了对管理 对象的一个访问手段。weak_ptr设计的目的只是为了配合shared_ptr而引入的一种智能指针，配合shared_ptr工作，它只可以从一个shared_ptr或者另一个weak_ptr对象构造，**它的构造和析构不会引起计数的增加或减少**。

**weak_ptr 如何解决 shared_ptr 的循环引用问题？**

​		为了解决循环引用导致的内存泄漏，引入了弱指针weak_ptr，weak_ptr的构造函数不会修改引用计数的值，从而不会对对象的内存进行管理，其类似一个普通指针，但是不会指向引用计数的共享内存，但是可以检测到所管理的对象是否已经被释放，从而避免非法访问。

##### (5) 智能指针的作用

1)  C++11中引入了智能指针的概念，方便管理堆内存。使用普通指针，容易造成堆内存泄露（忘记释放），二次释放，程序发生异常时内存泄露等问题等，使用智能指针能更好的管理堆内存。

2)  智能指针在C++11版本之后提供，包含在头文件\<memory>中，shared_ptr、unique_ptr、weak_ptr。shared_ptr多个指针指向相同的对象。shared_ptr使用引用计数，每一个shared_ptr的拷贝都指向相同的内存。每使用他一次，内部的引用计数加1，每析构一次，内部的引用计数减1，减为0时，自动删除所指向的堆内存。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。

3)  初始化。智能指针是个模板类，可以指定类型，传入指针通过构造函数初始化。也可以使用make_shared函数初始化。不能将指针直接赋值给一个智能指针，一个是类，一个是指针。

拷贝和赋值。拷贝使得对象的引用计数增加1，赋值使得原对象引用计数减1，当计数为0时，自动释放内存。后来指向的对象引用计数加1，指向后来的对象

4)  unique_ptr“唯一”拥有其所指对象，同一时刻只能有一个unique_ptr指向给定对象（通过禁止拷贝语义、只有移动语义来实现）。相比与原始指针unique_ptr用于其RAII的特性，使得在出现异常的情况下，动态资源能得到释放。unique_ptr指针本身的生命周期：从unique_ptr指针创建时开始，直到离开作用域。离开作用域时，若其指向对象，则将其所指对象销毁(默认使用delete操作符，用户可指定其他操作)。unique_ptr指针与其所指对象的关系：在智能指针生命周期内，可以改变智能指针所指对象，如创建智能指针时通过构造函数指定、通过reset方法重新指定、通过release方法释放所有权、通过移动语义转移所有权。

5)  智能指针类将一个计数器与类指向的对象相关联，引用计数跟踪该类有多少个对象共享同一指针。每次创建类的新对象时，初始化指针并将引用计数置为1；当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数；对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。

6)  weak_ptr 是一种不控制对象生命周期的智能指针, 它指向一个 shared_ptr 管理的对象. 进行该对象的内存管理的是那个强引用的 shared_ptr. weak_ptr只是提供了对管理对象的一个访问手段。weak_ptr 设计的目的是为配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作, 它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造, 它的构造和析构不会引起引用记数的增加或减少. 

##### (6) 手写实现智能指针类

​		智能指针是一个数据类型，一般用模板实现，模拟指针行为的同时还提供自动垃圾回收机制。它会自动记录SmartPointer<T*>对象的引用计数，一旦T类型对象的引用计数为0，就释放该对象。

​		除了指针对象外，我们还需要一个引用计数的指针设定对象的值，并将引用计数计为1，需要一个构造函数。新增对象还需要一个构造函数，析构函数负责引用计数减少和释放内存。

​		通过覆写赋值运算符，才能将一个旧的智能指针赋值给另一个指针，同时旧的引用计数减1，新的引用计数加1

​		一个构造函数、拷贝构造函数、复制构造函数、析构函数、移动函数；

#### 19. 四种强转

##### reinterpret_cast

​		retinterpret_cast < type-id > (expression)

​		type-id必须是一个指针、引用、算术类型、函数指针或者成员指针，用于类型之间的强转。

##### const_cast

​		const_cast < type-id > (expression)

​		修饰类型的const/volatile属性，

​		用于常量指针（引用）被转化为非常量指针（引用）并且仍然指向原来的对象；一般用于修改指针 如 const char *p

##### static_cast

​		static_cast < type-id > (expression)

​		把expression转换为 type-id 类型，没有运行时类型检查来保证转换的安全性。

​		用于类层次结构中基类和派生类之间指针或引用的转换；基本数据类型的转换；把空指针转换为目标类型的空指针；把任何类型的表达式转换为void类型

​		注意：static_cast不能转换掉expression的const、volatile、或者__unaligned属性。

##### dynamic_cast

​		type-id 必须是类的指针、类的引用或者void*；如果 type-id 是类指针类型，那么expression也必须是一个指针，如果 type-id 是一个引用，那么 expression 也必须是一个引用

​		dynamic_cast运算符可以在执行期决定真正的类型，也就是说expression必须是多态类型。

​		在类层次间进行上行转换时，dynamic_cast和static_cast的效果是一样的；在进行下行转换时，dynamic_cast具有类型检查的功能，比static_cast更安全

### 2  操作系统

#### 1. 硬件结构

​		**CPU（中央处理器）：**运算器、控制器、寄存器（存储计算时的和数据—通用寄存器、程序计数器、指令寄存器）（内存管理器MMU）（32位CPU管理4G内存）（32位和64位主要区别于一次可以计算多少字节数据）

​				（CPU缓存 L1 cache L2 L3静态随机存储器）

​		**总线：**地址总线（32位CPU32条）、指令总线、数据总线

​		**内存：**数据和程序存储在内存（虚拟内存）（内核区、用户区（固定区（eg栈）、覆盖区（动态内存分配、内存交换）））

​		**硬盘：**固态硬盘SSD、机械硬盘HDD（交换空间、文件空间）

​		**输入输出设备：**键盘、显示屏等，按键通过控制总线与CPU交互

#### 2. 中断和异常

​		外中断：由硬件触发中断（CPU执行指令以外的时间引起）（eg I/O中断，时钟中断）硬中断快速处理

​		软中断：由内核触发中断，异步处理硬中断未完成的工作，处理内核自定义事件，比如内核调度等

​		异常：由CPU执行指令的内部事件引起，比如：非法操作，地址越界，算术溢出

#### 3. 一个程序有哪些section

**从低地址到高地址，一个程序由代码段、数据段(已初始化)、BSS段(未初始化)、堆、共享区、栈等**组成。

1. **代码段：**存放**程序执行代码**的一块内存区域。

2. **数据段：**存放程序中**已初始化的全局变量和静态变量**的一块内存区域。还会包含一些只读的**常数变量**。

3. **BSS** 段：存放程序中**未初始化的全局变量和静态变量**的一块内存区域。

4. 可执行程序在运行时又会多出两个区域：堆区和栈区。

   **堆区：动态申请内存**用。堆从低地址向高地址增长。

   **栈区：**存储**局部变量、函数参数值、返回值**。栈从高地址向低地址增长。是一块连续的空间。 栈的大小是固定的一般是 `8 MB`。系统也提供了参数可改变大小

5. 最后还有一个**共享区**，位于堆和栈之间。  文件映射段，包括动态库、共享内存等，从低地址开始向上增长

   ​	堆和**文件映射段**的内存是动态分配的。比如说，使用 C 标准库的 `malloc()` 或者 `mmap()` ，就可以分别在堆和文件映射段动态分配内存。

#### 4. 为什么要用虚拟内存

​		因为早期的内存分配方法存在以下问题：

（1）**进程地址空间不隔离**。会导致数据被随意修改。

（2）容易产生内存碎片呢，**内存使用效率低**。

（3）程序运行的地址不确定。操作系统**随机**为进程分配内存空间，所以**程序运行的地址是不确定的**。

#### 5. 使用虚拟内存的好处

（1）**扩大地址空间。**每个进程独占一个4G空间，虽然真实物理内存没那么多。

（2）**内存保护**：防止不同进程对物理内存的争夺和践踏，可以对特定内存地址提供写保护，防止恶意篡改。

（3）可以实现**内存共享**，方便进程通信。

（4）可以**避免内存碎片**，虽然物理内存可能不连续，但映射到虚拟内存上可以连续。

#### 6. 操作系统如何管理内存

1. **物理内存**：物理内存有四个层次，分别是寄存器、高速缓存、主存、磁盘。

2. **虚拟内存**：操作系统为每一个进程分配一个独立的地址空间是虚拟内存。

   ​	虚拟内存与物理内存**存在映射关系**，通过**页表寻址**完成虚拟地址和物理地址的转换。

   ​	进程持有的虚拟地址会通过 CPU 芯片中的**内存管理单元（MMU）**的映射关系，来转换变成物理地址，然后再通过物理地址访问内存

#### 7. 虚拟内存管理方式

​		操作系统通过**内存分段**和**内存分页**的方式管理虚拟地址与物理地址之间的关系。

​			**内存分段：**程序是由**若干个逻辑分段**组成的，如可由代码分段、数据分段、栈段、堆段组成。存在**内存碎片**和**内存交换效率低**的问题，就出现了内存分页。

​			**内存分页：**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小，虚拟地址与物理地址之间通过**页表**来映射。

​			**段页式内存管理：**地址结构就由**段号、段内页号和页内位移**三部分组成。

#### 8. 内部碎片与外部碎片

​		**内碎片：**分配给某些进程的内存区域中有些部分没用上**（固定分区分配）**

​		**外碎片：**产生了多个不连续的小物理内存，导致新的程序无法被装载**（分段式存储管理）**

**如何消除碎片文件？**

​		**内碎片：**通过**紧凑技术**消除，就是操作系统不时地对进程进行移动和整理。但是这需要**动态重定位寄存器**地支持，且相对费时

​		**外碎片：**内存交换

#### 9. 分页是怎么解决分段的内存碎片、内存交换效率低的问题

​		（1）由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而采用了分页，那么**释放的内存都是以页为单位释放的**，也就不会产生无法给进程使用的小内存。

​		（2）如果内存空间不够，操作系统会把其他正在运行的进程中的**「LRU最近没被使用」**的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**。一旦需要的时候，再加载进来，称为**换入**。所以，**一次性写入磁盘的也只有少数的一个页或者几个页**，不会花太多时间，内存交换的效率就相对比较高。

​		（3）分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

#### 10. 内存交换和覆盖

​		交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一程序或进程中。

**内存交换**

​		内存空间紧张时，系统将内存中某些进程暂时换出外存（阻塞进程、优先级低的），把外存中某些已具备运行条件的进程换入内存(内存与磁盘间动态调度)

**覆盖**

​		不用将一个进程的全部信息装入内存后才能运行进程，内存分为**固定区**和**覆盖区**。将经常活跃的部分放在固定区，其余部分按照调用关系分段，首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统将其调入覆盖区，替换覆盖区中原有的段。

#### 11. 动态分配内存原理

​		**malloc底层实现：**当开辟的空间小于 128K 时，调用 brk() 函数；当开辟的空间大于 128K 时，调用mmap()。malloc采用的是**内存池**的管理方式，以减少内存碎片。先申请大块内存作为堆区，然后将堆区分为多个内存块。当用户申请内存时，直接从堆区分配一块合适的空闲快。采用**隐式链表**将所有空闲块，每一个空闲块记录了一个未分配的、连续的内存地址。

​		**从操作系统层面上看，malloc是通过两个系统调用来实现的： brk和mmap**

* brk是将进程数据段(.data)的最高地址指针向高处移动，这一步可以扩大进程在运行时的堆大小；(只分配虚拟空间，不对应物理内存(因此没有初始化)，第一次读/写数据时，引起内核**缺页中断**，内核才分配对应的物理内存，然后虚拟地址空间建立映射关系)；**brk分配的内存需要等到高地址内存释放以后才能释放**；

* mmap是在进程的虚拟地址空间中寻找一块空闲的虚拟内存，这一步可以获得一块可以操作的堆内存。**mmap分配的内存可以单独释放**

  ​	通常，分配的内存小于128k时，使用brk调用来获得虚拟内存，大于128k时就使用mmap来获得虚拟内存。

  ​	进程先通过这两个系统调用获取或者扩大进程的虚拟内存，获得相应的虚拟地址，在访问这些虚拟地址的时候，通过**缺页中断**，让内核分配相应的物理内存，这样内存分配才算完成。

#### 12. 动态分区分配算法

##### 1、首次适应算法

- **算法思想：**每次都从低地址开始查找，找到第–个能满足大小的空闲分区。
- **如何实现：**空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链( 或空闲分[表)，找到大小能满足要求的第-一个空闲分区。

##### 2、最佳适应算法

- **算法思想：**由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。
- **如何实现：**空闲分区按容量递增次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

##### 3、最坏适应算法

- **算法思想：**为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。又称最大适应算法(Largest Fit)
- **如何实现：**空闲分区按容量递减次序链接。每次分配内存时顺序查找空闲分区链(或空闲分区表)，找到大小能满足要求的第-一个空闲分区。

##### 4、邻近适应算法

- **算法思想：**首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
- **如何实现：**空闲分区以地址递增的顺序排列(可排成-一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区。

##### 5、总结

​		**首次适应不仅最简单，通常也是最好最快**，不过首次适应算法会使得内存低地址部分出现很多小的空闲分区，而每次查找都要经过这些分区，因此也增加了查找的开销。邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。

​		最佳导致大量碎片，最坏导致没有大的空间。

​		**首次适应**比最佳适应要好，他们都比最坏好。

#### 13. 内存泄露及解决办法

##### ① 什么是内存泄露

​		申请了一块内存空间，使用完毕后没有释放掉，失去了对该段内存的控制。

​		（1）new和malloc申请资源使用后，没有用delete和free释放；

​		（2）子类继承父类时，父类析构函数不是虚函数。

​		（3）Windows句柄资源使用后没有释放。

​		只发生一次小的内存泄漏可能不被注意，但泄漏大量内存的程序将会出现各种证照：性能下降到内存逐渐用完，导致另一个程序失败；

##### ② 怎么避免内存泄露

**避免内存泄露的几种方式**

- 计数法：使用new或者malloc时，让该数+1，delete或free时，该数-1，程序执行完打印这个计数，如果不为0则表示存在内存泄露
- 一定要将基类的析构函数声明为**虚函数**
- 对象数组的释放一定要用**delete []**
- 有new就有delete，有malloc就有free，保证它们一定成对出现

**解决方法**

​		智能指针

**检测工具**

- Linux下可以使用**Valgrind工具**
- Windows下可以使用**CRT库**

#### 14. 堆和栈的区别

​		**(1) 堆栈空间分配不同**。栈由操作系统自动分配释放 ，存放函数的参数值，局部变量的值等；堆一般由程序员分配释放。

​		**(2) 堆栈缓存方式不同**。栈使用的是一级缓存， 它们通常都是被调用时处于存储空间中，调用完毕立即释放；堆则是存放在二级缓存中，速度要慢些。

​		**(3) 堆栈数据结构不同**。堆类似数组结构；栈类似栈结构，先进后出。

​		**(4) 申请大小限制不同。**栈顶和栈底是之前预设好的，栈是向栈底扩展，大小固定，可以通过ulimit -a查看，由ulimit -s修改。堆向高地址扩展，是不连续的内存区域，大小可以灵活调整。栈空间默认是4M, 堆区一般是 1G - 4G

​		**(5) 申请效率不同。**栈由系统分配，速度快，不会有碎片。堆由程序员分配，速度慢，且会有碎片。

#### 15. 内存页面置换算法

**缺页异常（缺页中断）**：CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。

- **最佳页面置换算法（OPT）：**置换在「未来」最长时间不访问的页面
- **先进先出置换算法（FIFO）：**选择在内存驻留时间很长的页面进行中置换
- **最近最久未使用的置换算法（LRU）：**选择最长时间没有被访问的页面进行置换
- **时钟页面置换算法（Lock）：**把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。
- **最不常用置换算法（LFU）：**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰

####  16. 简述LRU算法及实现方式

1. **最近最久未使用的置换算法LRU**：LRU算法用于缓存淘汰。思路是将缓存中最近最少使用的对象删除掉
2. **实现方式**：利用**链表和hashmap**。
   - 当需要插入新的数据项的时候，如果新数据项在链表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。
   - 在访问数据的时候，如果数据项在链表中存在，则把该节点移到链表头部，否则返回-1。这样一来在链表尾部的节点就是最近最久未访问的数据项。

#### 17. 磁盘调度算法

- **先来先服务算法：**先到来的请求，先被服务
- **最短寻道时间优先算法：**优先选择从当前磁头位置所需寻道时间最短的请求
- **扫描算法：**磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向
- **循环扫描算法：**只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，返回中途不处理任何请求
- **LOOK 与 C-LOOK 算法：**磁头在移动到「最远的请求」位置，然后立即反向移动，反向移动的途中会响应请求

#### 18. 程序执行的过程

##### (1) 程序启动的过程

1. **操作系统**首先**创建相应的进程**并**分配私有的进程空间**，然后操作系统的**加载器**负责把**可执行文件的数据段和代码段**映射到进程的虚拟内存空间中。
2. 加载器读入可执行程序的**导入符号表**，根据这些符号表可以查找出该可执行程序的**所有依赖的动态链接库**。
3. 加载器针对该程序的每一个动态链接库**调用LoadLibrary** ，调用对应动态链接库的初始化函数
4. **初始化应用程序的全局变量**，对于全局对象自动调用构造函数。
5. 进入应用**程序入口点函数开始执行**。

##### (2) main执行前后的代码

**main函数执行之前**，主要就是初始化系统相关资源：

- 设置栈指针
- 初始化静态`static`变量和`global`全局变量，即`.data`段的内容
- 将未初始化部分的全局变量赋初值：数值型`short`，`int`，`long`等为`0`，`bool`为`FALSE`，指针为`NULL`等等，即`.bss`段的内容
- 全局对象初始化，在`main`之前调用构造函数，这是可能会执行前的一些代码
- 将main函数的参数`argc`，`argv`等传递给`main`函数，然后才真正运行`main`函数
- `__attribute__((constructor))`

**main函数执行之后**：

- 全局对象的析构函数会在main函数之后执行；
- 可以用 **`atexit`** 注册一个函数，它会在main 之后执行;
- `__attribute__((destructor))`

##### (3) 主机完成一条指令的过程

​		将程序通过输入设备送至计算机，将程序首地址送入程序计数器，启动程序运行，取指令(数据)，程序计数器加一，分析指令，执行指令，打印结果，停机

##### (4) CPU 执行一条程序

​		一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束

#### 19. 进程和线程

##### (1) 进程与线程的区别

- 进程是资源分配的基本单位，线程是 CPU 调度的基本单位；
- 多个进程在执行时拥有各自独立的内存单元，多个线程共享进程的内存，如代码段、数据段、扩展段；但每个线程拥有自己的**栈段**和**寄存器组**；
- 一个进程内多个线程可以并发（最好和CPU核数相等）；多个进程可以并发。
- 线程能减少并发执行的时间和空间开销；（系统开销小）
  - 创建线程比创建进程通常要快，终止时间也快，同一个进程内的**线程切换比进程切换快**
  - **线程之间能够方便、快速地共享信息**。只需将数据复制到共享（全局或堆）变量中即可。
  - **线程间是共享虚拟地址空间的**，无需采用写时复制来复制内存，也无需复制页表。

##### (2) 线程与协程的区别

​		① 线程是CPU调度执行的基本单位，协程是线程内部调度的基本单位，一个线程可以有多个协程

​		② 协程执行效率比线程高，切换开销小：协程直接操作栈基本没有内核切换的开销，并且协程不需要多线程的锁机制，所以上下文的切换非常快。

​		③ 协程占用内存少：执行协程只需要极少的栈内存。

##### (3) 进程最多能创建线程数

​		一个进程可以创建的线程数由可用**虚拟空间**和**线程的栈的大小**共同决定

- 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
- 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。

​		**一个线程占多大内存：**一个linux的线程大概占8M内存。linux的栈是通过缺页来分配内存的，不是所有栈地址空间都分配了内存。

##### (4) 多线程和多进程的不同

​		（1）一个线程从属于一个进程；一个进程可以包含多个线程。

​		（2）一个线程挂掉，对应的进程挂掉，多线程也挂掉；一个进程挂掉，不会影响其他进程，多进程稳定。

​		（3）进程系统开销显著大于线程开销；线程需要的系统资源更少。

​		（4）多个进程在执行时拥有各自独立的内存单元，多个线程共享进程的内存，如代码段、数据段、扩展段；但每个线程拥有自己的栈段和寄存器组。

​		（5）多进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈；多线程切换时只需要切换硬件上下文和内核栈。

​		（6）通信方式不一样。

​		（7）多进程适应于多核、多机分布；多线程适用于多核

**另一种答案**

* 频繁修改：需要频繁创建和销毁的优先使用**多线程**

* 计算量：需要大量计算的优先使用**多线程**  因为需要消耗大量CPU资源且切换频繁，所以多线程好一点

* 相关性：任务间相关性比较强的用**多线程**，相关性比较弱的用多进程。因为线程之间的数据共享和同步比较简单。

* 多分布：可能要扩展到多机分布的用**多进程**，多核分布的用**多线程**。

  ​	但是实际中更常见的是进程加线程的结合方式，并不是非此即彼的。

##### (5) 多线程和单线程的区别

1. **区别**：

   （1）多线程从属于一个进程，单线程也从属于一个进程；一个线程挂掉都会导致从属的进程挂掉。

   （2）一个进程里有多个线程，可以并发执行多个任务；一个进程里只有一个线程，就只能执行一个任务。

   （3）多线程并发执行多任务，需要切换内核栈与硬件上下文，有切换的开销；单线程不需要切换，没有切换的开销。

   （4）多线程并发执行多任务，需要考虑同步的问题；单线程不需要考虑同步的问题。

2. 多线程编程需要考虑**同步**的问题。线程间的同步方式包括**互斥锁、信号量、条件变量、读写锁**。

3. 多线程加锁，主要需要注意**死锁**的问题。破坏死锁的必要条件从而避免死锁。

##### (6) 进程为什么比线程慢

1. 进程**系统开销**显著大于线程开销；线程需要的系统资源更少。
2. 进程**切换开销**比线程大。多进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈；多线程切换时只需要切换硬件上下文和内核栈。
3. 进程通信比线程**通信开销**大。进程通信需要借助管道、队列、共享内存，需要额外申请空间，通信繁琐；而线程共享进程的内存，如代码段、数据段、扩展段，通信快捷简单，同步开销更小。

#### 20. 进程的状态

​		三态模型：就绪态、执行态、阻塞态

​		五态模型：新建态、就绪态、执行态、阻塞态、终止态

​				**就绪态：**进程具备运行条件，加入就绪队列，等待系统分配处理器以便运行

​				**运行态：**进程占有CPU正在运行

​				**阻塞态：**进程不具备运行条件，正在等待某个事件的完成

​				**新建态：**进程刚被创建时的状态，还没有加入就绪队列

​				**终止态：**进程完成任务到达正常结束点；或出现无法克服的错误而异常终止；或被操作系统及终止权的进程所终止时的状态

#### 21. 上下文中断切换

##### 进程上下文中断切换过程

​		① 保护进程的处理器现场信息

​		② 修改进程的进程控制块PCB的有关信息，如进程状态

​		③ 把进程的PCB加入有关队列

​		④ 选择下一个占有处理器运行的进程

​		⑤ 根据被选中进程设置操作系统用到的地址转换和存储保护信息

​				**切换页目录以使用新的地址空间**

​				**切换内核栈和硬件上下文**（包括分配的内存、数据段、堆栈段等）

​		⑥ 根据被选中的进程恢复处理器现场

##### 线程上下文切换的过程

​		① 保护线程的处理器现场信息

​		② 修改线程的线程控制块有关信息，如线程状态等

​		③ 把线程的线程控制块加入有关队列

​		④ 选择下一个运行的线程

​		 ⑤ 根据被选中线程设置操作系统用到的存储保护信息

​					**切换内核栈和硬件上下文**（切换堆栈、以及存储器）（不需要设置转换的地址）

​		⑥ 恢复处理器现场

#### 22. 进程线程通信 

##### (1) 进程间的通信 IPC

​		**进程间通信的目的：**数据传输、通知事件、资源共享、进程控制

###### ① 管道

​		**管道**是一种两个进程间进行**单向通信**的机制。操作系统在内核中开辟一块缓冲区（称为管道）用于通信，管道本质是一种文件。

- **无名管道（内存文件）：**管道是一种**半双工**的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程之间使用，通常是指父子进程关系。字节流
- **有名管道（FIFO文件，借助文件系统）：**有名管道也是半双工的通信方式，但是允许在没有亲缘关系的进程之间使用，管道是**先进先出**的通信方式。

###### ② 共享内存

​		共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。与信号量，配合使用来实现进程间的同步和通信。

###### ③ 内存映射

​		内存映射mmap：将磁盘文件的数据映射到内存，用户通过修改内存就能修改磁盘文件。每个进程在自己的虚拟地址空间中有一个独立的内存。

**mmap的原理和使用场景**

**原理：**

​		**mmap是一种内存映射文件的方法**，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。

**使用场景**：

​		(1) 对同一块区域频繁读写操作；

​		(2) 可用于实现用户空间和内核空间的高效交互

​		(3) 可提供进程间共享内存及相互通信

​		(4) 可实现高效的大规模数据传输。

###### 共享内存和内存映射的区别

​    1.共享内存可以直接创建，内存映射需要磁盘文件（匿名映射除外）

​    2.共享内存效果更高

​    3.内存
​        所有的进程操作的是同一块共享内存。
​        内存映射，每个进程在自己的虚拟地址空间中有一个独立的内存。

​    4.数据安全
​		- 进程突然退出：共享内存还存在、内存映射区消失
​		- 运行进程的电脑死机，宕机了：数据存在在共享内存中，没有了。内存映射区的数据 ，由于磁盘文件中的数据还在，所以内存映射区的数据还存在。

​	5.生命周期

​		内存映射区：进程退出，内存映射区销毁

​		共享内存：进程退出，共享内存还在，标记删除（所有的关联的进程数为0），或者关机：如果一个进程退出，会自动和共享内存进行取消关联。

###### ④ 消息队列

​		消息队列是有消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、**管道只能承载无格式字节流**以及缓冲区大小受限等缺点。（消息块）

###### ⑤ 信号

​		用于通知接收进程某个事件已经发生，进程间通信机制中**唯一的异步通信机制**。

###### ⑥ 信号量

​		信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，实现进程、线程的对临界区的同步及互斥访问。

###### ⑦ 套接字

​		适用于**不同机器**间进程通信，在本地也可作为两个进程通信的方式。

##### (2) 线程同步

​		**线程同步：**即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作，其他线程才能对该内存地址进行操作，而其他线程则处于等待状态。

​		**临界区：**对临界资源进行访问的那段代码（临界资源是一次仅允许一个线程使用的共享资源）

​		**同步：**多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。

​		**互斥：**多个进程在同一时刻只有一个进程能进入临界区。

##### ① 互斥和同步的实现

###### 互斥量 mutex

​		采用互斥对象机制，只有拥有互斥对象的线程才可以访问，保证公共资源不会被多个线程同时访问。

​		用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

###### 条件变量 cond

​		通过条件变量通知操作的方式来保持多线程同步，用于阻塞线程的， 没有东西可以读的时候可以阻塞通知生产者生产后再通知消费者消费。

​		互斥锁 + 条件变量：只能用于线程同步

###### 读写锁 rwlock

- 如果有其它线程读数据，则允许其它线程执行读操作，但不允许写操作。
- 如果有其它线程写数据，则其它线程都不允许读、写操作。
- 写是独占的，写的优先级高。

###### 信号量 sem

​		信号量本质上是一个计数器，用于多进程对共享数据对象的读取，可用于进程同步，也可用于线程同步。

##### ③ 生产者消费者模型

- **生产者**在生成数据后，放在一个缓冲区中；
- **消费者**从缓冲区取出数据处理；
- 任何时刻，**只能有一个**生产者或消费者可以访问缓冲区；

##### ④  锁

​		**互斥锁：**（独占锁）加锁失败后，线程会**释放 CPU** ，给其他线程，会从用户态陷入到内核态，让内核帮我们切换线程，存在一定的性能开销成本

​		**自旋锁：**加锁失败后，线程会**忙等待**，直到它拿到锁；在「用户态」完成加锁和解锁操作，销小一些；一直自旋，利用 CPU 周期，直到锁可用

​		**读写锁：**读锁，允许其它线程执行读操作，不允许写操作。写锁，其它线程都不允许读、写操作。写是独占的，写的优先级高。

​		**乐观锁：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。

​		**悲观锁：** 互斥锁、自旋锁、读写锁，都是悲观锁。**乐观锁是先修改同步资源，再验证有没有发生冲突。悲观锁是修改共享数据前，都要先加锁，防止竞争。**

**互斥锁**用于临界区持锁时间比较长的操作，比如下面这些情况都可以考虑

​		（1）临界区有IO操作

​		（2）临界区代码复杂或者循环量大

​		（3）临界区竞争非常激烈

​		（4）单核处理器

**自旋锁就**主要用在临界区持锁时间非常短且CPU资源不紧张的情况下。

##### ② 死锁

​		两个或两个以上的进程在执行过程中，因争夺共享资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。  （是指多个进程在执行过程中，因争夺资源而造成了互相等待。）

###### 死锁的几种场景

- 忘记释放锁
- 重复加锁
- 多线程多锁，抢占锁资源

###### 满足条件

死锁只有**同时满足**以下四个条件才会发生：

（1）**互斥条件**：进程对所分配到的资源不允许其他进程访问，若其他进程访问，只能等待，直到进程使用完成后释放该资源；

（2）**请求保持条件**：进程获得一定资源后，又对其他资源发出请求，但该资源被其他进程占有，此时请求阻塞，而且该进程不会释放自己已经占有的资源；

（3）**不可剥夺条件**：进程已获得的资源，只能自己释放，不可剥夺；

（4）**环路等待条件**：若干进程之间形成一种头尾相接的循环等待资源关系。

###### 避免死锁

​		要破坏其中一个条件即可，最常用的方法就是使用**资源有序分配法**来破坏环路等待条件。（进程总是以相同的顺序申请自己想要的资源）

**如何解决**：

（1）资源一次性分配，从而解决请求保持的问题

（2）可剥夺资源：当进程新的资源未得到满足时，释放已有的资源；

（3）资源有序分配：资源按序号递增，进程请求按递增请求，释放则相反。  保证上锁的顺序一致。

**处理方法**

- 鸵鸟策略：忽略
- 死锁检测与死锁恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复，利用抢占恢复，利用回滚恢复，通过杀死进程恢复。
- 死锁预防：破坏互斥条件、破坏请求和保持条件、破坏不剥夺条件、破坏循环请求等待
- 死锁避免：
  - **安全状态：**如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕
  - **单个/多个资源的银行家算法：**算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

##### (3)  进程同步的方式

1. **信号量semaphore**：是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步。P操作(递减操作)可以用于阻塞一个进程，V操作(增加操作)可以用于解除阻塞一个进程。
2. **管道**：一个进程通过调用管程的一个过程进入管程。在任何时候，只能有一个进程在管程中执行，调用管程的任何其他进程都被阻塞，以等待管程可用。
3. **消息队列**：消息的链接表，放在内核中。消息队列独立于发送与接收进程，进程终止时，消息队列及其内容并不会被删除；消息队列可以实现消息的随机查询，可以按照消息的类型读取。

#### 23. 进程的种类

##### (1) 孤儿进程

​		父进程运行结束后，子进程还在运行，会把子进程交给1号进程管理。

##### (2) 僵尸进程

​		子进程终止时，父进程尚未回收，子进程残留的资源PCB存放在内核中，变成僵尸进程。

​		**危害：**不能被kill -9杀死，会占用大量的进程号。

##### 如何解决：

​		① 父进程及时调用wait系统调用

​		② 使用kill -s SIGCHID 命令

##### (3) 守护进程

​		进程组是一组相关的进程的集合，会话是一组进程组的集合，会存在一个前台进程组，剩下的是后台进程组。

​		守护进程：后台服务进程，生命周期很长，它独立于控制终端，会在系统启动的时候被创建并一直运行到系统关闭。

##### 如何实现：

​		① 创建子进程，终止父进程，执行一个 fork()，之后父进程退出，子进程继续执行

​		② 子进程调用 setsid() 开启一个新会话。  //脱离控制终端

​		③ 清除进程的 umask 以确保当守护进程创建文件和目录时拥有所需的权限。

​		④ 修改进程的当前工作目录，通常会改为根目录（/）

​		⑤ 关闭守护进程从其父进程继承而来的所有打开着的文件描述符（0、1、2），守护进程通常会打开/dev/null (会被丢弃)并使用dup2() 使所有这些描述符指向这个设备。

#### 23. 进程的调度

**调度原则：**CPU 利用率、系统吞吐量（单位时间内 CPU 完成进程的数量）、周转时间（进程运行和阻塞时间总和）、等待时间 (处于就绪队列的时间)、响应时间

**1.  先来先服务 （FCFS）**

​		非抢占式的调度算法，按照请求的顺序进行调度。

​		有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**2.  短作业优先（SJF）**

​		非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

​		长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**3. 最短剩余时间优先 （SRTN）**

​		最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。

​		如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**4.  时间片轮转**

​		将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。

​		当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

**5.  优先级调度**

​		为每个进程分配一个优先级，按优先级进行调度。

​		为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**6.  多级反馈队列**

​		一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。**各个队列优先级从高到低**，**优先级越高的时间片越短**。

​		多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。之前的进程只需要交换 7 次。每个队列优先权也不同最上面的优先权最高。只有上一个队列没有进程在排队，才能调度当前队列上的进程。

​		可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

**7. 分类**

​		**非抢占式（Nonpreemptive）：**让进程运行直到结束或阻塞的调度方式，容易实现，适合专用系统，不适合通用系统。 抢

​		**占式（Preemptive）：**允许将逻辑上可继续运行的在运行过程暂停的调度方式可防止单一进程长时间独占，CPU系统开销大

### 3  计算机网络

#### 1. 端口有效范围

​		0-1023为知名端口号，比如其中HTTP是80，FTP是20（数据端口）、21（控制端口）

​		UDP和TCP报头使用两个字节存放端口号，所以端口号的有效范围是从0到65535。动态端口的范围是从1024到65535

#####   一台机器使用端口号上限

​		65536.因为TCP的报文头部中源端口号和目的端口号的长度是16位，也就是可以表示2^16=65536个不同端口号，因此TCP可供识别的端口号最多只有65536个。但是由于0到1023是知名服务端口，所以实际上还要少1024个端口号。

​		而对于服务器来说，可以开的端口号与65536无关，其实是**受限于Linux可以打开的文件数量**，并且可以通过MaxUserPort来进行配置。

#### 2. 计算机网络体系结构

##### (1) OSI七层模型

- **物理层**：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。                                                                      物理层数据被称为**比特流**
- **数据链路层**：建立逻辑连接、数据的封帧和差错检测，以及 MAC 寻址；                                                                               数据链路层数据被称为**帧**
- **网络层**：进行逻辑地址寻址，定义IP编址，定义路由功能；负责数据的路由、转发、分片；                                                网络层数据被称做**包**
- **传输层**：定义了一些传输数据的协议和端口号，在端到端之间提供可靠的透明数据传输；如 TCP、UDP。                        传输层数据被称作**段**     (TCP段)   
- 会话层：负责在网络中的两节点之间建立、维持和终止通信。  负责建立、管理和终止表示层实体之间的通信会话；
- 表示层：处理用户信息的表示问题，数据的编码，压缩和解压缩，数据的加密和解密.。负责把数据转换成兼容另一个系统能识别的格式；
- 应用层：各种应用软件，包括 Web 应用。        负责给应用程序提供统一的接口；

##### (2) TCP/IP四层模型

​		**TCP/IP协议族**是现在 Internet（因特网）使用的主流协议族，**是一个分层、多协议的通信体系**，一个四层协议系统，自底而上分别是数据链路层、网络层、传输层和应用层。每一层完成不同的功能，且通过若干协议来实现，**上层协议使用下层协议提供的服务**。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312194850754.png" alt="image-20220312194850754" style="zoom:50%;" />

​		**1. 应用层**：直接为应用进程提供服务的。负责向用户提供一组应用程序

​				（1）对不同种类的应用程序不同协议，邮件传输应用使用了 SMTP 协议、万维网应用使用了 HTTP 协议、远程登录服务应用使用了有 TELNET 协议。

​				（2）应用层还能加密、解密、格式化数据。

​				（3）应用层可以建立或解除与其他节点的联系，这样可以充分节省网络资源。

​		**2. 传输层**： **TCP 和 UDP** 起到了中流砥柱的作用，负责端到端的通信

​		**3. 网络层**：可以进行网络连接的建立和终止以及 **IP 地址**的寻找等功能。负责网络包的封装、分片、路由、转发

​		**4. 网络接口层**：由于网络接口层兼并了物理层和数据链路层，网络接口层是传输数据的物理媒介。负责网络包在物理网络中的传输

#### 3. 常见协议

​		**应用层**常见的协议有：**FTP协议**（文件传输协议）、**HTTP协议**（超文本传输协议）、**NFS**（网络文件系统）、**TELNET** （远程登录服务应用）

​		**传输层**常见协议有：**TCP协议**（传输控制协议）、**UDP协议**（ 用户数据报协议）。

​		**网络层**常见协议有：**IP 协议**（因特网互联协议）、**ICMP 协议**（因特网控制报文协议）、**IGMP 协议**（因特网组管理协议）、**RIP** （路由信息协议）

​		**网络接口层**常见协议有：**ARP协议**（地址解析协议）、**RARP协议**（反向地址解析协议）。

##### 网络层常见协议

| 协议 | 名称                 | 作用                                                         |
| ---- | -------------------- | ------------------------------------------------------------ |
| IP   | 网际协议             | IP协议不但定义了数据传输时的基本单元和格式，还定义了数据报的递交方法和路由选择 |
| ICMP | Internet控制报文协议 | ICMP就是一个“错误侦测与回报机制”，其目的就是让我们能够检测网路的连线状况﹐也能确保连线的准确性，是ping和traceroute的工作协议 |
| RIP  | 路由信息协议         | 使用“跳数”(即metric)来衡量到达目标地址的路由距离             |
| IGMP | Internet组管理协议   | 用于实现组播、广播等通信                                     |

##### Ping命令基于哪一层协议

​		ping命令基于网络层的命令，是基于ICMP协议工作的。

##### 什么是ARP

​		ARP：根据IP地址获取物理地址。  （已知自己地址  但 不知道对方MAC地址）

​		ARP 协议会在以太网中以**广播**的形式，对以太网所有的设备喊出：“这个 IP 是谁的？请把你的 MAC 地址告诉我”。然后有人回答：“这个 IP 是我的，我的 MAC 地址是 XX”。如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。

​		在后续操作系统会把本次查询结果放到一块叫做 **ARP 缓存**的内存空间留着以后用，不过缓存的时间就几分钟。

​		也就是说，在发包时： 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。

​												而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。

##### 什么是RARP

​		反向地址转换协议，使只知道自己硬件地址的主机能够知道其IP地址。RARP发出要反向解释的物理地址并希望返回其IP地址，应答包括能够提供所需信息的RARP服务器发出的IP地址。

**原理：**
​		(1) 网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。主机从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址。

​		(2) RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给主机。

​		(3) PC1收到RARP回应后，就使用得到的IP地址进行通讯。

##### 上层协议是如何使用下层协议提供的服务的呢？

​				通过封装实现的。应用程序数据在发送到物理网络上之前，将沿着协议栈从上往下依次传递。每层协议都将在上层数据的基础上加上自己的头部信息（有时还包括尾部信息），以实现该层的功能，这个过程就称为**封装**。

#### 4. 静态路由和动态路由

1. 静态路由是由**系统管理员设计与构建的路由表规定的路由**。适用于网关数量有限的场合，且网络拓朴结构不经常变化的网络。其缺点是不能动态地适用网络状况的变化，当网络状况变化后必须由网络管理员修改路由表。
2. 动态路由是**由路由选择协议而动态构建的**，路由协议之间通过交换各自所拥有的路由信息实时更新路由表的内容。动态路由可以自动学习网络的拓朴结构，并更新路由表。其缺点是路由广播更新信息将占据大量的网络带宽。

**哪些路由协议，都是如何更新的**

​		路由可分为静态&动态路由。静态路由由管理员手动维护；动态路由由路由协议自动维护。

​		路由选择算法的必要步骤：

​			1）向其它路由器传递路由信息；

​			2）接收其它路由器的路由信息；

​			3）根据收到的路由信息计算出到每个目的网络的最优路径，并由此生成路由选择表；

​			4）根据网络拓扑的变化及时的做出反应，调整路由生成新的路由选择表，同时把拓扑变化以路由 信息的形式向其它路由器宣告。

​		两种主要算法：距离向量法（Distance Vector Routing）和链路状态算法（Link-State Routing）。

​		路由协议：RIP 路由协议(距离向量协议)、OSPF 路由协议(基于链路状态)、BGP 和 BGP4 路由协议(外部网关协议)、IGRP 和 EIGRP 协议(动态路由协议)

#### 5. TCP 和 UDP 的区别

- 是否创建连接：TCP协议是有连接的，UDP是无连接的
- 是否可靠：TCP协议是可靠的（保证数据无差错、不丢失、不重复、按序到达），UDP是不可靠的（尽最大努力交付，不保证可靠交付）
- 连接的对象个数：TCP是一对一的连接，UDP支持一对一，多对多，一对多，多对一的通信
- 传输的方式：TCP面向字节流，没有边界， UDP面向数据报，有边界
- 首部开销：TCP首部最少需20个字节，UDP首部8个字节
- 适用场景：TCP适用可靠性高的应用（FTP文件传输、HTTP/HTTPS），UDP适用实时应用（视频会议，直播，广播通信）
- 发送速率：TCP有流量控制和拥塞控制，保证数据传输的安全性；UDP没有，网络拥堵不会影响发送端的发送速率；TCP速度慢，UDP速度快

​		上层使用的协议：基于TCP协议的：Telnet，FTP以及SMTP协议；基于UDP协议的：DHCP、DNS、SNMP、TFTP、BOOTP。

#### 6. TCP通信流程

**服务器端 （被动接受连接的角色）** 

1. 创建一个用于监听的套接字 
   - 监听：监听有客户端的连接 
   - 套接字：这个套接字其实就是一个文件描述符 
2. 将这个监听文件描述符和本地的IP和端口绑定（IP和端口就是服务器的地址信息） 
   - 客户端连接服务器的时候使用的就是这个IP和端口 
3. 设置监听，监听的fd开始工作 
4. 阻塞等待，当有客户端发起连接，解除阻塞，接受客户端的连接，会得到一个和客户端通信的套接字 （fd） 
5. 通信 
   - 接收数据 
   - 发送数据 
6. 通信结束，断开连接

**客户端** 

1. 创建一个用于通信的套接字（fd） 
2. 连接服务器，需要指定连接的服务器的 IP 和 端口 
3. 连接成功了，客户端可以直接和服务器通信 - 接收数据 - 发送数据 
4. 通信结束，断开连接

#### 7. TCP三次握手

​		三次握手的目的是为了保证双方之间建立了连接   //    初始化Socket、序列号和窗口大小并建立 TCP 连接。

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312202007088.png" alt="image-20220312202007088" style="zoom: 80%;" />

​		一开始客户端和服务器都处于CLOSED状态，服务器主动监听某个端口，处于LISTEN状态。

​		**第一次握手：**客户端给服务器端发送一个TCP首部 SYN置1，序号置一个随机初始化数字（ISN）的SYN报文，然后处于SYN_SEND状态。
​		**第二次握手：**服务器收到客户端的SYN报文，给客户端发送一个TCP首部 ACK置1，确认号置客户端的ISN+1，SYN置1，序号置随机化数字的ACK-SYN报文，然后处于SYN_RCVD状态
​		**第三次握手：**客户端收到服务器的报文后，给服务器发送一个TCP首部ACK置1，确认号置服务器的ISN+1的报文，然后处于ESTABLISHED状态，服务器收到后也处于ESTABLISHED状态。

##### ① TCP为什么握手需要3次

​		**因为三次握手才能保证双方具有接收和发送的能力**

​		为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接。

​				(1) 三次握手才可以阻止重复历史连接的初始化（主要原因）（两次握手可能建立一个历史连接，造成资源浪费）

​				(2) 三次握手才可以避免资源浪费（两次握手会造成客户端的 `SYN` 阻塞了，重复发送多次 `SYN` 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。）

​				(3) 三次握手才可以同步双方的初始序列号（两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。）

**不使用「两次握手」和「四次握手」的原因：**

- 「两次握手」：**无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；**
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

##### ② 三次握手消息丢失

1. 第一次握手消息丢失：客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，最大重传次数内核参数控制

2. 第二次握手消息丢失：客户端和服务端都会重传报文，客户端会重传 SYN 报文（第一次握手），服务端会重传 SYN-ACK 报文（第二次握手）

3. 第三次握手消息丢失：服务端重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

   ​	**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。**

##### 超时重传次数和时间

​		在 Linux 里，**最大重传次数**由**内核参数控制** SYN报文是`tcp_syn_retries`，SYN_ACK是`tcp_synack_retries`，这个参数可以自定义的，默认值一般是 5。

​		通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，**每次超时的时间是上一次的 2 倍**。第五次超时重传后，会继续等待 32 秒，若服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，断开 TCP 连接。

​	所以，总耗时是 1+2+4+8+16+32=63 秒，大约 1 分钟左右。

##### ③ 三次握手可以携带数据吗

​		其实第三次握手的时候，是可以携带数据的。但是，**第一次、第二次握手不可以携带数据**

​		**第一次**握手不可以放数据，其中一个简单的原因就是会**让服务器更加容易受到攻击了**。而对于**第三次**的话，此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，他已经建立起连接了，并且也**已经知道服务器的接收、发送能力是正常的**了，所以能携带数据也没啥毛病。

##### ④ 序号的作用

- 接收方可以**去除重复的数据**；
- 接收方可以根据数据包的序列号**按序接收**；
- 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

##### 为什么要求随机生成ISN

- 为了防止历史报文被服务器进程重启的连接接收，造成数据错乱（主要方面）；防止在网络中被延迟的分组在以后又被传送，而导致数据错乱。
- 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；如果 ISN 是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。

##### ⑤ MSS 和 MTU

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzIzLmpwZw?x-oss-process=image/format,png" alt="MTU 与 MSS" style="zoom:50%;" />

- `MTU`：**一个网络包的最大长度**，以太网中一般为 `1500` 字节；
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 **TCP 数据的最大长度**；

##### 为什么IP层可以分片，还需要MSS？

​		因为IP层是不可靠传输，如果在 TCP 的整个报文交给 IP 层进行分片，一个 IP 分片丢失，整个 IP 报文的所有分片都得重传，所以，为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。

##### ⑥ 什么是半连接队列

​		服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个**队列**里，我们把这种队列称之为**半连接队列**。

​		当然还有一个**全连接队列**，就是已经完成三次握手，建立起连接的就会从半连接队列转移到全连接队列中。如果队列满了就有可能会出现丢包现象。

##### ⑦ SYN 攻击

##### 什么是SYN攻击

​	**SYN攻击就是攻击者在短时间内伪造大量不存在IP地址的`SYN` 报文，并向服务器端不断地发送SYN包**，Server则回复确认包，并等待确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用半连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

​	如果不断受到 SYN 攻击，就会导致 SYN 队列（半连接队列）被占满，从而导致无法在建立新的连接。

##### 怎样防御SYN攻击

- 缩短超时（SYN Timeout）时间
- 增加最大半连接数
- 过滤网关防护
- **SYN cookies技术**
  - 当半连接队列满之后，后续服务器收到 SYN 包，不进入半连接队列；
  - 计算出一个 `cookie` 值，再以 SYN + ACK 中的「序列号」返回客户端，
  - 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到全连接队列。

##### 如何调整 SYN 半连接队列大小？

​		要想增大半连接队列，不能只单纯增大 tcp_max_syn_backlog 的值，还需一同增大 somaxconn 和 backlog，也就是增大 accept 队列。否则，只单纯增大 tcp_max_syn_backlog 是无效的。增大 tcp_max_syn_backlog 和 somaxconn 的方法是修改 Linux 内核参数。最后，改变了如上这些参数后，要重启 Nginx 服务，因为 SYN 半连接队列和 accept 队列都是在 `listen()` 初始化的。

##### 如果 SYN 半连接队列已满，只能丢弃连接吗？

​		开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接。

​		syncookies 的工作原理：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功

##### SYN 报文被丢弃的两种场景

- 开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃
  - 如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包
  - 开启PAWS 机制，防止 TCP 包中的序列号发生绕回
- TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃

#### 8. TCP 四次挥手

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220312202129663.png" alt="image-20220312202129663" style="zoom:67%;" />

第一次挥手：客户端给服务器端发送一个FIN置1的报文，然后进入`FIN_WAIT_1`状态（若close关闭表示不发不收，若shutdown关闭有可能表示不发能收）。

第二次挥手：服务器端收到报文后，给客户端发送一个ACK置1的回应报文，然后进入`CLOSED_WAIT`状态。(表示自己接收到关闭消息，但还有数据没有处理完)；

​						客户端收到服务器端的回应报文后，进入FIN_WAIT_2状态。

第三次挥手：服务器端处理完数据后，给客户端发送FIN置1的报文，然后进入`LAST_WAIT`状态（表示数据处理完了，请求关闭）

第四次挥手：客户端收到服务器的FIN报文后，给服务器发送ACK置1的回应报文，然后进入`TIME_WAIT`状态，经过2MSL时间后，自动给进入`CLOSED`状态。

​						服务器收到客户端的回应报文后，进入`CLOSED`关闭状态。

##### ① 为什么挥手需要四次？

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

##### ② 四次挥手信息丢失

​		第一次挥手丢失：触发超时重传机制，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

​		第二次挥手丢失：服务器不会重传ACK 报文的，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。

​		第三次挥手丢失：服务器收不到ACK，就会重发 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

​		第四次挥手丢失：服务器收不到ACK，就会重发 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

##### ③ 为什么需要TIME_WAIT

- **保证客户端发送的最后一个ACK报文段能够到达服务端。**（保证「被动关闭连接」的一方，能被正确的关闭；）（用来重发可能丢失的ACK报文）

  ​		因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。

- **防止“已失效的连接请求报文段”出现在本连接中。**（防止历史连接中的数据，被后面重新连接的服务器错误的接收）(定义这个连接的socked不能再被使用)

  ​		客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。

##### 为什么等待的是 2MSL

​		`MSL` 是 **报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

​		若没有收到 ACK 报文，触发超时重发 `FIN` 报文，会重发 ACK 给被动关闭方，所以**一来一回需要等待 2 倍的时间**。可以看到 **2MSL时长** 这其实是相当于**至少允ACK许报文丢失一次**。若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。

​		为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。

​		`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。

​		在 Linux 系统里 `2MSL` 默认是 `60` 秒，那么一个 `MSL` 也就是 `30` 秒。**Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒**。

##### MSL 与 TTL 的区别

​		因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

​		 MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

​		TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了。

##### TIME_WAIT 过多的危害

- 第一是**内存资源**占用；     客户端受端口资源限制：服务端受系统资源（比如文件描述符、内存资源、CPU 资源、线程资源等）限制：
- 第二是对**端口资源**的占用，一个 TCP 连接至少消耗「发起连接方」的一个本地端口；

##### 如何优化 TIME_WAIT

- 打开选项 net.ipv4.tcp_tw_reuse（=1：在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用） 和

  ​		        net.ipv4.tcp_timestamps （=1：打开对 TCP 时间戳的支持，时间戳的字段是在 TCP 头部的「选项」里，8 个字节，第一个 4 字节字段用来保存发送该数据包的时间，第二个 4 字节字段用来保存最近一次接收对方发送到达数据的时间。由于引入了时间戳，我们在前面提到的 `2MSL` 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。）；

- net.ipv4.tcp_max_tw_buckets（这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置）

- 程序中使用 SO_LINGER ，应用强制使用 RST 关闭。

##### ④ 若建立了连接，但是客户端突然出现故障了怎么办？

​		TCP 有一个机制是**保活机制**。这个机制的原理是这样的：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

**原理：**如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

- 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
- 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。
- 所以，TCP 保活机制可以在双方没有数据交互的情况，**通过探测报文，来确定对方的 TCP 连接是否存活**。

##### 1)  在「**没有数据传输**」的场景下的一些异常情况：

- **若建立了连接，但是客户端突然出现故障了怎么办？**
  - TCP 有一个机制是保活机制，通过探测报文，来确定对方的 TCP 连接是否存活。
- **在没有开启 TCP keepalive，如果客户端的「主机崩溃」了，会发生什么？**
  - 客户端主机崩溃了，服务端是无法感知到的，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态，直到服务端重启进程。
  - 所以一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。
- **若建立了连接，但是客户端的进程崩溃会发生什么？**
  - 使用 kill -9 来模拟进程崩溃的情况，发现在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手。
- **拔掉网线后， 原本的 TCP 连接还存在吗？**
  - 双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
  - 双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。

##### 2)  在「**有数据传输**」的场景下的一些异常情况：

- **客户端主机宕机，又迅速重启，会发生什么？**
  - 在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发**超时重传**机制，重传未得到响应的报文。
  - 服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：
    - 如果客户端主机上**没有**进程监听该 TCP 报文的目标端口号，那么客户端内核就会回复 RST 报文，重置该 TCP 连接；
    - 如果客户端主机上**有**进程监听该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会**回复 RST 报文，重置该 TCP 连接**。
  - 所以，只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接。
- **客户端主机宕机，一直没有重启，会发生什么？**
  - 服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，一般就是 ETIMEOUT 状态码。
  - 在重传报文且一直没有收到对方响应的情况时，先达到「最大重传次数」或者「最大超时时间」这两个的其中一个条件后，就会停止重传。
- **拔掉网线后， 原本的 TCP 连接还存在吗？**
  - 在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。
  - 在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。

##### ⑤ FIN_WAIT_2，CLOSE_WAIT和TIME_WAIT

- FIN_WAIT_2：
  - 半关闭状态。

  - 发送断开请求一方还有接收数据能力，但已经没有发送数据能力。

- CLOSE_WAIT状态：
  - 被动关闭连接一方接收到FIN包会立即回应ACK包表示已接收到断开请求。

  - 被动关闭连接一方如果还有剩余数据要发送就会进入CLOSE_WAIT状态。

- TIME_WAIT状态：
  - 又叫2MSL等待状态。
  - 如果客户端直接进入CLOSED状态，如果服务端没有接收到最后一次ACK包会在超时之后重新再发FIN包，此时因为客户端已经CLOSED，所以服务端就不会收到ACK而是收到RST。所以TIME_WAIT状态目的是防止最后一次握手数据没有到达对方而触发重传FIN准备的。
  - 在2MSL时间内，同一个socket不能再被使用，否则有可能会和旧连接数据混淆（如果新连接和旧连接的socket相同的话）。

#### 9. TCP 可靠性保证

​		TCP主要提供了检验和、序列号/确认应答、重传机制、最大消息长度、滑动窗口控制、连接管理等方法实现了可靠性传输。

##### ① 检验和

- 通过检验和的方式，接收端可以检测出来数据是否有差错和异常，假如有差错就会直接丢弃TCP段，重新发送。TCP在计算检验和时，会在TCP首部加上一个12字节的伪首部。检验和总共计算3部分：TCP首部、TCP数据、TCP伪首部

##### ② 序列号/确认应答

- 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。
- 只要接收端没有回应确认包（ACK包），都会重发。或者接收端的应答包，发送端没有收到也会重发数据。这就可以保证数据的完整性。
- **累计应答**指的是：为了保证**顺序性**，每一个包都有一个**ID**（序号），在建立连接的时候，会商定起始的ID是多少，然后按照ID一个个发送。而为了保证不丢包，对应发送的包都要进行应答，但不是一个个应答，而是会**应答某个之前的ID**，该模式称为**累计应答**

##### ③ 最大消息长度

- 在建立TCP连接的时候，双方约定一个最大的长度（MSS）作为发送的单位，重传的时候也是以这个单位来进行重传。理想的情况下是该长度的数据刚好不被网络层分块。

##### ④ 重传机制

###### 超时重传

- 超时重传是指就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据。
- TCP 会在以下两种情况发生超时重传：
  - 数据包丢失
  - 确认应答丢失
- 超时时间`RTO` （Retransmission Timeout 超时重传时间）应该设置为多少呢？
  - `RTT` （Round-Trip Time 往返时延）就是**数据从网络一端传送到另一端所需的时间**，也就是包的往返时间。
  - 超时重传时间 RTO 的值应该**略大于报文往返 RTT 的值**
  - 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**
  - 超时触发重传存在的问题是，超时周期可能相对较长。

###### 可以解释一下RTO，RTT和超时重传分别是什么吗？

- 超时重传：发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况：

  - 发送的数据没能到达接收端，所以对方没有响应。

  - 接收端接收到数据，但是ACK报文在返回过程中丢失。

  - 接收端拒绝或丢弃数据。

- RTO：从上一次发送数据，因为长期没有收到ACK响应，到下一次重发之间的时间。就是重传间隔。
  - 通常每次重传RTO是前一次重传间隔的两倍，计量单位通常是RTT。例：1RTT，2RTT，4RTT，8RTT......

  - 重传次数到达上限之后停止重传。

- RTT：数据从发送到接收到对方响应之间的时间间隔，即数据报在网络中一个往返用时。大小不稳定。

###### 快速重传

- 它不以时间为驱动，而是以数据驱动重传
- 当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
- 问题：重传的时候，不清楚这连续的三个 ACK 是谁传回来的，是重传之前的一个，还是重传三个所有的问题。

###### 为何快速重传是选择3次ACK？

​		主要的考虑还是要区分包的丢失是由于链路故障还是乱序等其他因素引发。因为两次有可能是乱序。

​		如果接受到三次重复ACK，重传如果接收到正确的ACK，就是丢包；若依然收到重复ACK。则认为网络拥塞，将发送速率减半。

###### SACK 方法

​		`SACK`（ Selective Acknowledgment 选择性确认）。

​		这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。如果要支持 `SACK`，必须双方都要支持。

###### Duplicate SACK

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

可见，`D-SACK` 有这么几个好处：

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

在 Linux 下可以通过 `net.ipv4.tcp_dsack` 参数开启/关闭这个功能（Linux 2.4 后默认打开）。

##### ⑤ 滑动窗口

​		TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着**接收端告诉发送端自己还有多少缓冲区可以接收数据**。

​		发送方可以通过接收方滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0时，发送方一般不能再发送数据报。

​		通信双方都有发送的缓冲区和接收的缓冲区

​			服务器：发送缓冲区、接收缓冲区

​			客户端：发送缓冲区、接收缓冲区		

###### 窗口大小由哪一方决定？

​		**窗口的大小是由接收方的窗口大小来决定的**。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

###### 滑动窗口过小怎么办

​		我们可以假设窗口的大小是1，也是就每次只能发送一个数据，并且发送方只有接受方对这个数据进行确认了以后才能发送下一个数据。如果说窗口过小，那么当传输比较大的数据的时候需要不停的对数据进行确认，这个时候就会**造成很大的延迟**。

##### ⑥ 流量控制

​		流量控制是为了控制发送方发送速率，保证接收方来得及接收，允许接受方对传输进行限制，直到它拥有足够的缓冲空间来容纳更多的数据。

**原理：**

- 目的是接收方通过TCP头窗口字段告知发送方本方可接收的最大数据量，用以解决发送速率过快导致接收方不能接收的问题。所以流量控制是点对点控制。
- TCP是双工协议，双方可以同时通信，所以发送方接收方各自维护一个发送窗和接收窗。

  - 发送窗：用来限制发送方可以发送的数据大小，其中发送窗口的大小由接收端返回的TCP报文段中窗口字段来控制，接收方通过此字段告知发送方自己的缓冲（受系统、硬件等限制）大小。

  - 接收窗：用来标记可以接收的数据大小。
- TCP是流数据，发送出去的数据流可以被分为以下四部分：已发送且被确认部分 | 已发送未被确认部分 | 未发送但可发送部分 | 不可发送部分，其中发送窗 = 已发送未确认部分 + 未发但可发送部分。接收到的数据流可分为：已接收 | 未接收但准备接收 | 未接收不准备接收。接收窗 = 未接收但准备接收部分。
- 发送窗内数据只有当接收到接收端某段发送数据的ACK响应时才移动发送窗，左边缘紧贴刚被确认的数据。接收窗也只有接收到数据且最左侧连续时才移动接收窗口。

###### 操心系统的缓冲区，是如何影响发送窗口和接收窗口的呢？

​		发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会**被操作系统调整**。

​		如果发生了**先减少缓存，再收缩窗口，就会出现丢包的现象**，为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。

###### 窗口关闭—死锁

​		如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是**窗口关闭**。

​		接收方向发送方通告窗口大小时，是通过 `ACK` 报文来通告的。

​		当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。

**TCP 是如何解决窗口关闭时，潜在的死锁现象呢？**

​		TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

- 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
- 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。

###### 糊涂窗口综合症

​		如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。

糊涂窗口综合症的现象是可以发生在发送方和接收方：

- 接收方可以通告一个小的窗口
- 而发送方可以发送小数据

于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了

- 让接收方不通告小窗口给发送方
- 让发送方避免发送小数据

###### 不通告小窗口的方法

​	当「窗口大小」小于 min( MSS，缓存空间/2 ) ，就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`，也就阻止了发送方再发数据过来。

​		等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。

###### 避免发送小数据的方法

发送方通常的策略:

使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：

- 要等到窗口大小 >= `MSS` 或是 数据大小 >= `MSS`
- 收到之前发送数据的 `ack` 回包

只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。

另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。

可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）

###### 延迟确认与 Nagle 算法

那么就出现了常见的两种策略，来减少小报文的传输，分别是：

- **Nagle 算法**

  - Nagle 算法的策略：
    - 没有已发送未确认报文时，立刻发送数据。
    - 存在未确认报文时，直到「没有已发送未确认报文」或「数据长度达到 MSS 大小」时，再发送数据。
  - Nagle 算法一定会有一个小报文，也就是在最开始的时候。
  - Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。

- **延迟确认**

  - TCP 延迟确认的策略：

    - 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
    - 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送
    - 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK

  - 延迟确认 和 Nagle 算法混合使用时，会导致时耗增长，要解决这个问题

    - 要不发送方关闭 Nagle 算法
    - 要不接收方关闭 TCP 延迟确认

  - **延迟应答**指的是：TCP在接收到对端的报文后，并不会立即发送ack，而是等待一段时间发送ack，以便将ack和要发送的数据一块发送。当然ack不能无限延长，否则对端会认为包超时而造成报文重传。linux采用动态调节算法来确定延时的时间。

##### ⑦ 拥塞控制

​		目的就是**避免「发送方」的数据填满整个网络。**

​		拥塞控制目的是防止数据被过多注网络中导致网络资源（路由器、交换机等）过载。因为拥塞控制涉及网络链路全局，所以属于全局控制。

###### 拥塞窗口

​		**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

​		我们在前面提到过发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。

拥塞窗口 `cwnd` 变化的规则：

- 只要网络中没有出现拥塞，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；

###### 怎么知道出现了拥塞

​		其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了用拥塞。**

###### 拥塞控制的控制算法

- **慢启动**
  - TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，试探一下网络的承受能力，以免直接扰乱了网络通道的秩序。
  - 连接建好的开始，先初始化拥塞窗口cwnd大小为1，表明可以传一个MSS大小的数据。
  - 当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1，发包的个数是**指数性的增长**。
  - 每当过了一个往返延迟时间RTT(Round-Trip Time)，cwnd大小直接翻倍，乘以2，呈指数让升。
  - 有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。（一般来说 `ssthresh` 的大小是 `65535` 字节。）
    - 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
    - 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」
- **拥塞避免**
  - 每当收到一个 ACK 时，cwnd 增加 1/cwnd
  - 每当过了一个往返延迟时间RTT，cwnd大小加一。
  - 拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。
  - 网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传，当触发了重传机制，也就进入了「拥塞发生算法」
- **拥塞发生**
  - 发生**超时重传**的拥塞发生算法：这个时候，ssthresh 和 cwnd 的值会发生变化：
    - `ssthresh` 设为 `cwnd/2`，
    - `cwnd` 重置为 `1`
    - 重新开始慢启动，慢启动是会突然减少数据流的，这种方式太激进了，反应也很强烈，会造成网络卡顿
  - 发生**快速重传**的拥塞发生算法：这个时候，ssthresh 和 cwnd 的值会发生变化：
    - `cwnd = cwnd/2` ，也就是设置为原来的一半;
    - `ssthresh = cwnd`;
    - 进入快速恢复算法
- **快速恢复**
  - 快速重传和快速恢复算法一般同时使用，进入快速恢复算法如下：
    - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
    - 重传丢失的数据包；
    - 如果再收到重复的 ACK，那么 cwnd 增加 1；
    - 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

###### 流量控制和拥塞控制

- 流量控制属于通信双方协商；拥塞控制涉及通信链路全局。
- 流量控制需要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的TCP报文段中窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。
- 实际最终发送窗口 = min{流控发送窗口，拥塞窗口}。

####  10. TCP 如何保证有序

（1）为了保证数据包的可靠传递，**发送方**必须把**已发送的数据包保留在缓冲区**，并为每个已发送的数据包启动一个**超时定时器**；

（2）如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答，也可以是对本包后续包的应答），则**释放该数据包占用的缓冲区**;

（3）否则，**重传该数据包**，直到收到应答或重传次数超过规定的最大次数为止。

（4）**接收方**收到数据包后，先**进行CRC校验**，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去。

#### 11. TCP 协议如何保证可靠传输

- **确认和重传**：接收方收到报文就会确认，发送方没有收到确认就会重传。标志位确保通信实体的存在，序号和确认号确保了数据是按序、完整到达。
- **数据校验**：TCP报文头有校验和，用于校验报文是否损坏。
- **数据合理分片和排序**：tcp会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层。而UDP：IP数据报大于1500字节，大于MTU。这个时候发送方的IP层就需要分片，把数据报分成若干片，是的每一片都小于MTU。而接收方IP层则需要进行数据报的重组。由于UDP的特性，某一片数据丢失时，接收方便无法重组数据报，导致丢弃整个UDP数据报。
- **流量控制**：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，避免过量发送，防止包丢失。
- **拥塞控制**：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

#### 12. UDP 如何保证尽量可靠

1. UDP仅提供了最基本的数据传输功能，至于传输时连接的建立和断开、传输可靠性的保证这些UDP统统不关心，而是把这些问题抛给了UDP上层的应用层程序去处理，自己仅提供传输层协议的最基本功能。
2. 最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。
   - 添加seq/ack机制，确保数据发送到对端
   - 添加发送和接收缓冲区，主要是用户超时重传。
   - 添加超时重传机制。

#### 13. TCP 粘包和拆包

​		TCP是个“流”协议，所谓流，就是没有界限的一串数据。大家可以想想河里的流水，是连成一片的，其间并没有分界线。

​		一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，**这就是所谓的TCP粘包和拆包问题**。

​		粘包的问题出现是因为**不知道一个用户消息的边界在哪**，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种方式分包的方式：

- **固定长度的消息；**
  - 每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。
  - 这种方式灵活性不高，实际中很少用。
- **特殊字符作为边界；**
  - 我们可以在两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息。
  - HTTP 通过设置回车符、换行符作为 HTTP 报文协议的边界。
  - 如果刚好消息内容里有这个特殊字符，我们要对这个字符转义，避免被接收方当作消息的边界点而解析到无效的数据。
- **自定义消息结构。**
  - 我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

##### ① TCP粘包问题出现原因

**TCP粘包**是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

- 由TCP**连接复用**造成的粘包问题。
- 因为TCP默认会使用**Nagle算法**，此算法会导致粘包问题。
  - 只有上一个分组得到确认，才会发送下一个分组；
  - 收集多个小分组，在一个确认到来时一起发送。
- **数据包过大**造成的粘包问题。
- 流量控制，**拥塞控制**也可能导致粘包。
- **接收方不及时接收缓冲区的包，造成多个包接收**

##### ② 封包和拆包，它是基于TCP还是UDP的

封包和拆包都是基于TCP的概念。因为TCP是无边界的流传输，所以需要对TCP进行封包和拆包，确保发送和接收的数据不粘连。

* 封包：封包就是在发送数据报的时候为每个TCP数据包加上一个包头，将数据报分为包头和包体两个部分。包头是一个固定长度的结构体，里面包含该数据包的总长度。
* 拆包：接收方在接收到报文后提取包头中的长度信息进行截取。

#### 14. 多路IO复用技术及区别

1. **select，poll，epoll**都是IO多路复用的机制，I/O多路复用就是通过一种机制，可以监视多个文件描述符，一旦某个文件描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。

2. **区别**：

   （1）poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。

   （2）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。

   （3）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把当前进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把当前进程往等待队列上挂也只挂一次，这也能节省不少的开销。

3. **epoll为什么高效：**

   （1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。

   （2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把当前进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把当前进程往等待队列上挂也只挂一次，这也能节省不少的开销。

#### 15. epoll水平触发与边缘触发的区别

​		LT模式（水平触发）下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作；

​		ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。

#### 16. 服务器怎么判断客户端断开了连接

1. 检测连接是否丢失的方法大致有两种：**keepalive**和**heart-beat**
2. （tcp内部机制）采用keepalive，它会先要求此连接一定时间没有活动（一般是几个小时），然后发出数据段，经过多次尝试后（每次尝试之间也有时间间隔），如果仍没有响应，则判断连接中断。可想而知，整个**周期需要很长**的时间。
3. （应用层实现）一个简单的heart-beat实现一般测试连接是否中断采用的时间间隔都比较短，可以**很快的决定连接是否中断**。并且，由于是在应用层实现，因为可以自行决定当判断连接中断后应该采取的行为，而keepalive在判断连接失败后只会将连接丢弃。

#### keepalive

1. **HTTP Keep-Alive**

   在http早期，每个http请求都要求打开一个tpc socket连接，并且使用一次之后就断开这个tcp连接。使用keep-alive可以改善这种状态，即在一次TCP连接中可以持续发送多份数据而不会断开连接。通过使用keep-alive机制，可以减少tcp连接建立次数，也意味着可以减少TIME_WAIT状态连接，以此提高性能和提高httpd服务器的吞吐率(更少的tcp连接意味着更少的系统内核调用,socket的accept()和close()调用)。但是，keep-alive并不是免费的午餐,长时间的tcp连接容易导致系统资源无效占用。配置不当的keep-alive，有时比重复利用连接带来的损失还更大。所以，正确地设置keep-alive timeout时间非常重要。

2. **TCP KEEPALIVE**

   链接建立之后，如果应用程序或者上层协议一直不发送数据，或者隔很长时间才发送一次数据，当链接很久没有数据报文传输时如何去确定对方还在线，到底是掉线了还是确实没有数据传输，链接还需不需要保持，这种情况在TCP协议设计中是需要考虑到的。TCP协议通过一种巧妙的方式去解决这个问题，当超过一段时间之后，TCP自动发送一个数据为空的报文给对方，如果对方回应了这个报文，说明对方还在线，链接可以继续保持，如果对方没有报文返回，并且重试了多次之后则认为链接丢失，没有必要保持链接。

   ​	TCP的keepalive机制和HTTP的keep-alive机制是说的完全不同的两个东西，tcp的keepalive是在ESTABLISH状态的时候，双方如何检测连接的可用行。而http的keep-alive说的是如何避免进行重复的TCP三次握手和四次挥手的环节。

#### 17. 在浏览器中输入url地址后显示主页的过程?

- 根据域名url，进行DNS域名解析；   （向DNS服务器发送DNS请求，查询本地DNS服务器，这其中用的是UDP的协议）                
- 拿到解析的IP地址，建立TCP连接；    

- 向IP地址，发送HTTP请求；
- 服务器处理请求；
- 返回响应结果；
- 关闭TCP连接；
- 浏览器解析HTML；
- 浏览器布局渲染

#### 18. HTTP 常见的响应状态码

**五大类HTTP状态码**

- **1XX : 信息类状态码**（表示接收请求状态处理）（提示信息，目前是协议处理的中间状态，还有后续的操作）
- **2XX : 成功状态码**（表示请求正常处理完毕） （成功，报文已经收到并且被正确处理）  常见：200 204 206
  - 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
  - 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
  - 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分。
- **3XX : 重定向**（表示需要进行附加操作，已完成请求）（资源位置发生变动，需要客户端重新发送请求） 常见： 301 302 304
  - 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
  - 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。
    - 301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。
  - 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。
- **4XX : 客户端错误**（表示服务器无法处理请求）（请求报文有误，服务器无法处理）常见：400 403 404
  - 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
  - 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
  - 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。
- **5XX : 服务器错误状态码**（表示服务器处理请求的时候出错）（服务器在处理内部请求的时候发生了错误） 常见：500 501 502 503
  - 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
  - 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
  - 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
  - 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。

#### 19. GET请求和 POST 请求

##### (1) GET和 POST 的区别

- **语义：**
  - GET 的语义是从服务器获取指定的资源，是「只读」操作
  - POST 的语义是根据请求负荷（报文body）对指定的资源做出处理，是「新增或提交数据」的操作
- **携带数据：**
  - GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制
  - POST 请求携带数据的位置一般是写在报文 body 中， 数据可以是任意格式的数据，只要客户端与服务端协商好即可，浏览器不会对 body 大小做限制
- **安全和幂等：**
  - GET 方法是安全且幂等的，可以对 GET 请求的数据做缓存，缓存可以做到浏览器或者代理上，而且在浏览器中 GET 请求可以保存为书签。
  - POST 方法是不安全且不幂等的，会修改服务器的资源，多次提交数据会创建多个资源，浏览器一般不会缓存 POST 请求，也不把 POST 请求保存为书签
    - 可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。
    - 可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。

##### (2) GET 请求可以带 body 吗

​		RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。

##### (3) GET和POST的长度限制

​		网络上都会提到浏览器地址栏输入的参数是有限的。

​		首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。

​		浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制。

​		get 限制是**特定的浏览器及服务器对它的限制**，比如IE对URL长度的限制是2083字节(2K+35字节)。对于其他浏览器，如FireFox，Netscape等，则没有长度限制，这个时候其限制**取决于服务器的操作系统**；即如果url太长，服务器可能会因为安全方面的设置从而拒绝请求或者发生不完整的数据请求。

​		post 理论上讲是没有大小限制的，HTTP协议规范也没有进行大小限制，但实际上**post所能传递的数据量大小取决于服务器的设置和内存大小**。


##### (4) POST 方法比 GET 方法安全

​		有人说POST 比 GET 安全，因为数据在地址栏上不可见。

​		然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。

​		要想安全传输，就只有加密，也就是 HTTPS。


##### (5) POST 产生两个 TCP 数据包

​		有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。

​		HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。

​		所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。

#### 20. HTTP 与 HTTPS 的区别

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。



### 4  mysql





### 5  项目

#### 1. 项目介绍

​		这个项目主要的目的是对**浏览器的链接请求进行解析处理，处理完之后给浏览器客户端返回一个响应，如文字图片视频等**。服务器后端的处理方式**使用socket通信，利用多路IO复用**（epoll 监管套接字的时候用    **边沿触发 + EPOLLONESHOT + 非阻塞I/O**），可以同时处理多个请求，请求的解析使**用预先准备好的线程池**，使用reactor模式，**主线程负责监听**IO，获取io请求后把请求对象放入请求队列，交给工作线程。睡眠在请求队列上的**工作线程被唤醒进行**数据读取以及逻辑处理。利用**状态机**思想解析 Http 报文，支持 **GET/POST**请求，支持长/短连接；使用基于**小根堆**的定时器关闭超时请求，解决超时，连接系统资源占用问题。



**主线程：**

1. 在主线程中，epoll监听套接字， 处理就绪套接字上的外部IO事件，包括已连接客户的写请求（发送报文），或者新客户的连接请求。
2. 将就绪IO套接字发过来的请求封装成一个requestData对象，对象里面包括了就绪文件描述符是哪一个，发过来的报文数据是啥，这些数据的处理函数是啥等等。
3. 并且设置requestData中的timer为NULL，也就是处理完一个requestData就delete掉，默认是短连接。如果报文解析到长连接，则会在后面补上timer。然后将requestData放在线程池的任务队列里面等待工作线程的处理。
4. 主线程还有一个while循环，利用定时器堆管理定时器结点，删除超时事件。

**工作线程：**

1. 工作线程采用条件变量和锁的形式从任务队列里面取任务，用requestData自己的处理函数分析http报文，发送http响应。
2. 如果分析到报文里面有keep-alive选项，则requestData不会销毁，而是用清空的方式保留。
3. keep-alive长连接不是永久保留的，而是设置了一个定时器（也就是keep-alive中的timer成员）超时，超出时间以后，就把他关闭掉，这里超时时间设定为500ms。
4. 然后就把它加入到定时器最小堆中。
5. 最后由于一开始fd是epolloneshot模式，还需要再epoll ctl设置一下fd的状态，使得他可以再次被监听。

其中线程池中工作线程取用任务队列里面的任务，在工作线程调用requestData中的handleRequest进行使用**状态机**解析了HTTP请求

#### 2. epoll和EPOLLONESHOT

epoll 监管套接字的时候用    **边沿触发 + EPOLLONESHOT + 非阻塞I/O**。

> **EPOLLONESHOT事件   (一个socket连接在任意时刻都只被一个线程处理)**
>
> **即使可以使用边缘触发模式，一个socket上的某个时间还是可能被触发多次。比如一个线程在读取完某个socket上的数据后开始处理这些数据，而在数据的处理过程中，socket上又有了新数据可以读（EPOLLIN再次被触发），此时另外一个线程被唤醒来读取这些新的数据。就会出现两个线程同时操作一个socket的局面。一个socket连接在任意时刻都只被一个线程处理，可以使用 epoll + EPOLLONESHOT 实现。**
>
> **对于注册了EPOLLONESHOT事件的文件描述符有，操作系统最多出发其注册的一个刻度、可写或异常事件，且只触发一次。除非我们使用epoll_ctl函数重置该文件描述符上注册的EPOLLONESHOT事件。**
>
> 这样一个线程在处理某个socket时，其他线程是不可能有机会操作该socket，但反过来要注意，注册了EPOLLONESHOT事件的socket一旦被某个线程处理完毕，该线程就应该立即重置socket上的EPOLLONESHOT事件，以确保这个socket下一次可读时，其EPOLLIN事件能被触发，进而可以让其他线程有几回处理这个socket。

#### 3. 多线程和线程池

使用多线程充分利用**多核CPU**，并使用线程池**避免线程频繁创建**、销**毁加大系统开销。**

- 创建一个线程池来管理多线程，线程池中主要包含**任务队列** 和**工作线程**集合，将任务添加到队列中，然后在创建线程后，自动启动这些任务。使用了一个固定线程数的工作线程，限制线程最大并发数。
- 多个线程共享任务队列，所以需要进行线程间同步，工作线程之间对任务队列的竞争采用**条件变量**和**互斥锁**结合使用。
- 一个工作线程**先加互斥锁**，当任务队列中任务数量为0时候，阻塞在条件变量，当任务数量大于0时候，用条件变量通知阻塞在条件变量下的线程，这些线程来继续竞争获取任务。
- 对任务队列中任务的调度采用**先来先服务**算法。

> 线程池的线程数量最直接的限制因素是CPU处理器的个数。
>
> 如果CPU是四核的，那么对于CPU密集的任务，线程池的线程数量最好也为4，或者+1防止其他因素导致阻塞。
>
> 如果是IO密集的任务，一般要多于CPU的核数，因为线程间竞争的不是CPU资源而是IO，IO的处理一般比较慢，多于核数的线程将为CPU争取更多的任务，不至于在县城处理IO的时候造成CPU空闲导致资源浪费。

#### 4. 解析HTTP请求

1. 采用reactor事件处理模式，主线程只负责监听IO，获取io请求后把请求对象放入请求队列，交给工作线程，工作线程负责数据读取以及逻辑处理。

> proactor模式将所有IO读写操作 都交给主线程和内核来处理，工作线程仅仅负责业务逻辑。

2. 在主线程循环监听到读写套接字有报文传过来以后，在工作线程调用requestData中的handleRequest进行使用**状态机**解析了HTTP请求。

http报文解析和报文响应 解析过程状态机如上图所示。

在一趟循环过程中，状态机先read一个数据包，然后根据当前状态变量判断如何处理该数据包。当数据包处理完之后，状态机通过给当前状态变量传递目标状态值来实现状态转移。那么当状态机进行下一趟循环时，将执行新的状态对应的逻辑。

#### 5. GET和POST报文解析

值得注意的是这里支持了两种类型GET和POST报文的解析。

```c++
//get报文:请求访问的资源。（客户端：我想访问你的某个资源）
GET /0606/01.php HTTP/1.1\r\n  请求行:请求方法 空格 URL 空格 协议版本号 回车符 换行符
Host: localhost\r\n         首部行 首部行后面还有其他的这里忽略
\r\n                空行分割
空                实体主体
```

```c++
//post报文:传输实体主体。（客户端：我要把这条信息告诉你）
POST /0606/02.php HTTP/1.1 \r\n   请求行
Host: localhost\r\n             首部行 首部行中必须有Contenr-length，告诉服务器我要给你发的实体主体有多少字节 
Content-type: application/x-www-form-urlencoded\r\n
Contenr-length: 23\r\n       
 \r\n                                   空行分割
username=zhangsan&age=9 \r\n    实体主体
```

如果是post报文的话，首部行里面必然会有Content-length字段而get没有，所以取出这个字段，求出后面实体主体时候要取用的长度。然后往下走回送相应的http响应报文即可。

而get报文，实体主体是空的，直接读取请求行的url数据，然后往下走回送相应的http响应报文即可。

- 当得到一个完整的，正确的HTTP请求时，就到了`analysisReques`代码部分，我们需要首先对GET请求和不同POST请求（登录，注册，请求图片，视频等等）做不同的处理，然后**分析目标文件的属性**，若目标文件存在、对所有用户可读且不是目录时，则**使用** **`mmap`将其映射到内存地址`m_file_address`处**，并告诉调用者获取文件成功。

- 在这是支持**长连接 keep-alive**

  在首部行读取出来数据以后如果请求方设置了长连接，则Connection字段为keep-alive以此作为依据。

  如果读取到这个字段的话就在报文解析，报文回送完毕之后将requestData重置。然后将该套接字属性也用epoll_ctl重置，再次加入epoll监听。

<img src="https://mmbiz.qpic.cn/mmbiz_png/UsKp3goVVTyy2cvaibStwpBXQ3HH3qsdTqvMiayOwUEiaRP42rI6NHS6z9ibMUIPSAibtsxibkPnv5SXTRAeMcGRuLOA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

#### 6. 定时器优化

实现了一个小根堆的定时器及时剔除超时请求，使用了STL的优先队列来管理定时器。

**优化：**原本是一个基于升序链表的定时器，升序定时器链将其中的定时器按照超时时间做升序排列。但是基于升序链表的定时器，添加定时器的效率**偏低O(n)**，而使用了**优先队列**管理定时器，优先队列的底层是小根堆，添加一个定时器的时间复杂度是**O(log(n))**，删除定时器的时间复杂度是**O(1)**，执行定时器任务的时间复杂度是**O(1)**。

> alarm函数**周期性地触发SIGALRM信号**，该信号处理函数利用管道通知主循环执行定时器链表上的定时任务。

默认是短连接，如果在任务处理时检测到是长连接的话，则加入epoll继续响应，并且设置一个定时器（`mytimer`），放入优先队列中。

#### 7. 两处锁的使用

第一处是请求任务队列的添加和取操作，都需要加锁，并配合条件变量，跨越了多个线程。

第二处是定时器结点的添加和删除，需要加锁，主线程和工作线程都要操作定时器队列。

#### 8. 改进

- 指针可以改成shared_ptr，不需要delete。

> shared_ptr要注意**线程安全**和**循环引用**的问题。

- 想法在某些地方写成单例模式。
- 信号处理部分可以将 epoll_wait 替换为更安全的 epoll_pwait。

#### 9. 优先队列

优先队列（priority queue）可以在**O(1)**时间内获得最大值，并且可以在**O(log n)** 时间内取出最大值或插入任意值。

优先队列常常用堆（heap）来实现。堆是一个**完全二叉树**，其每个节点的值总是小于等于子节点的值。实际实现堆时，我们通常用一个**数组**而不是用指针建立一个树。这是因为堆是完全二叉树，所以用数组表示时，**位置 i 的节点的父节点位置一定为 [(i-1)/2]，而它的两个子节点的位置又一定分别为 2i+1 和 2i+2。**

以下是堆的实现方法，其中最核心的两个操作是**上浮**和**下沉**，例如小根堆：如果一个节点比父节点小，那么需要交换这个两个节点；交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，我们称之为上浮；类似地，如果一个节点比子节点大，也需要不断地向下进行比较和交换操作，我们称之为下沉。如果一个节点有两个子节点，我们总是交换最小的子节点。

<img src="https://mmbiz.qpic.cn/mmbiz_png/UsKp3goVVTyy2cvaibStwpBXQ3HH3qsdT1xfUbIhZdGcJbREjNBOse3ew7NKl8Hb8Khr04ObSicJzjDDQgflHC6Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 25%;" />

通过将算法中的大于号和小于号互换，我们也可以得到一个快速获得最小值的优先队列。

```c++
vector<int> heap;

// 获得最小值
void top() {
    return heap[0];
}

// 插入任意值：把新的数字放在最后一位，然后上浮
void push(int k) {
    heap.push_back(k);
    swim(heap.size() - 1);
}

// 上浮
void swim(int pos) {
    //如果父节点大于当前插入点，则交换，即上浮
    //除非父节点小于等于插入点，或者pos=0,即已经上浮到根节点最小值，停止循环
    while (pos > 0 && heap[(pos-1)/2] > heap[pos])) {
        swap(heap[(pos-1)/2], heap[pos]);
        pos = (pos-1)/2;
    }
}

//最小堆的删除指的是删除根节点的最小值，即数组的第一个值
//为了不破坏最小堆结构，y由于少了第一个元素，我们把把最后一个数字挪到开头，然后进行下沉
void pop() {
    heap[0] = heap.back();
    heap.pop_back();
    sink(0);
}

// 下沉
//如果当前点 大于 子节点中较小的那个，则交换，即下沉
//除非当前点小于等于 子节点中较小的那个，或者当前点已经到达最底部，即已经下沉到最底部，退出循环
void sink(int pos) {
    while (2 * pos + 1 < heap.size()) {
        int i = 2 * pos + 1;
        if (i+1 < heap.size() && heap[i] > heap[i+1]) ++i;//如果有两个子节点，找到较小的那个交换
        if (heap[pos] <= heap[i]) break;
        swap(heap[pos], heap[i]);
        pos = i;
    }
}
```

#### 10. 五种IO模型

##### 网络IO模型

网络IO涉及**用户空间**和**内核空间**，一般会经历两个阶段：

- **一阶段**：**等待数据准备就绪**，即等待网络数据被copy到内核缓冲区
- **二阶段**：**将数据从内核缓冲区copy到用户缓冲区**

上述数据准备就绪可理解为socket中有数据到来，**根据以上两阶段的不同**，出现多种网络IO模型，接下来将根据这两阶段来进行分析。

##### 1. 阻塞IO

调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等待这个函数返回才能进行下一步动作。用户进程**全程阻塞**直到两阶段完成，即，**一阶段**等待数据会阻塞，**二阶段**将数据从内核`copy`到用户空间也会阻塞，只有`copy`完数据后内核返回，用户进程才会**解除阻塞**状态，重新运行。

`linux`中`socket`默认`blocking`

缺点：同一时刻智能处理一个操作，效率低

**结论**：阻塞IO，两阶段都阻塞。

##### 2. 非阻塞IO

用户进程系统调用时，如果没有数据，则直接返回，不管事件有没有发生，若没有发生，则返回-1。因此**一阶段数据准备**不会阻塞**用户进程。但是，用户进程需要**不断的询问内核**数据是否准备好（会造成CPU空转浪费资源，因此很少使用）。当数据准备好时，用户进程会**阻塞直到**数据从内核空间copy到用户空间完成（**二阶段），内核返回结果。

可使用`fcntl`将`socket`设置为`NON-BLOCKING`(`fcntl(fd, F_SETFL, O_NONBLOCK);`)，使其变为**非阻塞**。

这里需要单独判断一下返回值为-1的情况，以`recv` 返回值为例，当返回值为-1时，需要先判断errno，errno为`EAGAIN`表示recv操作未完成，如果errno 为 `EWOULDBLOCK`, 表示无数据，这两种情况下都不是真正的系统错误，排除这两个以后，表示遇到系统错误。含义：

- **大于0**，接收数据完毕，返回值即收到的字节数
- **等于0**，连接已经正常断开

缺点：忙轮询，需要占用CPU资源。

**结论：**非阻塞IO一阶段不阻塞，二阶段阻塞。

##### 3. IO多路复用 (select/poll/epoll)

linux通过使用`select/poll/epoll`函数实现IO复用，这些函数本身是**阻塞的**。但是和阻塞IO所不同的是这些函数可以**同时阻塞多个IO操作**。可在单个进程/线程中同时监听多个网络连接的`socket fd`，一旦有**事件触发**，才真正的调用IO操作函数，进行相应处理。

**结论：**两阶段都处于阻塞状态，优点是单个线程可同时监听和处理多个网络连接。

> 如果连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟更大。因为前者需要两个系统调用(select/epoll + read)，而后者只有一个(read)。但是在连接数很多的情况下，select/epoll的优势就凸显出来了。

##### 4. 信号驱动IO

linux用socket进行信号驱动IO，通过`sigaction`系统调用，建立起信号驱动IO的socket，并绑定一个**信号处理函数**；`sigaction`不会阻塞，立即返回。进程继续运行。当数据准备好，内核就为进程产生一个`SIGIO`信号，随后在信号处理函数中调用`recv`接收数据。

与非阻塞IO的区别在于它提供了消息通知机制，不需要用户进程不断地轮询检查，减少了系统调用次数，提高了效率。

**结论：**一阶段不阻塞（异步），二阶段阻塞（同步）

以上四种模型都有一个**共同点**：**二阶段阻塞**，也就是在真正IO操作的时候需要用户进程参与，因此以上四种模型均称为**同步IO模型**。

##### 5. 异步IO

Linux中提供了异步IO的接口`aio_read`和`aio_write`，内核收到用户进程的`aio_read`之后会立即返回，不会阻塞，`aio_read`会给内核传递**文件描述符**，**缓冲区指针**，**缓冲区大小**，**文件偏移**等；当数据准备好，内核直接将数据`copy`到用户空间，`copy`完后给用户进程发送一个信号，进行用户数据异步处理（`aio_read`）。因此，异步IO中用户进程是不需要参与数据从内核空间`copy`到用户空间这个过程的，也即**二阶段不阻塞**。

**结论：两阶段都不阻塞**

#### 11. 阻塞与非阻塞 同步与异步

**阻塞和非阻塞的区别**在于内核数据还没准备好时，用户进程在**一阶段数据准备时**是否会阻塞；**同步与异步的区别**在于当数据从内核`copy`到用户空间时，用户进程是否会阻参与**第二阶段的数据读写**。

同步表示**第二阶段数据的读写**都是请求方自己来完成；异步表示**请求方并没有参与事件读写**，只是向其他人传入请求的事件以及事情发生时通知方式，之后请求方就可以去处理其他逻辑，当其他人监听到事件处理完成后，会用事先约好的通知方式，通知请求方处理结果。

#### 12. IO多路复用

- #### 什么是IO多路复用技术？

简单点说就是**单个线程/进程**可监听**多个**文件描述符，一旦某个fd就绪，就可以进行相应的读写操作。通过减少运行的进程，有效的减少**上下文切换**的消耗。但是select、poll、epoll本质都是同步I/O，他们都需要在读写事件就绪之后自己负责读写，即这个数据读写过程是阻塞的。

- #### 为什么需要IO多路复用技术

为实现**高性能服务器**。阻塞IO的`recvfrom`接口会**阻塞**直到有数据copy完成，如果是**单线程**的话会导致**主线程被阻塞**，即整个程序永远**锁死**。当然可以通过多线程解决，即**一个连接分配一个线程**来处理，但是如果是**百万连接**情况，总不能创建百万个线程，毕竟操作系统资源有限。因此就有了IO多路复用技术来解决**单线程监听多个网络连接**的情况。

- #### IO多路复用技术有哪些？

主要IO多路复用技术有：`select`，`poll`和`epoll`，注意这些系统调用本身都是**阻塞**的，其所监听的`socket`设置为`non-blocking`。`select`同`poll`原理类似。

- #### select

**工作流程：**

1. 首先构造一个关于文件描述符的列表`readfds`，将要监听的文件描述符添加到该列表中，通过`FD_SET`将`readfds`中对应的文件描述符设为1。
2. 调用`select`，将文件描述符列表`readfds` copy到内核空间，监听该列表中的文件描述符，`轮询`感兴趣的fd，**没有数据到来则select阻塞**，直到这些文件描述符中的一个或者多个进行IO操作时，内核将对应位置为1并将结果返回用户空间。
3. 用户空间**遍历**文件描述符列表`readfds`，通过`FD_ISSET`检测对应的fd是否置位，如果置位则调用read读取数据。

**优点**：可以监听多个文件描述符

**缺点**：

- **最大可监听文件描述符**有上限，由`fd_set`决定（一般为1024）
- 需要将`fd_set`在用户态和内核态之间进行copy，开销大
- 无法精确知道哪些fd准备就绪，每次都需要遍历所有的fd
- 文件描述符列表集合不能重用，每次都需要重置。

- #### poll

`poll`跟`select`实现方式差不多，效率也差不多。只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构。这个结构体`struct pollfd`，里面有`fd`是委托内核检测的文件描述符，`events`是委托内核检测文件描述符的什么事件，`revents`是文件描述符实际发生的事件。

区别在于

- **没有最大可监听fd限制**，因为其底层通过**链表**实现；
- `poll`内核通过`revents`来设置某些事件是否触发，所有每次不需要再重置。

```c++
struct pollfd{
    int fd;
    short events;
    short revents;
 }
```

- #### epoll

`epoll`是一种比`select`，`poll`更加高效的IO多路复用技术。epoll有三个重要接口：`epoll_create`, `epoll_ctl`, `epoll_wait`。

首先通过`epoll_create`在**内核**创建一个新的创建`eventpoll`结构体。

这个在**内核**创建的结构体有两个重要的数据，一个是需要检测的文件描述符信息，底层是**红黑树，** **增删改时间复杂度都为logn**。另一个是就绪列表，存放所有有IO事件到来的fd（其共用红黑树的节点），底层是**双向链表**。

`epoll_ctl`是对这个实例进行管理，包括**插入**，**删除**和**更新**三个操作。

其中**插入**是使用socket fd及其关注的事件构造结构体，并插入到`eventpoll`中，同时会给内核中断处理程序注册一个**回调函数**，告诉内核，如果这个句柄的中断到了，就把它放到**准备就绪list链表**中。**删除**就是将socket fd对应的节点从`eventpoll`中删除，**更新**就是修改socket fd相关的信息，比如更改其所监听的事件等。

`epoll_wait`为检测函数，是一个**阻塞**的接口，如果就绪列表中有事件到来，就会将**就绪事件**copy到用户空间（通过`epoll_event`结构体），并返回事件的数量。没有数据就sleep，等到timeout时间到了即使没有数据也返回。

#### 13. epoll的工作模式：LT和ET

假设委托内核检测读事件，检测fd的读缓冲区。

**水平触发LT(Level Trigger)**：只要缓冲区有数据，就一直触发，直到缓冲区无数据。如果用户只读一部分数据，或者用户不读数据，只有缓冲区还有数据，就会一直触发。除非缓冲区的数据读完了，才不通知。LT是一种默认的工作方式，同时支持block和non-block socket。**（读一次）**

**边缘触发ET(Edge Trigger)**: 缓冲区从无数据到有数据时，epoll检测到了会给用户通知。如果用户不读数据，数据一直在缓冲区，epoll下次检测的时候就不通知；如果用户只读了部分数据，epoll不通知。直到下一次客户端有新的数据包到达时，`epoll_wait`才会再次被唤醒。**（循环读）**

ET只支持**no-block socket**，在这种模式下，当描述符从**未就绪**变为**就绪**时，内核通过epoll告诉你，然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到做了某些操作导致那个文件描述符不再为就绪状态。如果一直不对这个fd做IO操作（从而导致它在此变为未就绪），内核不会发送更多的通知。

ET在很大程度上减少了epoll事件被重复触发的次数，因此效率比LT高。epoll工作在ET模式的时候，必须使用非阻塞接口，**以避免由一个文件句柄的阻塞读/写操作 而把多个文件描述符的任务饿死**。

**为什么ET模式下一定要设置为非阻塞模式？**

因为ET模式，当有数据时，只会被触发一次，所以每次读取数据时，**一定要一次性把数据读取完**（必须等到它们返回**EWOULDBLOCK**（确保所有数据都已读完或写完），所以我们需要**设置一个whlie循环read数据，但如果read是阻塞模式，那么如果没有数据时，将会阻塞，导致程序卡死。**所以这里read只允许非阻塞模式，如果没有数据，read将会跳出循环，继续执行其他程序。

**优缺点**

**1. ET模式**

缺点：应用层业务逻辑复杂，容易遗漏事件，很难用好。

优点：相对LT模式效率比较高。一触发立即处理事件。

**2. LT模式**

优点：编程更符合用户直觉，业务层逻辑更简单。

缺点：效率比ET低。

#### 14. epoll与select, poll对比

对于select和poll来说，所有文件描述符都是在**用户态被加入其文件描述符集合**的，每次调用都需要**将整个集合拷贝到**内核态**；epoll则将**整个文件描述符集合维护在内核态**，每次添加文件描述符的时候都**都需要执行一个系统调用。

**系统调用的开销是很大的**，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。

select使用**线性表**描述文件描述符集合，**文件描述符有上限**；poll使用链表来描述；epoll底层通过**红黑树**来描述，并且维护一个**就绪链表**，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。

select和poll的最大开销**来自内核判断是否有文件描述符就绪**这一过程：每次执行select或poll调用时，它们会采用**遍历**的方式，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，会自动**触发epoll回调函数通知epoll文件描述符**，然后**内核将这些就绪的文件描述符放到就绪链表**中等待epoll_wait调用后被处理。

select和poll都只能工作在相对低效的LT模式下，而epoll同时支持LT和ET模式。

综上，当**监测的fd数量较小，且各个fd都很活跃的情况下**，建议使用select和poll；当监听的fd数量较多，且**单位时间仅部分fd活跃的情况**下，使用epoll会明显提升性能。

#### 15. 事件处理模式：Reactor和Proactor

reactor事件处理模式，主线程只负责监听IO，获取io请求后把请求对象放入请求队列，交给工作线程，工作线程负责数据读取以及逻辑处理。

proactor模式将所有IO读写操作 都交给主线程和内核来处理，工作线程仅仅负责业务逻辑。

服务器程序通常需要处理三类事件：**I/O 事件**、**信号**及**定时事件**。随着网络设计模式的兴起，Reactor 和 Proactor 事件处理模式应运而生。

- **同步 I/O** 模型通常用于实现 **Reactor 模式**
- **异步 I/O** 模型则用于实现 **Proactor 模式**。

##### Reactor模式：

Reactor 模式：**主线程**只负责监听文件描述符上是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元）。除此之外，**主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成。**

- 使用同步 I/O 模型（以 epoll_wait 为例）实现的 Reactor 模式的工作流程：

1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。
2. 主线程调用 epoll_wait 等待 socket 上有数据可读。
3. 当 socket 上有数据可读时， epoll_wait 通知主线程。主线程则主线程则**socket 可读事件放入请求队列**。
4. 睡眠在请求队列上的**某个工作线程被唤醒**，它从 socket 读取数据，并处理客户请求，然后往 epoll 内核事件表中注册该 socket 上的写就绪事件。
5. 主线程调用 epoll_wait 等待 socket 可写。
6. 当 socket 可写时，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列。
7. 睡眠在请求队列上的某个工作进程被唤醒，它往 socket 上写入服务器处理客户请求的结果。

<img src="https://mmbiz.qpic.cn/mmbiz_png/UsKp3goVVTyy2cvaibStwpBXQ3HH3qsdTdiczbIesGKUdGpafHJJWVQvticN4ZBvt1v0sTPPfcm4CHE0bciaDRXVLA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

工作线程从请求队列中取出事件后，将根据事件类型来决定如何处理它：对于可读事件，执行读数据和处理请求的操作；对于可写事件，执行写数据的操作。因此，Reactor 模式中没必要区分所谓的 “读工作线程” 和 “写工作线程”。

##### Proactor模式

Proactor 模式**将所有 I/O 操作都交给主线程和内核来处理， 工作线程仅仅负责业务逻辑。**

- 使用异步 I/O 模型（以 aio_read 和 aio_write为例）实现的 Proactor 模式的工作流程：

1. 主线程调用 aio_read 函数向内核注册 socket 上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序(这里以信号为例)主线程继续处理其他逻辑。
2. 当 socket 上的数据被读入用户缓冲区后，**内核**将向应用程序发送一个信号，以**通知应用程序数据已经可用。**
3. 应用程序预先定义好的**信号处理函数**选择一个工作线程来处理客户请求。工作线程处理完客户请求之后，调用 aio_write 函数向内核注册 socket 上的写完成事件，并告诉**内核用户写缓冲区的位置**，以及写操作完成时如何通知应用程序（仍然以信号为例）
4. 主线程继续处理其他逻辑
5. 当用户缓冲区的数据被写入 socket 之后，内核将向应用程序发送一个信号，以**通知应用程序数据已经发送完毕**。
6. 应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭 socket。

<img src="https://mmbiz.qpic.cn/mmbiz_png/UsKp3goVVTyy2cvaibStwpBXQ3HH3qsdTlbwp6DDjvsSicnuicQqkPVlkns247m8RWJ4vkCU2jficqHClTyh1Ks3rw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;" />

连接 socket 上的读写事件是通过 aio_read/aio_write 向内核注册的，因此内核将通过信号来向应用程序报告连接 socket 上的读写事件。所以，**主线程中的 epoll_wait 调用仅能用来检测监听 socket 上的**连接请求事件，而不能用来检测 socket 上的读写事件。

##### Reactor和Proactor区别及优缺点

**1. Reactor 是****非阻塞同步网络模式，感知的是就绪可读写事件**。在每次感知到有事件发生（比如可读就绪事件）后，就需要**应用进程**主动调用 read 方法来完成**数据的读取**，也就是要应用进程主动将 socket 接收缓存中的**数据读到应用进程内存中**，这个过程是同步的，**读取完数据后应用进程才能处理数据。**

- 优缺点：Reactor实现相对简单，对于耗时短的处理场景处理高效；事件的串行化对应用是透明的，可以顺序的同步执行而不需要加锁；Reactor处理耗时长的操作会造成事件分发的阻塞，影响到后续事件的处理；

**2. Proactor 是****异步网络模式， 感知的是已完成的读写事件**。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，**这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read/write 来读写数据**，操作系统完成读写工作后，就会通知应用进程直接处理数据。

- 优缺点：Proactor性能更高，这种设计**允许多个任务并发的执行，从而提高吞吐量**；并可执行耗时长的任务（各个任务间互不影响）；Proactor实现逻辑复杂；依赖操作系统对异步的支持。

\3. Reactor 可以理解为**来了事件操作系统通知应用进程，让应用进程来处理**，而 Proactor 可以理解为**来了事件操作系统来处理，处理完再通知应用进程**。

##### 适用场景

Reactor：同时接收多个服务请求，并且依次同步的处理它们的事件驱动程序；

Proactor：异步接收和同时处理多个服务请求的事件驱动程序；

#### 16. 线程池

##### 1. 线程池设计

使用多线程充分利用多核CPU，并使用线程池避免线程频繁创建、销毁加大系统开销。

- 创建一个线程池来管理多线程，线程池中主要包含**任务队列** 和**工作线程**集合，将任务添加到队列中，然后在创建线程后，自动启动这些任务。使用了一个固定线程数的工作线程，限制线程最大并发数。
- 多个线程共享任务队列，所以需要进行线程间同步，工作线程之间对任务队列的竞争采用**条件变量**和**互斥锁**结合使用
- 一个工作线程**先加互斥锁**，当任务队列中任务数量为0时候，阻塞在条件变量，当任务数量大于0时候，用条件变量通知阻塞在条件变量下的线程，这些线程来继续竞争获取任务
- 对任务队列中任务的调度采用**先来先服务**算法

##### 2. 根据并发量、任务执行时间使用线程池

> \1. 高并发、任务执行时间短的业务怎样使用线程池？
>
> \2. 并发不高、任务执行时间长的业务怎样使用线程池？
>
> \3. 并发高、业务执行时间长的业务怎样使用线程池？

线程池本质上是**生产者和消费者**模型，包括三要素：

- 往线程池队列中投**递任务的生产者**；
- **任务队列**；
- 从任务队列取出任务执行的**工作线程（消费者）**。

要想合理的配置线程池的大小，得分析线程池任务的特性，可以从以下几个方面来分析：

- 根据任务的性质来分：CPU 密集型任务；IO 密集型任务；混合型任务。
- 根据任务的优先级：高、中、低
- 根据任务的执行时间：长、中、短

不同性质的任务可以交给不同配置的线程池执行。

##### 3. 线程池的线程数量

最直接的限制因素是CPU处理器的个数。

- 如果CPU是4核的，那么对于CPU密集的任务，线程池的线程数量最好也为4，或者+1防止其他因素导致阻塞。
- 如果是IO密集的任务，一般要多于CPU的核数，因为 IO 操作不占用 CPU，线程间竞争的不是CPU资源而是IO，IO的处理一般比较慢，多于核数的线程将为CPU争取更多的任务，不至于在线程处理IO的时候造成CPU空闲导致资源浪费。
- 而对于混合型的任务，如果可以拆分，拆分成 IO 密集型和 CPU 密集型分别处理，前提是两者运行的时间是差不多的，如果处理时间相差很大，则没必要拆分了。

如果**任务执行时间长**，在工作线程数量有限的情况下，工作线程很快就很被任务占完，导致后续任务不能及时被处理，此时应适当**增加工作线程数量**；反过来，如果**任务执行时间短**，那么**工作线程数量不用太多**，太多的工作线程会导致过多的时间浪费在线程上下文切换上。

回到这个问题本身来，这里的“高并发”应该是生产者生产任务的速度比较快，此时需要适当**增大任务队列上限**。

但是对于第三个问题并发高、业务执行时间长这种情形单纯靠线程池解决方案是不合适的，即使服务器有再高的资源配置，每个任务长周期地占用着资源，最终服务器资源也会很快被耗尽，因此对于这种情况，应该配合**业务解耦**，做些模块拆分优化整个系统结构。

#### 17. 这个web服务器是你自己申请的域名么？域名号是多少？

没有申请，因为服务器是放在同一网段的虚拟机里，然后在本地的浏览器里面访问。

或者也可以在同一局域网的不同主机下实验，在同一局域网下通过私有IP+端口号就可以访问。

又或者或者直接把服务器程序放在本地，然后使用本地回环地址127.0.0.1就可以。

本地回环地址主要作用有两个：一是测试本机的网络配置，能PING通127.0.0.1说明本机的网卡和IP协议安装都没有问题；另一个作用是某些SERVER/CLIENT的应用程序在运行时需调用服务器上的资源，一般要指定SERVER的IP地址，但当该程序要在同一台机器上运行而没有别的SERVER时就可以把SERVER的资源装在本机，SERVER的IP地址设为127.0.0.1同样也可以运行。

#### 18. 线程池中的工作线程是一直等待吗？

线程池中的工作线程是处于一直阻塞等待的模式下的。因为在我们创建线程池之初时，我们通过循环调用pthread_create往线程池中创建了5个工作线程，工作线程处理函数接口为pthread_create函数原型中第三个参数函数指针所指向的worker函数（自定义的函数），然后调用线程池类成员函数run（自定义）。

为什么不直接将第三个参数直接指向run函数，而是要通过向worker中传入对象从而调用run呢？原因是因为我们已经将worker设置为静态成员函数，而我们都知道静态成员函数只能访问静态成员变量，所以为了能够访问到类内非静态成员变量，我们可以通过在worker中调用run这个非静态成员变量来达到这一要求。

在run函数中，我们为了能够处理高并发的问题，将线程池中的工作线程都设置为阻塞等待在请求队列是否不为空的条件上，因此项目中线程池中的工作线程是处于一直阻塞等待的模式下的。

#### 19. 你的线程池工作线程处理完一个任务后的状态是什么？

这里要分**两种**情况考虑

1. 当处理完任务后如果请求队列为空时，则这个线程重新回到阻塞等待的状态。
2. 当处理完任务后如果请求队列不为空时，那么这个线程将处于与其他线程竞争资源的状态，谁获得锁谁就获得了处理事件的资格。

#### 20. 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？

该项目是基于IO复用的并发模式。**需要注意的是，不是一个客户连接就对应一个线程**！当客户连接有事件需要处理的时，epoll会进行事件提醒，而后讲对应的任务加入请求队列，等待工作线程竞争执行。**如果速度还是慢，那就只能够增大线程池容量**，或者考虑集群分布式的做法。

#### 21. 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?

会影响接下来的客户请求，因为线程池内线程的数量时有限的，如果客户请求占用线程时间过久的话会影响到处理请求的效率，当请求处理过慢时会造成后续接受的请求只能在请求队列中等待被处理，从而影响接下来的客户请求。

**应对策略：**

1. 我们可以为线程处理请求对象设置处理超时时间, 超过时间先发送信号告知线程处理超时，然后设定一个时间间隔再次检测，若此时这个请求还占用线程则直接将其断开连接。
2. 给每一个线程处理任务设定一个时间阈值，当某一个客户请求时间过长，则将其**置于任务请求最后**，或断开连接。

#### 22. 状态机设计机制及优缺点

状态机就是用于不同状态转换的一种数学模型。

设计机制：将程序中的不同状态进行整合，来保证不论状态发生的顺序如何，最后都能转移到需要的状态上。

好处：项目中状态机主要用于对客户端请求的处理，其中有三种状态，处理请求行，处理请求头，处理请求体，有了状态机，一方面可以避免多种状态同时发生造成混乱。另一方面保证了状态处理结束后能够正确的进行状态转移，相比只有if进行判断更加安全可靠。

缺点：状态机的缺点就是性能比较低，一般一个状态做一个事情，性能比较差，在追求高性能的场景下一般不用，高性能场景一般使用流水线设计。

#### 23. Webbench是什么，介绍一下原理

​		父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。

#### 24. 介绍一下生产者消费者

​		生产者和消费者主要用于对于数据的同步使用，生产者生产数据，然后放到共享缓冲区中，消费者在缓冲区没有数据之前会阻塞等待，当生产者生产数据之后，会用signal函数唤醒阻塞，开始消费数据，而当数据生产充满缓冲区之后，生产者就会阻塞等待。其中的阻塞都使用条件变量。

### 6  TinyWebserver

#### 1. 什么是Web Server（网络服务器）

​		一个Web Server就是一个服务器软件（程序），或者是运行这个服务器软件的硬件（计算机）。

​		主要功能是通过HTTP协议与客户端（通常是浏览器（Browser））进行通信，来接收，存储，处理来自客户端的HTTP请求，并对其请求做出HTTP响应，返回给客户端其请求的内容（文件、网页等）或返回一个Error信息。

#### 2. 用户如何与你的Web服务器进行通信

​		通常用户使用Web浏览器与相应服务器进行通信。在浏览器中键入“域名”或“**IP地址:端口号**”，浏览器则先将你的域名解析成相应的IP地址或者直接根据你的IP地址向对应的Web服务器发送一个HTTP请求。这一过程首先要通过TCP协议的三次握手建立与目标Web服务器的连接，然后HTTP协议生成针对目标Web服务器的HTTP请求报文，通过TCP、IP等协议发送到目标Web服务器上。

#### 3. Web服务器如何接收客户端发来的HTTP请求报文呢?

​		Web服务器端通过`socket`监听来自用户的请求

​		远端的很多用户会尝试去`connect()`这个Web Server上正在`listen`的这个`port`，而监听到的这些连接会排队等待被`accept()`。由于用户连接请求是随机到达的异步事件，每当监听socket（`listenfd`）`listen`到新的客户连接并且放入监听队列，我们都需要告诉我们的Web服务器有连接来了，`accept`这个连接，并分配一个逻辑单元来处理这个用户请求。

**怎样实现并发：**

​		我们在处理这个请求的同时，还需要继续监听其他客户的请求并分配其另一逻辑单元来处理（并发，同时处理多个事件，后面会提到使用线程池实现并发）。这里，服务器通过**epoll**这种I/O复用技术（还有select和poll）**来实现对监听socket（`listenfd`）和连接socket（客户请求）的同时监听**。

​		注意I/O复用虽然可以同时监听多个文件描述符，但是它本身是阻塞的，并且当有多个文件描述符同时就绪的时候，如果不采取额外措施，程序则只能按顺序处理其中就绪的每一个文件描述符，所以为提高效率，我们将在这部分**通过线程池来实现并发（多线程并发），为每个就绪的文件描述符分配一个逻辑单元（线程）来处理**。

服务器程序通常需要处理三类事件：I/O事件，信号及定时事件。有两种事件处理模式：

- Reactor模式：要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生（可读、可写），若有，则立即通知工作线程（逻辑单元），将socket可读可写事件放入请求队列，交给工作线程处理。
- Proactor模式：将所有的I/O操作都交给主线程和内核来处理（进行读、写），工作线程仅负责处理逻辑，如主线程读完成后`users[sockfd].read()`，选择一个工作线程来处理客户请求`pool->append(users + sockfd)`。

通常使用同步I/O模型（如`epoll_wait`）实现Reactor，使用异步I/O（如`aio_read`和`aio_write`）实现Proactor。但在此项目中，我们使用的是**同步I/O模拟的Proactor**事件处理模式。那么什么是同步I/O，什么是异步I/O呢？

- 同步（阻塞）I/O：在一个线程中，CPU执行代码的速度极快，然而，一旦遇到IO操作，如读写文件、发送网络数据时，就需要等待IO操作完成，才能继续进行下一步操作。这种情况称为同步IO。
- 异步（非阻塞）I/O：当代码需要执行一个耗时的IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时，再通知CPU进行处理。

Linux下有三种IO复用方式：epoll，select和poll，为什么用epoll，它和其他两个有什么区别呢？

- 对于select和poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，每次调用都需要将整个集合拷贝到内核态；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要执行一个系统调用。系统调用的开销是很大的，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。
- select使用线性表描述文件描述符集合，文件描述符有上限；poll使用链表来描述；epoll底层通过红黑树来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。
- select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll调用时，它们会采用遍历的方式，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，会自动触发epoll回调函数通知epoll文件描述符，然后内核将这些就绪的文件描述符放到之前提到的ready list中等待epoll_wait调用后被处理。
- select和poll都只能工作在相对低效的LT模式下，而epoll同时支持LT和ET模式。
- 综上，当监测的fd数量较小，且各个fd都很活跃的情况下，建议使用select和poll；当监听的fd数量较多，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。

`Epoll`对文件操作符的操作有两种模式：LT（电平触发）和ET（边缘触发），二者的区别在于当你调用`epoll_wait`的时候内核里面发生了什么：

- LT（电平触发）：类似`select`，LT会去遍历在epoll事件表中每个文件描述符，来观察是否有我们感兴趣的事件发生，如果有（触发了该文件描述符上的回调函数），`epoll_wait`就会以非阻塞的方式返回。若该epoll事件没有被处理完（没有返回`EWOULDBLOCK`），该事件还会被后续的`epoll_wait`再次触发。
- ET（边缘触发）：ET在发现有我们感兴趣的事件发生后，立即返回，并且`sleep`这一事件的`epoll_wait`，不管该事件有没有结束。

在使用ET模式时，必须要保证该文件描述符是非阻塞的（确保在没有数据可读时，该文件描述符不会一直阻塞）；并且每次调用`read`和`write`的时候都必须等到它们返回`EWOULDBLOCK`（确保所有数据都已读完或写完）。

#### 4. Web服务器如何处理以及响应接收到的HTTP请求报文呢?

​		该项目使用线程池（半同步半反应堆模式）并发处理用户请求，主线程负责读写，工作线程（线程池中的线程）负责处理逻辑（HTTP请求报文的解析等等）。通过之前的代码，我们将`listenfd`上到达的`connection`通过 `accept()`接收，并返回一个新的socket文件描述符`connfd`用于和用户通信，并对用户请求返回响应，同时将这个`connfd`注册到内核事件表中，等用户发来请求报文。这个过程是：通过`epoll_wait`发现这个`connfd`上有可读事件了（`EPOLLIN`），主线程就将这个HTTP的请求报文读进这个连接socket的读缓存中`users[sockfd].read()`，然后将该任务对象（指针）插入线程池的请求队列中`pool->append(users + sockfd);`，线程池的实现还需要依靠**锁机制**以及**信号量**机制来实现线程同步，保证操作的原子性。
在线程池部分做几点解释，然后大家去看代码的时候就更容易看懂了：

- 所谓线程池，就是一个`pthread_t`类型的普通数组，通过`pthread_create()`函数创建`m_thread_number`个**线程**，用来执行`worker()`函数以执行每个请求处理函数（HTTP请求的`process`函数），通过`pthread_detach()`将线程设置成脱离态（detached）后，当这一线程运行结束时，它的资源会被系统自动回收，而不再需要在其它线程中对其进行 `pthread_join()` 操作。
- 操作工作队列一定要加锁（`locker`），因为它被所有线程共享。
- 我们用信号量来标识请求队列中的请求数，通过`m_queuestat.wait();`来等待一个请求队列中待处理的HTTP请求，然后交给线程池中的空闲线程来处理。

**为什么要使用线程池？**
当你需要限制你应用程序中同时运行的线程数时，线程池非常有用。因为启动一个新线程会带来性能开销，每个线程也会为其堆栈分配一些内存等。为了任务的并发执行，我们可以将这些任务任务传递到线程池，而不是为每个任务动态开启一个新的线程。

**:star:线程池中的线程数量是依据什么确定的？**

> 在StackOverflow上面发现了一个还不错的[回答](https://stackoverflow.com/a/16128493/7121726)，意思是：
> 线程池中的线程数量最直接的限制因素是中央处理器(CPU)的处理器(processors/cores)的数量`N`：如果你的CPU是4-cores的，对于CPU密集型的任务(如视频剪辑等消耗CPU计算资源的任务)来说，那线程池中的线程数量最好也设置为4（或者+1防止其他因素造成的线程阻塞）；对于IO密集型的任务，一般要多于CPU的核数，因为线程间竞争的不是CPU的计算资源而是IO，IO的处理一般较慢，多于cores数的线程将为CPU争取更多的任务，不至在线程处理IO的过程造成CPU空闲导致资源浪费，公式：`最佳线程数 = CPU当前可使用的Cores数 * 当前CPU的利用率 * (1 + CPU等待时间 / CPU处理时间)`（还有回答里面提到的Amdahl准则可以了解一下）

OK，接下来说说每个`read()`后的HTTP请求是如何被处理的

首先，`process_read()`，也就是对我们读入该`connfd`读缓冲区的请求报文进行解析。
HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据四个部分组成有。两种请求报文（例子来自社长的[详解文章](https://mp.weixin.qq.com/s/BfnNl-3jc_x5WPrWEJGdzQ)：
**GET**（Example）

```
GET /562f25980001b1b106000338.jpg HTTP/1.1
Host:img.mukewang.com
User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64)
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36
Accept:image/webp,image/*,*/*;q=0.8
Referer:http://www.imooc.com/
Accept-Encoding:gzip, deflate, sdch
Accept-Language:zh-CN,zh;q=0.8
空行
请求数据为空
```



**POST**（Example，注意POST的请求内容不为空）

```
POST / HTTP1.1
Host:www.wrox.com
User-Agent:Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022)
Content-Type:application/x-www-form-urlencoded
Content-Length:40
Connection: Keep-Alive
空行
name=Professional%20Ajax&publisher=Wiley
```



**GET和POST的区别**

- 最直观的区别就是GET把参数包含在URL中，POST通过request body传递参数。
- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。
- GET请求在URL中传送的参数是有长度限制。（大多数）浏览器通常都会限制url长度在2K个字节，而（大多数）服务器最多处理64K大小的url。
- GET产生一个TCP数据包；POST产生两个TCP数据包。对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100（指示信息—表示请求已接收，继续处理）continue，浏览器再发送data，服务器响应200 ok（返回数据）。

参考社长的文章：[最新版Web服务器项目详解 - 05 http连接处理（中）](https://mp.weixin.qq.com/s/wAQHU-QZiRt1VACMZZjNlw)
`process_read()`函数的作用就是将类似上述例子的请求报文进行解析，因为用户的请求内容包含在这个请求报文里面，只有通过解析，知道用户请求的内容是什么，是请求图片，还是视频，或是其他请求，我们根据这些请求返回相应的HTML页面等。项目中使用**主从状态机**的模式进行解析，从状态机（`parse_line`）负责读取报文的一行，主状态机负责对该行数据进行解析，主状态机内部调用从状态机，从状态机驱动主状态机。每解析一部分都会将整个请求的`m_check_state`状态改变，状态机也就是根据这个状态来进行不同部分的解析跳转的：

- `parse_request_line(text)`，解析请求行，也就是GET中的`GET /562f25980001b1b106000338.jpg HTTP/1.1`这一行，或者POST中的`POST / HTTP1.1`这一行。通过请求行的解析我们可以判断该HTTP请求的类型（GET/POST），而请求行中最重要的部分就是`URL`部分，我们会将这部分保存下来用于后面的生成HTTP响应。
- `parse_headers(text);`，解析请求头部，GET和POST中`空行`以上，请求行以下的部分。
- `parse_content(text);`，解析请求数据，对于GET来说这部分是空的，因为这部分内容已经以明文的方式包含在了请求行中的`URL`部分了；只有POST的这部分是有数据的，项目中的这部分数据为用户名和密码，我们会根据这部分内容做登录和校验，并涉及到与数据库的连接。

OK，经过上述解析，当得到一个完整的，正确的HTTP请求时，就到了`do_request`代码部分，我们需要首先对GET请求和不同POST请求（登录，注册，请求图片，视频等等）做不同的预处理，然后分析目标文件的属性，若目标文件存在、对所有用户可读且不是目录时，则使用`mmap`将其映射到内存地址`m_file_address`处，并告诉调用者获取文件成功。

抛开`mmap`这部分，先来看看这些不同请求是怎么来的：
假设你已经搭好了你的HTTP服务器，然后你在本地浏览器中键入`localhost:9000`，然后回车，这时候你就给你的服务器发送了一个GET请求，什么都没做，然后服务器端就会解析你的这个HTTP请求，然后发现是个GET请求，然后返回给你一个静态HTML页面，也就是项目中的`judge.html`页面，那POST请求怎么来的呢？这时你会发现，返回的这个`judge`页面中包含着一些`新用户`和`已有账号`这两个`button`元素，当你用鼠标点击这个`button`时，你的浏览器就会向你的服务器发送一个POST请求，服务器段通过检查`action`来判断你的POST请求类型是什么，进而做出不同的响应。

#### 5. 数据库连接池是如何运行的

在处理用户注册，登录请求的时候，我们需要将这些用户的用户名和密码保存下来用于新用户的注册及老用户的登录校验，相信每个人都体验过，当你在一个网站上注册一个用户时，应该经常会遇到“您的用户名已被使用”，或者在登录的时候输错密码了网页会提示你“您输入的用户名或密码有误”等等类似情况，这种功能是服务器端通过用户键入的用户名密码和数据库中已记录下来的用户名密码数据进行校验实现的。若每次用户请求我们都需要新建一个数据库连接，请求结束后我们释放该数据库连接，当用户请求连接过多时，这种做法过于低效，所以类似**线程池**的做法，我们构建一个数据库连接池，预先生成一些数据库连接放在那里供用户请求使用。
(找不到`mysql/mysql.h`头文件的时候，需要安装一个库文件：`sudo apt install libmysqlclient-dev`)
我们首先看单个数据库连接是如何生成的：

1. 使用`mysql_init()`初始化连接
2. 使用`mysql_real_connect()`建立一个到mysql数据库的连接
3. 使用`mysql_query()`执行查询语句
4. 使用`result = mysql_store_result(mysql)`获取结果集
5. 使用`mysql_num_fields(result)`获取查询的列数，`mysql_num_rows(result)`获取结果集的行数
6. 通过`mysql_fetch_row(result)`不断获取下一行，然后循环输出
7. 使用`mysql_free_result(result)`释放结果集所占内存
8. 使用`mysql_close(conn)`关闭连接

对于一个数据库连接池来讲，就是预先生成多个这样的数据库连接，然后放在一个链表中，同时维护最大连接数`MAX_CONN`，当前可用连接数`FREE_CONN`和当前已用连接数`CUR_CONN`这三个变量。同样注意在对连接池操作时（获取，释放），要用到锁机制，因为它被所有线程共享。

#### 6. 什么是CGI校验

OK，弄清楚了数据库连接池的概念及实现方式，我们继续回到第4部分，对用户的登录及注册等POST请求，服务器是如何做校验的。当点击`新用户`按钮时，服务器对这个POST请求的响应是：返回用户一个登录界面；当你在用户名和密码框中输入后，你的POST请求报文中会连同你的用户名密码一起发给服务器，然后我们拿着你的用户名和密码在数据库连接池中取出一个连接用于`mysql_query()`进行查询，逻辑很简单，同步线程校验`SYNSQL`方式相信大家都能明白，但是这里社长又给出了其他两种校验方式，CGI什么的，就很容易让小白一时摸不到头脑，接下来就简单解释一下CGI是什么。

CGI（通用网关接口），它是一个运行在Web服务器上的程序，在编译的时候将相应的`.cpp`文件编程成`.cgi`文件并在主程序中调用即可（通过社长的`makefile`文件内容也可以看出）。这些CGI程序通常通过客户在其浏览器上点击一个`button`时运行。这些程序通常用来执行一些信息搜索、存储等任务，而且通常会生成一个动态的HTML网页来响应客户的HTTP请求。我们可以发现项目中的`sign.cpp`文件就是我们的CGI程序，将用户请求中的用户名和密码保存在一个`id_passwd.txt`文件中，通过将数据库中的用户名和密码存到一个`map`中用于校验。在主程序中通过`execl(m_real_file, &flag, name, password, NULL);`这句命令来执行这个CGI文件，这里CGI程序仅用于校验，并未直接返回给用户响应。这个CGI程序的运行通过多进程来实现，根据其返回结果判断校验结果（使用`pipe`进行父子进程的通信，子进程将校验结果写到pipe的写端，父进程在读端读取）。

#### 7. 生成HTTP响应并返回给用户

通过以上操作，我们已经对读到的请求做好了处理，然后也对目标文件的属性作了分析，若目标文件存在、对所有用户可读且不是目录时，则使用`mmap`将其映射到内存地址`m_file_address`处，并告诉调用者获取文件成功`FILE_REQUEST`。 接下来要做的就是根据读取结果对用户做出响应了，也就是到了`process_write(read_ret);`这一步，该函数根据`process_read()`的返回结果来判断应该返回给用户什么响应，我们最常见的就是`404`错误了，说明客户请求的文件不存在，除此之外还有其他类型的请求出错的响应，具体的可以去百度。然后呢，假设用户请求的文件存在，而且已经被`mmap`到`m_file_address`这里了，那么我们就将做如下写操作，将响应写到这个`connfd`的写缓存`m_write_buf`中去

首先将`状态行`写入写缓存，`响应头`也是要写进`connfd`的写缓存（HTTP类自己定义的，与socket无关）中的，对于请求的文件，我们已经直接将其映射到`m_file_address`里面，然后将该`connfd`文件描述符上修改为`EPOLLOUT`（可写）事件，然后`epoll_Wait`监测到这一事件后，使用`writev`来将响应信息和请求文件**聚集写**到**TCP Socket**本身定义的发送缓冲区（这个缓冲区大小一般是默认的，但我们也可以通过`setsockopt`来修改）中，交由内核发送给用户。OVER！

#### 8. 服务器优化：定时器处理非活动链接

项目中，我们预先分配了`MAX_FD`个http连接对象：

```
// 预先为每个可能的客户连接分配一个http_conn对象
http_conn* users = new http_conn[MAX_FD];
```

如果某一用户`connect()`到服务器之后，长时间不交换数据，一直占用服务器端的文件描述符，导致连接资源的浪费。这时候就应该利用定时器把这些超时的非活动连接释放掉，关闭其占用的文件描述符。这种情况也很常见，当你登录一个网站后长时间没有操作该网站的网页，再次访问的时候你会发现需要重新登录。
项目中使用的是`SIGALRM信号`来实现定时器，利用`alarm`函数周期性的触发`SIGALRM`信号，信号处理函数利用管道通知主循环，主循环接收到该信号后对升序链表上所有定时器进行处理，若该段时间内没有交换数据，则将该连接关闭，释放所占用的资源。（具体请参考`Linux高性能服务器编程 第11章 定时器`和[社长庖丁解牛：07定时器篇](https://mp.weixin.qq.com/s/mmXLqh_NywhBXJvI45hchA)），我们接下来看项目中的具体实现。

`alarm`函数会定期触发`SIGALRM`信号，这个信号交由`sig_handler`来处理，每当监测到有这个信号的时候，都会将这个信号写到`pipefd[1]`里面，传递给主循环：

当我们在读端`pipefd[0]`读到这个信号的的时候，就会将`timeout`变量置为`true`并跳出循环，让`timer_handler()`函数取出来定时器容器上的到期任务，该定时器容器是通过升序链表来实现的，从头到尾对检查任务是否超时，若超时则调用定时器的回调函数`cb_func()`，关闭该socket连接，并删除其对应的定时器`del_timer`。

**定时器优化**
这个基于升序双向链表实现的定时器存在着其固有缺点：

- 每次遍历添加和修改定时器的效率偏低(O(n))，使用最小堆结构可以降低时间复杂度降至(O(logn))。
- 每次以固定的时间间隔触发`SIGALRM`信号，调用`tick`函数处理超时连接会造成一定的触发浪费，举个例子，若当前的`TIMESLOT=5`，即每隔5ms触发一次`SIGALRM`，跳出循环执行`tick`函数，这时如果当前即将超时的任务距离现在还有`20ms`，那么在这个期间，`SIGALRM`信号被触发了4次，`tick`函数也被执行了4次，可是在这4次中，前三次触发都是无意义的。对此，我们可以动态的设置`TIMESLOT`的值，每次将其值设置为**当前最先超时的定时器与当前时间的时间差**，这样每次调用`tick`函数，超时时间最小的定时器必然到期，并被处理，然后在从时间堆中取一个最先超时的定时器的时间与当前时间做时间差，更新`TIMESLOT`的值。

#### 9. 服务器优化：日志

参考：

- [最新版Web服务器项目详解 - 09 日志系统（上）](https://mp.weixin.qq.com/s/IWAlPzVDkR2ZRI5iirEfCg)
- [最新版Web服务器项目详解 - 10 日志系统（下）](https://mp.weixin.qq.com/s/f-ujwFyCe1LZa3EB561ehA)
- [muduo第五章：高效的多线程日志](https://github.com/chenshuo/muduo)

日志，由服务器自动创建，并记录运行状态，错误信息，访问数据的文件。
这部分内容个人感觉相对抽象一点，涉及单例模式以及单例模式的两种实现方式：懒汉模式和恶汉模式，以及条件变量机制和生产者消费者模型。这里大概就上述提到的几点做下简单解释，具体的还是去看参考中社长的笔记。
**单例模式**
最常用的设计模式之一，保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。
实现思路：私有化它的构造函数，以防止外界创建单例类的对象；使用类的私有静态指针变量指向类的唯一实例，并用一个公有的静态方法获取该实例。

- 懒汉模式

  ：即非常懒，不用的时候不去初始化，所以在第一次被使用时才进行初始化（实例的初始化放在

  ```
  getinstance
  ```

  函数内部）

  - 经典的线程安全懒汉模式，使用双检测锁模式（`p == NULL`检测了两次）
  - 利用局部静态变量实现线程安全懒汉模式

- **饿汉模式**：即迫不及待，在程序运行时立即初始化（实例的初始化放在`getinstance`函数外部，`getinstance`函数仅返回该唯一实例的指针）。

**日志系统的运行机制**

- 日志文件
  - 局部变量的懒汉模式获取实例
  - 生成日志文件，并判断同步和异步写入方式
- 同步
  - 判断是否分文件
  - 直接格式化输出内容，将信息写入日志文件
- 异步
  - 判断是否分文件
  - 格式化输出内容，将内容写入阻塞队列，创建一个写线程，从阻塞队列取出内容写入日志文件

#### 10. 压测（非常关键）

一个服务器项目，你在本地浏览器键入`localhost:9000`发现可以运行无异常还不够，你需要对他进行压测（即服务器并发量测试），压测过了，才说明你的服务器比较稳定了。社长的项目是如何压测的呢？
用到了一个压测软件叫做Webbench，可以直接在社长的Gtihub里面下载，解压，然后在解压目录打开终端运行命令（`-c`表示客户端数， `-t`表示时间）：

```
./webbench -c 10001 -t 5 http://127.0.0.1:9006/
```



直接解压的`webbench-1.5`文件夹下的`webbench`文件可能会因为权限问题找不到命令或者无法执行，这时你需要重新编译一下该文件即可：

```
gcc webbench.c -o webbench
```



然后我们就可以压测得到结果了（我本人电脑的用户数量`-c`设置为`10500`会造成资源不足的错误）：

```
Webbench - Simple Web Benchmark 1.5
Copyright (c) Radim Kolar 1997-2004, GPL Open Source Software.

Benchmarking: GET http://127.0.0.1:9006/
10001 clients, running 5 sec.

Speed=1044336 pages/min, 2349459 bytes/sec.
Requests: 87028 susceed, 0 failed.
```



**Webbench是什么，介绍一下原理**
父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。



### 7  项目简洁版

#### 1. 项目介绍

​		这个项目主要的目的是对**浏览器的链接请求进行解析处理，处理完之后给浏览器客户端返回一个响应，如文字图片视频等**。服务器后端的处理方式**使用socket通信，利用多路IO复用**（epoll 监管套接字的时候用    **边沿触发 + EPOLLONESHOT + 非阻塞I/O**），可以同时处理多个请求，请求的解析使**用预先准备好的线程池**，使用reactor模式，**主线程负责监听**IO，获取io请求后把请求对象放入请求队列，交给工作线程。睡眠在请求队列上的**工作线程被唤醒进行**数据读取以及逻辑处理。利用**状态机**思想解析 Http 报文，支持 **GET/POST**请求，支持长/短连接；使用基于**小根堆**的定时器关闭超时请求，解决超时，连接系统资源占用问题。

\* 使用 **线程池 + 非阻塞socket + epoll(ET和LT均实现) + 事件处理(Reactor和模拟Proactor均实现)** 的并发模型

\* 使用**状态机**解析HTTP请求报文，支持解析**GET和POST**请求

\* 访问服务器数据库实现web端用户**注册、登录**功能，可以请求服务器**图片和视频文件**

\* 实现**同步/异步日志系统**，记录服务器运行状态

\* 经Webbench压力测试可以实现**上万的并发连接**数据交换

项目描述：该项目主要是实现Linux环境下以C++开发语言来搭建轻量级的Web服务器，服务器可以支持相对数量的客户

端并发访问并及时响应，如文字图片视频等。

主要工作：

 (1) 使用 Socket 实现不同主机间的通信；

 (2) 利用I/O复用技术 Epoll 与 线程池 实现多线程的 Reactor (及模拟Proactor) 高并发模型；

 (3) 使用有限状态机解析HTTP请求报文，对GET和HTTP请求进行处理；

 (4) 使用mysql数据库实现Web端用户注册、登录功能，可以请求服务器图片和视频文件。

个人收获：对HTTP的服务过程以及TCP三次握手有了更深的了解；对Socket通信以及I/O复用有了更深的理解。

**主线程：**

1. 在主线程中，epoll监听套接字， 处理就绪套接字上的外部IO事件，包括已连接客户的写请求（发送报文），或者新客户的连接请求。
2. 将就绪IO套接字发过来的请求封装成一个requestData对象，对象里面包括了就绪文件描述符是哪一个，发过来的报文数据是啥，这些数据的处理函数是啥等等。
3. 并且设置requestData中的timer为NULL，也就是处理完一个requestData就delete掉，默认是短连接。如果报文解析到长连接，则会在后面补上timer。然后将requestData放在线程池的任务队列里面等待工作线程的处理。
4. 主线程还有一个while循环，利用定时器堆管理定时器结点，删除超时事件。

**工作线程：**

1. 工作线程采用条件变量和锁的形式从任务队列里面取任务，用requestData自己的处理函数分析http报文，发送http响应。
2. 如果分析到报文里面有keep-alive选项，则requestData不会销毁，而是用清空的方式保留。
3. keep-alive长连接不是永久保留的，而是设置了一个定时器（也就是keep-alive中的timer成员）超时，超出时间以后，就把他关闭掉，这里超时时间设定为500ms。
4. 然后就把它加入到定时器最小堆中。
5. 最后由于一开始fd是epolloneshot模式，还需要再epoll ctl设置一下fd的状态，使得他可以再次被监听。

其中线程池中工作线程取用任务队列里面的任务，在工作线程调用requestData中的handleRequest进行使用**状态机**解析了HTTP请求



**客户端如何与我们所写的服务器进行通信？**

​		通常用户使用web浏览器与相应服务器进行通信，在浏览器中输入“域名”或者“IP地址：端口号”，浏览器则先将你的域名解析成相应的IP地址或者直接根据你的IP地址向对应的web服务器发送一个http请求，这一过程首先需要通过TCP协议的三次握手建立与目标web服务器的连接，然后http协议生成http请求报文，通过TCP、IP等协议发送到目标web服务器上。

**服务器如何接收客户端发来的http请求报文？**

​		web服务器通过socket监听listen()来自用户的请求。

​		客户端尝试去connect()连接服务器端口，而服务器监听到的这些连接请求会排队被accept()，由于客户端连接请求时随机到达的异步事件，每当监听到新的客户连接就会放入监听队列，服务器端需要接收这个客户端连接并分配一个逻辑单元来处理这个客户端请求，同时还需要继续监听其他客户的请求并分配另一个逻辑单元来处理（并发，同时处理多个事件，用线程池实现）。服务器通过epoll这种I/O多路复用技术来实现监听套接字和客户端请求的同时监听，注意I/O复用虽然可以同时监听多个文件描述符，但她本身是阻塞的，并且当有多个文件描述符就绪的时候，如果不采用额外措施，程序只能按顺序处理其中就绪的每一个文件描述符，所以为了提高效率，我们通过线程池来实现并发，为每个就绪的文件描述符分配一个线程来处理。

​		服务器程序通常需要处理三类事件：I/O事件、信号及定时事件，有两种事件处理模式：

reactor模式：要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生（可读、可写），若有则立即通知线程，将socket可读可写事件放入请求队列，交给工作线程处理。

proactor模式：将所有的I/O操作都交给主线程和内核来处理（进行读、写），工作线程仅负责处理逻辑，如主线程读完后，选择一个工作线程来处理客户请求。

​		通常使用同步I/O模型（epoll_wait）实现reactor，使用异步I/O（aio_read、aio_write）实现proactor，但我们使用同步I/O模拟proator事件处理模式。



​		同步（阻塞）I/O：在一个线程中，CPU执行代码的速度极快，然而一旦遇到I/O操作，如读写文件、发送网络数据时，就需要等待I/O操作完成，才能继续下一步操作。

​		异步（非阻塞）I/O：当代码需要执行一个耗时的I/O操作时，它只发出I/O指令，并不等待I/O结果，然后就去执行其他代码了，一段时间后，当I/O返回结果时，再通知CPU处理。

epoll、select、poll

​		对于select、poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，每次调用都需要将整个集合拷贝到内核态，epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要执行一个系统调用，系统调用开销是很大的，而且有很多短期活跃连接的情况下，epoll可能会慢于select、poll。

​		select使用线性表描述文件描述符集合，文件描述符有上限；poll使用链表来描述；epoll底层通过红黑树来描述，并且维护一个r双链表eady list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。

​		select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程，每次执行select或poll调用时都会采用遍历的方式，遍历整个文件描述符集合去判断各个描述符是否有活动；epoll则不需要这种方式检查，当有活动产生时，会自动触发epoll回调函数通知epoll文件描述符，然后内核将这些就绪的文件描述符放到ready list等待epoll_wait调用后被处理。

​		select和poll都只能工作在相对低效的LT模式下，而epoll同时支持LT和ET模式。

​		综上，当检测的fd数量较小，且各个fd都很活跃的情况下，建议使用select和poll，当监听的fd数量较多，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。

epoll对于文件描述符的操作有两种模式：LT（电平触发）和ET（边缘触发），两者区别在于当你调用epoll_wait的时候内核发生了什么：

​		LT（电平触发）：类似select，LT会去遍历epoll事件表中每个文件描述符，来观察是否有事件发生，如果有（触发了该文件描述符上的回调函数），epoll_wait就会以非阻塞的方式返回，若该epoll时间没有被处理完（没有返回EWOULDBLOCK），该事件还会被后续的epoll_wait触发

​		ET（边缘触发）：ET在发现有我们感兴趣的事件发生后，立即返回，并且sleep这一事件的epoll_wait，不管该事件有没有结束

在使用ET模式的时候，必须保证该文件描述符是非阻塞的（确保没有数据可读的时候该文件描述符不会一直阻塞）；并且每次调用read和write的时候都必须等到他们返回EWOULDBLOCK（确保所有数据都已读完或者写完）



**web服务器如何处理以及响应接收到的http请求报文？**

该项目使用线程池（半同步半反应堆模式）并发处理用户请求，主线程负责读写，工作线程（线程池中的线程）负责处理逻辑（http请求报文的解析等等），将监听socket上到达的连接通过accpet()接收，并返回一个新的socket文件描述符connfd用于和用户通信，并对用户请求返回响应，同时将这个connfd注册到内核事件表中，等待用户发来请求报文，这个过程是：通过epoll_wait发现这个connfd上有可读事件了（EPOLLIN）主线程就将这个http请求报文读进这个连接socket的读缓存中users[sockfd].read()，然后将该任务对象（指针）插入线程池的请求队列中，线程池的实现还需要依靠锁机制及信号量机制来实现线程同步



线程池，就是一个pthread_t线程类型的数组，通过`pthread_create()`函数创建`m_thread_number`个**线程**，用来执行`worker()`函数以执行每个请求处理函数（HTTP请求的`process`函数），通过`pthread_detach()`将线程设置成脱离态（detached）后，当这一线程运行结束时，它的资源会被系统自动回收，而不再需要在其它线程中对其进行 `pthread_join()` 操作。

- 操作工作队列一定要加锁（`locker`），因为它被所有线程共享。
- 我们用信号量来标识请求队列中的请求数，通过`m_queuestat.wait();`来等待一个请求队列中待处理的HTTP请求，然后交给线程池中的空闲线程来处理。





#### 2. 基本框架

##### (1) 服务器编程基本框架

主要由**I/O单元**，**逻辑单元**和**网络存储单元**组成，其中每个单元之间通过**请求队列**进行通信，从而协同完成任务。

其中I/O单元用于处理客户端连接，读写网络数据；逻辑单元用于处理业务逻辑的线程；网络存储单元指本地数据库和文件等。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBH2ZO50WrURwTiaNKTH7tCia3QENT2MZibwxf74GnEpuxqz30UHUJZuJ9d0vYP8SzkU5fK1sMw4DNzng/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

<img src="C:\Users\zyy\AppData\Roaming\Typora\typora-user-images\image-20220313153639247.png" alt="image-20220313153639247" style="zoom: 80%;" />

​		I/O 处理单元是服务器管理客户连接的模块。它通常要完成以下工作：等待并接受新的客户连接，接收客户数据，将服务器响应数据返回给客户端。但是数据的收发不一定在 I/O 处理单元中执行，也可能在逻辑单元中执行，具体在何处执行取决于事件处理模式。

​		一个逻辑单元通常是一个进程或线程。它分析并处理客户数据，然后将结果传递给 I/O 处理单元或者直接发送给客户端（具体使用哪种方式取决于事件处理模式）。服务器通常拥有多个逻辑单元，以实现对多个客户任务的并发处理。

​		网络存储单元可以是数据库、缓存和文件，但不是必须的。

​		请求队列是各单元之间的通信方式的抽象。I/O 处理单元接收到客户请求时，需要以某种方式通知一个逻辑单元来处理该请求。同样，多个逻辑单元同时访问一个存储单元时，也需要采用某种机制来协调处理竞态条件。请求队列通常被实现为池的一部分。

##### (2) 五种I/O模型

- **阻塞IO**：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作
- **非阻塞IO**：非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。非阻塞I/O执行系统调用总是立即返回，不管时间是否已经发生，若时间没有发生，则返回-1，此时可以根据errno区分这两种情况，对于accept，recv和send，事件未发生时，errno通常被设置成eagain
- **信号驱动IO**：linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO时间就绪，进程收到SIGIO信号。然后处理IO事件。
- **IO复用**：linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检测。知道有数据可读或可写时，才真正调用IO操作函数
- **异步IO**：linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。

注意：阻塞I/O，非阻塞I/O，信号驱动I/O和I/O复用都是同步I/O。**同步I/O**指内核向应用程序通知的是就绪事件，比如只通知有客户端连接，要求用户代码自行执行I/O操作，**异步I/O**是指内核向应用程序通知的是完成事件，比如读取客户端的数据后才通知应用程序，由内核完成I/O操作。

##### (3) 事件处理模式

- reactor模式中，主线程(**I/O处理单元**)只负责监听文件描述符上是否有事件发生，有的话立即通知工作线程(**逻辑单元** )，读写数据、接受新连接及处理客户请求均在工作线程中完成。通常由**同步I/O**实现。
- proactor模式中，主线程和内核负责处理读写数据、接受新连接等I/O操作，工作线程仅负责业务逻辑，如处理客户请求。通常由**异步I/O**实现。

###### 同步I/O模拟proactor模式

由于异步I/O并不成熟，实际中使用较少，这里将使用同步I/O模拟实现proactor模式。

同步I/O模型的工作流程如下（epoll_wait为例）：

> - 主线程往epoll内核事件表注册socket上的读就绪事件。
> - 主线程调用epoll_wait等待socket上有数据可读
> - 当socket上有数据可读，epoll_wait通知主线程,主线程从socket循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列。
> - 睡眠在请求队列上某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件
> - 主线程调用epoll_wait等待socket可写。
> - 当socket上有数据可写，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。

##### (4) 并发编程模式

并发编程方法的实现有多线程和多进程两种，但这里涉及的并发模式指I/O处理单元与逻辑单元的协同完成任务的方法。

- 半同步/半异步模式
- 领导者/追随者模式

###### 半同步/半反应堆

半同步/半反应堆并发模式是半同步/半异步的变体，将半异步具体化为某种事件处理模式.

并发模式中的同步和异步

> - 同步指的是程序完全按照代码序列的顺序执行
> - 异步指的是程序的执行需要由系统事件驱动

半同步/半异步模式工作流程

> - 同步线程用于处理客户逻辑
> - 异步线程用于处理I/O事件
> - 异步线程监听到客户请求后，就将其封装成请求对象并插入请求队列中
> - 请求队列将通知某个工作在**同步模式的工作线程**来读取并处理该请求对象

半同步/半反应堆工作流程（以Proactor模式为例）

> - 主线程充当异步线程，负责监听所有socket上的事件
> - 若有新请求到来，主线程接收之以得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件
> - 如果连接socket上有读写事件发生，主线程从socket上接收数据，并将数据封装成请求对象插入到请求队列中
> - 所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权

##### (5) 怎样实现并发

​		我们在处理这个请求的同时，还需要继续监听其他客户的请求并分配其另一逻辑单元来处理（并发，同时处理多个事件，后面会提到使用线程池实现并发）。这里，服务器通过**epoll**这种I/O复用技术（还有select和poll）**来实现对监听socket（`listenfd`）和连接socket（客户请求）的同时监听**。

​		注意I/O复用虽然可以同时监听多个文件描述符，但是它本身是阻塞的，并且当有多个文件描述符同时就绪的时候，如果不采取额外措施，程序则只能按顺序处理其中就绪的每一个文件描述符，所以为提高效率，我们将在这部分**通过线程池来实现并发（多线程并发），为每个就绪的文件描述符分配一个逻辑单元（线程）来处理**。

服务器程序通常需要处理三类事件：I/O事件，信号及定时事件。有两种事件处理模式：

- Reactor模式：要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生（可读、可写），若有，则立即通知工作线程（逻辑单元），将socket可读可写事件放入请求队列，交给工作线程处理。
- Proactor模式：将所有的I/O操作都交给主线程和内核来处理（进行读、写），工作线程仅负责处理逻辑，如主线程读完成后`users[sockfd].read()`，选择一个工作线程来处理客户请求`pool->append(users + sockfd)`。

通常使用同步I/O模型（如`epoll_wait`）实现Reactor，使用异步I/O（如`aio_read`和`aio_write`）实现Proactor。但在此项目中，我们使用的是**同步I/O模拟的Proactor**事件处理模式。那么什么是同步I/O，什么是异步I/O呢？

- 同步（阻塞）I/O：在一个线程中，CPU执行代码的速度极快，然而，一旦遇到IO操作，如读写文件、发送网络数据时，就需要等待IO操作完成，才能继续进行下一步操作。这种情况称为同步IO。
- 异步（非阻塞）I/O：当代码需要执行一个耗时的IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时，再通知CPU进行处理。

Linux下有三种IO复用方式：epoll，select和poll，为什么用epoll，它和其他两个有什么区别呢？

- 对于select和poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，每次调用都需要将整个集合拷贝到内核态；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要执行一个系统调用。系统调用的开销是很大的，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。
- select使用线性表描述文件描述符集合，文件描述符有上限；poll使用链表来描述；epoll底层通过红黑树来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。
- select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll调用时，它们会采用遍历的方式，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，会自动触发epoll回调函数通知epoll文件描述符，然后内核将这些就绪的文件描述符放到之前提到的ready list中等待epoll_wait调用后被处理。
- select和poll都只能工作在相对低效的LT模式下，而epoll同时支持LT和ET模式。
- 综上，当监测的fd数量较小，且各个fd都很活跃的情况下，建议使用select和poll；当监听的fd数量较多，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。

`Epoll`对文件操作符的操作有两种模式：LT（电平触发）和ET（边缘触发），二者的区别在于当你调用`epoll_wait`的时候内核里面发生了什么：

- LT（电平触发）：类似`select`，LT会去遍历在epoll事件表中每个文件描述符，来观察是否有我们感兴趣的事件发生，如果有（触发了该文件描述符上的回调函数），`epoll_wait`就会以非阻塞的方式返回。若该epoll事件没有被处理完（没有返回`EWOULDBLOCK`），该事件还会被后续的`epoll_wait`再次触发。
- ET（边缘触发）：ET在发现有我们感兴趣的事件发生后，立即返回，并且`sleep`这一事件的`epoll_wait`，不管该事件有没有结束。

在使用ET模式时，必须要保证该文件描述符是非阻塞的（确保在没有数据可读时，该文件描述符不会一直阻塞）；并且每次调用`read`和`write`的时候都必须等到它们返回`EWOULDBLOCK`（确保所有数据都已读完或写完）。

#### 3. socket

##### (1) socket

​		Web服务器端会通过创建一个绑定了服务器本地IP和端口的套接字 `socket` 监听来自客户端的请求，客户端可以通过 `connect()` 连接服务器IP和端口，发送连接请求，然后通过TCP三次握手后，监听到的这些连接会排队等待被`accept()`。

##### (2) TCP 通信流程

**服务器端 （被动接受连接的角色）** 

1. 创建一个用于监听的套接字 
   - 监听：监听有客户端的连接 
   - 套接字：这个套接字其实就是一个文件描述符 
2. 将这个监听文件描述符和本地的IP和端口绑定（IP和端口就是服务器的地址信息） 
   - 客户端连接服务器的时候使用的就是这个IP和端口 
3. 设置监听，监听的fd开始工作 
4. 阻塞等待，当有客户端发起连接，解除阻塞，接受客户端的连接，会得到一个和客户端通信的套接字 （fd） 
5. 通信 
   - 接收数据 
   - 发送数据 
6. 通信结束，断开连接

**客户端** 

1. 创建一个用于通信的套接字（fd） 
2. 连接服务器，需要指定连接的服务器的 IP 和 端口 
3. 连接成功了，客户端可以直接和服务器通信 - 接收数据 - 发送数据 
4. 通信结束，断开连接

##### (3) TCP三次握手

​		三次握手的目的是为了保证双方之间建立了连接   //    初始化Socket、序列号和窗口大小并建立 TCP 连接。

​		一开始客户端和服务器都处于CLOSED状态，服务器主动监听某个端口，处于LISTEN状态。

​		**第一次握手：**客户端给服务器端发送一个TCP首部 SYN置1，序号置一个随机初始化数字（ISN）的SYN报文，然后处于SYN_SEND状态。
​		**第二次握手：**服务器收到客户端的SYN报文，给客户端发送一个TCP首部 ACK置1，确认号置客户端的ISN+1，SYN置1，序号置随机化数字的ACK-SYN报文，然后处于SYN_RCVD状态
​		**第三次握手：**客户端收到服务器的报文后，给服务器发送一个TCP首部ACK置1，确认号置服务器的ISN+1的报文，然后处于ESTABLISHED状态，服务器收到后也处于ESTABLISHED状态。

##### (4) TCP 四次挥手

​		四次挥手发生在断开连接的时候，在程序中当调用了close()会使用TCP协议进行四次挥手。 因为在TCP连接的时候，采用三次握手建立的的连接是双向的，在断开的时候需要双向断开。

​		**第一次挥手：**客户端给服务器端发送一个FIN置1的报文，然后进入`FIN_WAIT_1`状态（若close关闭表示不发不收，若shutdown关闭有可能表示不发能收）。

​		**第二次挥手：**服务器端收到报文后，给客户端发送一个ACK置1的回应报文，然后进入`CLOSED_WAIT`状态。(表示自己接收到关闭消息，但还有数据没有处理完)；客户端收到服务器端的回应报文后，进入FIN_WAIT_2状态。

​		**第三次挥手：**服务器端处理完数据后，给客户端发送FIN置1的报文，然后进入`LAST_WAIT`状态（表示数据处理完了，请求关闭）

​		**第四次挥手：**客户端收到服务器的FIN报文后，给服务器发送ACK置1的回应报文，然后进入`TIME_WAIT`状态，经过2MSL时间后，自动给进入`CLOSED`状态。

​						服务器收到客户端的回应报文后，进入`CLOSED`关闭状态。

#### 4. I/O多路复用

##### (1) 什么是I/O多路复用

​		**单个线程/进程**可监听**多个**文件描述符，一旦某个fd就绪，就可以进行相应的读写操作。通过减少运行的进程，有效的减少**上下文切换**的消耗。但是select、poll、epoll本质都是同步I/O，他们都需要在读写事件就绪之后自己负责读写，即这个数据读写过程是阻塞的。

##### (2) 为什么使用IO多路复用

​		为实现**高性能服务器**。阻塞IO的 `recvfrom` 接口会**阻塞**直到有数据copy完成，如果是**单线程**的话会导致**主线程被阻塞**，即整个程序永远**锁死**。当然可以通过多线程解决，即**一个连接分配一个线程**来处理，但是如果是**百万连接**情况，总不能创建百万个线程，毕竟操作系统资源有限。因此就有了IO多路复用技术来解决**单线程监听多个网络连接**的情况。

​		服务器通过**epoll**这种I/O复用技术（还有select和poll）**来实现对监听socket（`listenfd`）和连接socket（客户请求）的同时监听**。

​		注意I/O复用虽然可以同时监听多个文件描述符，但是它本身是阻塞的，并且当有多个文件描述符同时就绪的时候，如果不采取额外措施，程序则只能按顺序处理其中就绪的每一个文件描述符，所以为提高效率，我们将在这部分**通过线程池来实现并发（多线程并发），为每个就绪的文件描述符分配一个逻辑单元（线程）来处理**。

##### (3) IO多路复用技术

主要IO多路复用技术有：`select`，`poll`和`epoll`，注意这些系统调用本身都是**阻塞**的，其所监听的`socket`设置为`non-blocking`。`select`同`poll`原理类似。

###### select

**工作流程：**

1. 首先构造一个关于文件描述符的列表`readfds`，将要监听的文件描述符添加到该列表中，通过`FD_SET`将`readfds`中对应的文件描述符设为1。
2. 调用`select`，将文件描述符列表`readfds` copy到内核空间，监听该列表中的文件描述符，`轮询`感兴趣的fd，**没有数据到来则select阻塞**，直到这些文件描述符中的一个或者多个进行IO操作时，内核将对应位置为1并将结果返回用户空间。
3. 用户空间**遍历**文件描述符列表`readfds`，通过`FD_ISSET`检测对应的fd是否置位，如果置位则调用read读取数据。

**优点**：可以监听多个文件描述符

**缺点**：

- **最大可监听文件描述符**有上限，由`fd_set`决定（一般为1024）

- 需要将`fd_set`在用户态和内核态之间进行copy，开销大

- 无法精确知道哪些fd准备就绪，每次都需要遍历所有的fd

- 文件描述符列表集合不能重用，每次都需要重置。


###### poll

`poll`跟`select`实现方式差不多，效率也差不多。只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构。这个结构体`struct pollfd`，里面有`fd`是委托内核检测的文件描述符，`events`是委托内核检测文件描述符的什么事件，`revents`是文件描述符实际发生的事件。

区别在于

- **没有最大可监听fd限制**，因为其底层通过**链表**实现；
- `poll`内核通过`revents`来设置某些事件是否触发，所有每次不需要再重置。

```c++
struct pollfd{
    int fd;
    short events;
    short revents;
 }
```

###### epoll

`epoll`是一种比`select`，`poll`更加高效的IO多路复用技术。epoll有三个重要接口：`epoll_create`, `epoll_ctl`, `epoll_wait`。

首先通过`epoll_create`在**内核**创建一个新的创建`eventpoll`结构体。

这个在**内核**创建的结构体有两个重要的数据，一个是需要检测的文件描述符信息，底层是**红黑树，** **增删改时间复杂度都为logn**。另一个是就绪列表，存放所有有IO事件到来的fd（其共用红黑树的节点），底层是**双向链表**。

`epoll_ctl`是对这个实例进行管理，包括**插入**，**删除**和**更新**三个操作。

其中**插入**是使用socket fd及其关注的事件构造结构体，并插入到`eventpoll`中，同时会给内核中断处理程序注册一个**回调函数**，告诉内核，如果这个句柄的中断到了，就把它放到**准备就绪list链表**中。**删除**就是将socket fd对应的节点从`eventpoll`中删除，**更新**就是修改socket fd相关的信息，比如更改其所监听的事件等。

`epoll_wait`为检测函数，是一个**阻塞**的接口，如果就绪列表中有事件到来，就会将**就绪事件**copy到用户空间（通过`epoll_event`结构体），并返回事件的数量。没有数据就sleep，等到timeout时间到了即使没有数据也返回。

###### epoll与select, poll对比

对于select和poll来说，所有文件描述符都是在**用户态被加入其文件描述符集合**的，每次调用都需要**将整个集合拷贝到**内核态**；epoll则将**整个文件描述符集合维护在内核态**，每次添加文件描述符的时候都**都需要执行一个系统调用。

**系统调用的开销是很大的**，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。

select使用**线性表**描述文件描述符集合，**文件描述符有上限**；poll使用链表来描述；epoll底层通过**红黑树**来描述，并且维护一个**就绪链表**，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。

select和poll的最大开销**来自内核判断是否有文件描述符就绪**这一过程：每次执行select或poll调用时，它们会采用**遍历**的方式，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，会自动**触发epoll回调函数通知epoll文件描述符**，然后**内核将这些就绪的文件描述符放到就绪链表**中等待epoll_wait调用后被处理。

select和poll都只能工作在相对低效的LT模式下，而epoll同时支持LT和ET模式。

综上，当**监测的fd数量较小，且各个fd都很活跃的情况下**，建议使用select和poll；当监听的fd数量较多，且**单位时间仅部分fd活跃的情况**下，使用epoll会明显提升性能。

###### **select/poll/epoll**

- 调用函数

- - select和poll都是一个函数，epoll是一组函数

- 文件描述符数量

- - select通过线性表描述文件描述符集合，文件描述符有上限，一般是1024，但可以修改源码，重新编译内核，不推荐
  - poll是链表描述，突破了文件描述符上限，最大可以打开文件的数目
  - epoll通过红黑树描述，最大可以打开文件的数目，可以通过命令ulimit -n number修改，仅对当前终端有效

- 将文件描述符从用户传给内核

- - select和poll通过将所有文件描述符拷贝到内核态，每次调用都需要拷贝
  - epoll通过epoll_create建立一棵红黑树，通过epoll_ctl将要监听的文件描述符注册到红黑树上

- 内核判断就绪的文件描述符

- - select和poll通过遍历文件描述符集合，判断哪个文件描述符上有事件发生
  - epoll_create时，内核除了帮我们在epoll文件系统里建了个红黑树用于存储以后epoll_ctl传来的fd外，还会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。
  - epoll是根据每个fd上面的回调函数(中断函数)判断，只有发生了事件的socket才会主动的去调用 callback函数，其他空闲状态socket则不会，若是就绪事件，插入list

- 应用程序索引就绪文件描述符

- - select/poll只返回发生了事件的文件描述符的个数，若知道是哪个发生了事件，同样需要遍历
  - epoll返回的发生了事件的个数和结构体数组，结构体包含socket的信息，因此直接处理返回的数组即可

- 工作模式

- - select和poll都只能工作在相对低效的LT模式下
  - epoll则可以工作在ET高效模式，并且epoll还支持EPOLLONESHOT事件，该事件能进一步减少可读、可写和异常事件被触发的次数。 

- 应用场景

- - 当所有的fd都是活跃连接，使用epoll，需要建立文件系统，红黑书和链表对于此来说，效率反而不高，不如selece和poll
  - 当监测的fd数目较小，且各个fd都比较活跃，建议使用select或者poll
  - 当监测的fd数目非常大，成千上万，且单位时间只有其中的一部分fd处于就绪状态，这个时候使用epoll能够明显提升性能

###### epoll事件类型

- - EPOLLIN：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）
  - EPOLLOUT：表示对应的文件描述符可以写
  - EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）
  - EPOLLERR：表示对应的文件描述符发生错误
  - EPOLLHUP：表示对应的文件描述符被挂断；
  - EPOLLET：将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)而言的
  - EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里

###### **ET/LT/EPOLLONESHOT**

- LT水平触发模式

- - epoll_wait检测到文件描述符有事件发生，则将其通知给应用程序，应用程序可以不立即处理该事件。
  - 当下一次调用epoll_wait时，epoll_wait还会再次向应用程序报告此事件，直至被处理

- ET边缘触发模式

- - epoll_wait检测到文件描述符有事件发生，则将其通知给应用程序，应用程序必须立即处理该事件
  - 必须要一次性将数据读取完，使用非阻塞I/O，读取到出现eagain

- EPOLLONESHOT

- - 一个线程读取某个socket上的数据后开始处理数据，在处理过程中该socket上又有新数据可读，此时另一个线程被唤醒读取，此时出现两个线程处理同一个socket
  - 我们期望的是一个socket连接在任一时刻都只被一个线程处理，通过epoll_ctl对该文件描述符注册epolloneshot事件，一个线程处理socket时，其他线程将无法处理，**当该线程处理完后，需要通过epoll_ctl重置epolloneshot事件**

> **EPOLLONESHOT事件   (一个socket连接在任意时刻都只被一个线程处理)**
>
> **即使可以使用边缘触发模式，一个socket上的某个时间还是可能被触发多次。比如一个线程在读取完某个socket上的数据后开始处理这些数据，而在数据的处理过程中，socket上又有了新数据可以读（EPOLLIN再次被触发），此时另外一个线程被唤醒来读取这些新的数据。就会出现两个线程同时操作一个socket的局面。一个socket连接在任意时刻都只被一个线程处理，可以使用 epoll + EPOLLONESHOT 实现。**
>
> **对于注册了EPOLLONESHOT事件的文件描述符有，操作系统最多出发其注册的一个刻度、可写或异常事件，且只触发一次。除非我们使用epoll_ctl函数重置该文件描述符上注册的EPOLLONESHOT事件。**
>
> 这样一个线程在处理某个socket时，其他线程是不可能有机会操作该socket，但反过来要注意，注册了EPOLLONESHOT事件的socket一旦被某个线程处理完毕，该线程就应该立即重置socket上的EPOLLONESHOT事件，以确保这个socket下一次可读时，其EPOLLIN事件能被触发，进而可以让其他线程有几回处理这个socket。

###### epoll工作模式：LT/ET

假设委托内核检测读事件，检测fd的读缓冲区。

**水平触发LT(Level Trigger)**：**只要缓冲区有数据，就一直触发，直到缓冲区无数据。**如果用户只读一部分数据，或者用户不读数据，只有缓冲区还有数据，就会一直触发。除非缓冲区的数据读完了，才不通知。LT是一种默认的工作方式，同时支持block和non-block socket。**（读一次）**

**边缘触发ET(Edge Trigger)**: **缓冲区从无数据到有数据时，epoll检测到了会给用户通知。**如果用户不读数据，数据一直在缓冲区，epoll下次检测的时候就不通知；如果用户只读了部分数据，epoll不通知。直到下一次客户端有新的数据包到达时，`epoll_wait`才会再次被唤醒。**（循环读）**

ET只支持**no-block socket**，在这种模式下，当描述符从**未就绪**变为**就绪**时，内核通过epoll告诉你，然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到做了某些操作导致那个文件描述符不再为就绪状态。如果一直不对这个fd做IO操作（从而导致它在此变为未就绪），内核不会发送更多的通知。

ET在很大程度上减少了epoll事件被重复触发的次数，因此效率比LT高。epoll工作在ET模式的时候，必须使用非阻塞接口，**以避免由一个文件句柄的阻塞读/写操作 而把多个文件描述符的任务饿死**。

**为什么ET模式下一定要设置为非阻塞模式？**

因为ET模式，当有数据时，只会被触发一次，所以每次读取数据时，**一定要一次性把数据读取完**（必须等到它们返回**EWOULDBLOCK**（确保所有数据都已读完或写完），所以我们需要**设置一个whlie循环read数据，但如果read是阻塞模式，那么如果没有数据时，将会阻塞，导致程序卡死。**所以这里read只允许非阻塞模式，如果没有数据，read将会跳出循环，继续执行其他程序。

**优缺点**

**1. ET模式**

缺点：应用层业务逻辑复杂，容易遗漏事件，很难用好。

优点：相对LT模式效率比较高。一触发立即处理事件。

**2. LT模式**

优点：编程更符合用户直觉，业务层逻辑更简单。

缺点：效率比ET低。

#### 5. 线程和线程池

##### (1) 线程池

使用多线程充分利用**多核CPU**，并使用线程池**避免线程频繁创建**、销**毁加大系统开销。**

- 创建一个线程池来管理多线程，线程池中主要包含**任务队列** 和**工作线程**集合，将任务添加到队列中，然后在创建线程后，自动启动这些任务。使用了一个固定线程数的工作线程，限制线程最大并发数。
- 多个线程共享任务队列，所以需要进行线程间同步，工作线程之间对任务队列的竞争采用**条件变量**和**互斥锁**结合使用。
- 一个工作线程**先加互斥锁**，当任务队列中任务数量为0时候，阻塞在条件变量，当任务数量大于0时候，用条件变量通知阻塞在条件变量下的线程，这些线程来继续竞争获取任务。
- 对任务队列中任务的调度采用**先来先服务**算法。

**线程池：**

- 空间换时间,浪费服务器的硬件资源,换取运行效率.

- 池是一组资源的集合,这组资源在服务器启动之初就被完全创建好并初始化,这称为静态资源.

- 当服务器进入正式运行阶段,开始处理客户请求的时候,如果它需要相关的资源,可以直接从池中获取,无需动态分配.

- 当服务器处理完一个客户连接后,可以把相关的资源放回池中,无需执行系统调用释放资源.

- 线程池的设计模式为半同步/半反应堆，其中反应堆具体为Proactor事件处理模式。

  ​		具体的，主线程为异步线程，负责监听文件描述符，接收socket新连接，若当前监听的socket发生了读写事件，然后将任务插入到请求队列。工作线程从请求队列中取出任务，完成读写数据的处理。


##### (2) 根据并发量、任务执行时间使用线程池

> 1. 高并发、任务执行时间短的业务怎样使用线程池？
>
> 2. 并发不高、任务执行时间长的业务怎样使用线程池？
>
> 3. 并发高、业务执行时间长的业务怎样使用线程池？

线程池本质上是**生产者和消费者**模型，包括三要素：

- 往线程池队列中投**递任务的生产者**；
- **任务队列**；
- 从任务队列取出任务执行的**工作线程（消费者）**。

要想合理的配置线程池的大小，得分析线程池任务的特性，可以从以下几个方面来分析：

- 根据任务的性质来分：CPU 密集型任务；IO 密集型任务；混合型任务。
- 根据任务的优先级：高、中、低
- 根据任务的执行时间：长、中、短

不同性质的任务可以交给不同配置的线程池执行。

##### (3) 线程池的线程数量

最直接的限制因素是CPU处理器的个数。

- 如果CPU是4核的，那么对于CPU密集的任务，线程池的线程数量最好也为4，或者+1防止其他因素导致阻塞。
- 如果是IO密集的任务，一般要多于CPU的核数，因为 IO 操作不占用 CPU，线程间竞争的不是CPU资源而是IO，IO的处理一般比较慢，多于核数的线程将为CPU争取更多的任务，不至于在线程处理IO的时候造成CPU空闲导致资源浪费。
- 而对于混合型的任务，如果可以拆分，拆分成 IO 密集型和 CPU 密集型分别处理，前提是两者运行的时间是差不多的，如果处理时间相差很大，则没必要拆分了。

如果**任务执行时间长**，在工作线程数量有限的情况下，工作线程很快就很被任务占完，导致后续任务不能及时被处理，此时应适当**增加工作线程数量**；反过来，如果**任务执行时间短**，那么**工作线程数量不用太多**，太多的工作线程会导致过多的时间浪费在线程上下文切换上。

回到这个问题本身来，这里的“高并发”应该是生产者生产任务的速度比较快，此时需要适当**增大任务队列上限**。

但是对于第三个问题并发高、业务执行时间长这种情形单纯靠线程池解决方案是不合适的，即使服务器有再高的资源配置，每个任务长周期地占用着资源，最终服务器资源也会很快被耗尽，因此对于这种情况，应该配合**业务解耦**，做些模块拆分优化整个系统结构。

##### (4) 线程同步机制

​		**线程同步**：当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作，其他线程才能对该内存地址进行操作，而其他线程则处于等待状态。

###### ① 信号量 sem

信号量是一种特殊的变量，它只能取自然数值并且只支持两种操作：等待(P)和信号(V).假设有信号量SV，对其的P、V操作如下：

> - P，如果SV的值大于0，则将其减一；若SV的值为0，则挂起执行
> - V，如果有其他进行因为等待SV而挂起，则唤醒；若没有，则将SV值加一

信号量的取值可以是任何自然数，最常用的，最简单的信号量是二进制信号量，只有0和1两个值.

> - sem_init函数用于初始化一个未命名的信号量
> - sem_destory函数用于销毁信号量
> - sem_wait函数将以原子操作方式将信号量减一,信号量为0时,sem_wait阻塞
> - sem_post函数以原子操作方式将信号量加一,信号量大于0时,唤醒调用sem_post的线程

以上，成功返回0，失败返回errno

###### ② 互斥量

互斥锁,也成互斥量,可以保护关键代码段,以确保独占式访问.当进入关键代码段,获得互斥锁将其加锁;离开关键代码段,唤醒等待该互斥锁的线程.

> - pthread_mutex_init函数用于初始化互斥锁
> - pthread_mutex_destory函数用于销毁互斥锁
> - pthread_mutex_lock函数以原子操作方式给互斥锁加锁
> - pthread_mutex_unlock函数以原子操作方式给互斥锁解锁

以上，成功返回0，失败返回errno

###### ③ 条件变量

条件变量提供了一种线程间的通知机制,当某个共享数据达到某个值时,唤醒等待这个共享数据的线程.

> - pthread_cond_init函数用于初始化条件变量
> - pthread_cond_destory函数销毁条件变量
> - pthread_cond_broadcast函数以广播的方式唤醒**所有**等待目标条件变量的线程
> - pthread_cond_wait函数用于等待目标条件变量.该函数调用时需要传入 **mutex参数(加锁的互斥锁)** ,函数执行时,先把调用线程放入条件变量的请求队列,然后将互斥锁mutex解锁,当函数成功返回为0时,互斥锁会再次被锁上. **也就是说函数内部会有一次解锁和加锁操作**.

##### (5) 锁机制的功能

- 实现多线程同步，通过锁机制，确保任一时刻只能有一个线程能进入关键代码段.

#### 6. HTTP

##### (1) HTTP报文格式

HTTP报文分为请求报文和响应报文两种，每种报文必须按照特有格式生成，才能被浏览器端识别。

其中，浏览器端向服务器发送的为请求报文，服务器处理后返回给浏览器端的为响应报文。

**请求报文**

HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据四个部分组成。

其中，请求分为两种，GET和POST，具体的：

- **GET**

```c++
 1    GET /562f25980001b1b106000338.jpg HTTP/1.1
 2    Host:img.mukewang.com
 3    User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64)
 4    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36
 5    Accept:image/webp,image/*,*/*;q=0.8
 6    Referer:http://www.imooc.com/
 7    Accept-Encoding:gzip, deflate, sdch
 8    Accept-Language:zh-CN,zh;q=0.8
 9    空行
10    请求数据为空
```

- **POST**

```c++
1    POST / HTTP1.1
2    Host:www.wrox.com
3    User-Agent:Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022)
4    Content-Type:application/x-www-form-urlencoded
5    Content-Length:40
6    Connection: Keep-Alive
7    空行
8    name=Professional%20Ajax&publisher=Wiley
```

> - **请求行**，用来说明请求类型,要访问的资源以及所使用的HTTP版本。
>   GET说明请求类型为GET，/562f25980001b1b106000338.jpg(URL)为要访问的资源，该行的最后一部分说明使用的是HTTP1.1版本。
>
> - **请求头部**，紧接着请求行（即第一行）之后的部分，用来说明服务器要使用的附加信息。
>
> - - HOST，给出请求资源所在服务器的域名。
>   - User-Agent，HTTP客户端程序的信息，该信息由你发出请求使用的浏览器来定义,并且在每个请求中自动发送等。
>   - Accept，说明用户代理可处理的媒体类型。
>   - Accept-Encoding，说明用户代理支持的内容编码。
>   - Accept-Language，说明用户代理能够处理的自然语言集。
>   - Content-Type，说明实现主体的媒体类型。
>   - Content-Length，说明实现主体的大小。
>   - Connection，连接管理，可以是Keep-Alive或close。
>
> - **空行**，请求头部后面的空行是必须的即使第四部分的请求数据为空，也必须有空行。
>
> - **请求数据**也叫主体，可以添加任意的其他数据。

**响应报文**

HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。

```c++
HTTP/1.1 200 OK
Date: Fri, 22 May 2009 06:07:21 GMT
Content-Type: text/html; charset=UTF-8
空行
<html>
      <head></head>
      <body>
            <!--body goes here-->
      </body>
</html>
```

> - 状态行，由HTTP协议版本号， 状态码， 状态消息 三部分组成。
>   第一行为状态行，（HTTP/1.1）表明HTTP版本为1.1版本，状态码为200，状态消息为OK。
> - 消息报头，用来说明客户端要使用的一些附加信息。
>   第二行和第三行为消息报头，Date:生成响应的日期和时间；Content-Type:指定了MIME类型的HTML(text/html),编码类型是UTF-8。
> - 空行，消息报头后面的空行是必须的。
> - 响应正文，服务器返回给客户端的文本信息。空行后面的html部分为响应正文。

##### (2) HTTP状态码

HTTP有5种类型的状态码，具体的：

- 1xx：指示信息--表示请求已接收，继续处理。

- 2xx：成功--表示请求正常处理完毕。

- - 200 OK：客户端请求被正常处理。
  - 206 Partial content：客户端进行了范围请求。

- 3xx：重定向--要完成请求必须进行更进一步的操作。

- - 301 Moved Permanently：永久重定向，该资源已被永久移动到新位置，将来任何对该资源的访问都要使用本响应返回的若干个URI之一。
  - 302 Found：临时重定向，请求的资源现在临时从不同的URI中获得。

- 4xx：客户端错误--请求有语法错误，服务器无法处理请求。

- - 400 Bad Request：请求报文存在语法错误。
  - 403 Forbidden：请求被服务器拒绝。
  - 404 Not Found：请求不存在，服务器上找不到请求的资源。

- 5xx：服务器端错误--服务器处理请求出错。

- - 500 Internal Server Error：服务器在执行请求时出现错误。

##### (3) 有限状态机

有限状态机，是一种抽象的理论模型，它能够把有限个变量描述的状态变化过程，以可构造可验证的方式呈现出来。比如，封闭的有向图。

有限状态机可以通过if-else,switch-case和函数指针来实现，从软件工程的角度看，主要是为了封装逻辑。

带有状态转移的有限状态机示例代码。

```
 1STATE_MACHINE(){
 2    State cur_State = type_A;
 3    while(cur_State != type_C){
 4        Package _pack = getNewPackage();
 5        switch(){
 6            case type_A:
 7                process_pkg_state_A(_pack);
 8                cur_State = type_B;
 9                break;
10            case type_B:
11                process_pkg_state_B(_pack);
12                cur_State = type_C;
13                break;
14        }
15    }
16}
该状态机包含三种状态：type_A，type_B和type_C。其中，type_A是初始状态，type_C是结束状态。
```

状态机的当前状态记录在cur_State变量中，逻辑处理时，状态机先通过getNewPackage获取数据包，然后根据当前状态对数据进行处理，处理完后，状态机通过改变cur_State完成状态转移。

有限状态机一种逻辑单元内部的一种高效编程方法，在服务器编程中，服务器可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂。

##### (4) http处理流程

- 浏览器端发出http连接请求，主线程创建http对象接收请求并将所有数据读入对应buffer，将该对象插入任务队列，工作线程从任务队列中取出一个任务进行处理。
- 工作线程取出任务后，调用process_read函数，通过主、从状态机对请求报文进行解析。
- 解析完之后，跳转do_request函数生成响应报文，通过process_write写入buffer，返回给浏览器端。

##### (5) 流程图与状态机

**从状态机负责读取报文的一行，主状态机负责对该行数据进行解析**，主状态机内部调用从状态机，从状态机驱动主状态机。

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBH2ZO50WrURwTiaNKTH7tCia3AR4WeKu2EEzSgKibXzG4oa4WaPfGutwBqCJtemia3rc5V1wupvOLFjzQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"  />

###### **主状态机**

三种状态，标识解析位置。

- CHECK_STATE_REQUESTLINE，解析请求行
- CHECK_STATE_HEADER，解析请求头
- CHECK_STATE_CONTENT，解析消息体，仅用于解析POST请求

###### **从状态机**

三种状态，标识解析一行的读取状态。

- LINE_OK，完整读取一行
- LINE_BAD，报文语法有误
- LINE_OPEN，读取的行不完整

##### (6) HTTP_CODE含义

表示HTTP请求的处理结果，在头文件中初始化了八种情形，在报文解析与响应中只用到了七种。

- NO_REQUEST

- - 请求不完整，需要继续读取请求报文数据
  - 跳转主线程继续监测读事件

- GET_REQUEST

- - 获得了完整的HTTP请求
  - 调用do_request完成请求资源映射

- NO_RESOURCE

- - 请求资源不存在
  - 跳转process_write完成响应报文

- BAD_REQUEST

- - HTTP请求报文有语法错误或请求资源为目录
  - 跳转process_write完成响应报文

- FORBIDDEN_REQUEST

- - 请求资源禁止访问，没有读取权限
  - 跳转process_write完成响应报文

- FILE_REQUEST

- - 请求资源可以正常访问
  - 跳转process_write完成响应报文

- INTERNAL_ERROR

- - 服务器内部错误，该结果在主状态机逻辑switch的default下，一般不会触发

##### (7) 解析报文整体流程

process_read通过while循环，将主从状态机进行封装，对报文的每一行进行循环处理。

- 判断条件

- - 主状态机转移到CHECK_STATE_CONTENT，该条件涉及解析消息体
  - 从状态机转移到LINE_OK，该条件涉及解析请求行和请求头部
  - 两者为或关系，当条件为真则继续循环，否则退出

- 循环体

- - 从状态机读取数据
  - 调用get_line函数，通过m_start_line将从状态机读取数据间接赋给text
  - 主状态机解析text

###### **从状态机逻辑**

上一篇的基础知识讲解中，对于HTTP报文的讲解遗漏了一点细节，在这里作为补充。

在HTTP报文中，每一行的数据由\r\n作为结束字符，空行则是仅仅是字符\r\n。因此，可以通过查找\r\n将报文拆解成单独的行进行解析，项目中便是利用了这一点。

从状态机负责读取buffer中的数据，将每行数据末尾的\r\n置为\0\0，并更新从状态机在buffer中读取的位置m_checked_idx，以此来驱动主状态机解析。

- 从状态机从m_read_buf中逐字节读取，判断当前字节是否为\r

- - 接下来的字符是\n，将\r\n修改成\0\0，将m_checked_idx指向下一行的开头，则返回LINE_OK
  - 接下来达到了buffer末尾，表示buffer还需要继续接收，返回LINE_OPEN
  - 否则，表示语法错误，返回LINE_BAD

- 当前字节不是\r，判断是否是\n（**一般是上次读取到\r就到了buffer末尾，没有接收完整，再次接收时会出现这种情况**）

- - 如果前一个字符是\r，则将\r\n修改成\0\0，将m_checked_idx指向下一行的开头，则返回LINE_OK

- 当前字节既不是\r，也不是\n

- - 表示接收不完整，需要继续接收，返回LINE_OPEN

###### **主状态机逻辑**

主状态机初始状态是CHECK_STATE_REQUESTLINE，通过调用从状态机来驱动主状态机，在主状态机进行解析前，从状态机已经将每一行的末尾\r\n符号改为\0\0，以便于主状态机直接取出对应字符串进行处理。

- CHECK_STATE_REQUESTLINE

- - 主状态机的初始状态，调用parse_request_line函数解析请求行
  - 解析函数从m_read_buf中解析HTTP请求行，获得请求方法、目标URL及HTTP版本号
  - 解析完成后主状态机的状态变为CHECK_STATE_HEADER

解析完请求行后，主状态机继续分析请求头。在报文中，请求头和空行的处理使用的同一个函数，这里通过判断当前的text首位是不是\0字符，若是，则表示当前处理的是空行，若不是，则表示当前处理的是请求头。

- CHECK_STATE_HEADER

- - 调用parse_headers函数解析请求头部信息
  - 判断是空行还是请求头，若是空行，进而判断content-length是否为0，如果不是0，表明是POST请求，则状态转移到CHECK_STATE_CONTENT，否则说明是GET请求，则报文解析结束。
  - 若解析的是请求头部字段，则主要分析connection字段，content-length字段，其他字段可以直接跳过，各位也可以根据需求继续分析。
  - connection字段判断是keep-alive还是close，决定是长连接还是短连接
  - content-length字段，这里用于读取post请求的消息体长度



如果仅仅是GET请求，如项目中的欢迎界面，那么主状态机只设置之前的两个状态足矣。

因为在上篇推文中我们曾说道，GET和POST请求报文的区别之一是有无消息体部分，GET请求没有消息体，当解析完空行之后，便完成了报文的解析。

但后续的登录和注册功能，为了避免将用户名和密码直接暴露在URL中，我们在项目中改用了POST请求，将用户名和密码添加在报文中作为消息体进行了封装。

为此，我们需要在解析报文的部分添加解析消息体的模块。

```c++
while((m_check_state==CHECK_STATE_CONTENT && line_status==LINE_OK)||((line_status=parse_line())==LINE_OK))
那么，这里的判断条件为什么要写成这样呢？
```

在GET请求报文中，每一行都是\r\n作为结束，所以对报文进行拆解时，仅用从状态机的状态line_status=parse_line())==LINE_OK语句即可。

但，在POST请求报文中，消息体的末尾没有任何字符，所以不能使用从状态机的状态，这里转而使用主状态机的状态作为循环入口条件。

```c++
那后面的&& line_status==LINE_OK又是为什么？
```

解析完消息体后，报文的完整解析就完成了，但此时主状态机的状态还是CHECK_STATE_CONTENT，也就是说，符合循环入口条件，还会再次进入循环，这并不是我们所希望的。

为此，增加了该语句，并在完成消息体解析后，将line_status变量更改为LINE_OPEN，此时可以跳出循环，完成报文解析任务。

- CHECK_STATE_CONTENT

- - 仅用于解析POST请求，调用parse_content函数解析消息体
  - 用于保存post请求消息体，为后面的登录和注册做准备

#### 7. 信号和定时器

`非活跃`，是指客户端（这里是浏览器）与服务器端建立连接后，长时间不交换数据，一直占用服务器端的文件描述符，导致连接资源的浪费。

`定时事件`，是指固定一段时间之后触发某段代码，由该段代码处理一个事件，如从内核事件表删除事件，并关闭文件描述符，释放连接资源。

`定时器`，是指利用结构体或其他形式，将多种定时事件进行封装起来。具体的，这里只涉及一种定时事件，即定期检测非活跃连接，这里将该定时事件与连接资源封装为一个结构体定时器。

`定时器容器`，是指使用某种容器类数据结构，将上述多个定时器组合起来，便于对定时事件统一管理。具体的，项目中使用升序链表将所有定时器串联组织起来。

`定时器设计`，将连接资源和定时事件等封装起来，具体包括连接资源、超时时间和回调函数，这里的回调函数指向定时事件。

`定时器容器设计`，将多个定时器串联组织起来统一处理，具体包括升序链表设计。

`定时任务处理函数`，该函数封装在容器类中，具体的，函数遍历升序链表容器，根据超时时间，处理对应的定时器。

###### 定时的方法

本项目中，服务器主循环为每一个连接创建一个定时器，并对每个连接进行定时。另外，利用升序时间链表容器将所有定时器串联起来，若主循环接收到定时通知，则在链表中依次执行定时任务。

`Linux`下提供了三种定时的方法:

- socket选项SO_RECVTIMEO和SO_SNDTIMEO
- SIGALRM信号
- I/O复用系统调用的超时参数

三种方法没有一劳永逸的应用场景，也没有绝对的优劣。由于项目中使用的是`SIGALRM`信号，这里仅对其进行介绍。

具体的，**利用`alarm`函数周期性地触发`SIGALRM`信号，信号处理函数利用管道通知主循环，主循环接收到该信号后对升序链表上所有定时器进行处理，若该段时间内没有交换数据，则将该连接关闭，释放所占用的资源。**

###### 信号通知流程

**Linux下的信号采用的异步处理机制，信号处理函数和当前进程是两条不同的执行路线。具体的，当进程收到信号时，操作系统会中断进程当前的正常流程，转而进入信号处理函数执行操作，完成后再返回中断的地方继续执行。**

为避免信号竞态现象发生，信号处理期间系统不会再次触发它。所以，为确保该信号不被屏蔽太久，信号处理函数需要尽可能快地执行完毕。

一般的信号处理函数需要处理该信号对应的逻辑，当该逻辑比较复杂时，信号处理函数执行时间过长，会导致信号屏蔽太久。

这里的解决方案是，信号处理函数仅仅发送信号通知程序主循环，将信号对应的处理逻辑放在程序主循环中，由主循环执行信号对应的逻辑代码。

**信号通知逻辑**

- 创建管道，其中管道写端写入信号值，管道读端通过I/O复用系统监测读事件
- 设置信号处理函数SIGALRM（时间到了触发）和SIGTERM（kill会触发，Ctrl+C）
  - 通过struct sigaction结构体和sigaction函数注册信号捕捉函数
  - 在结构体的handler参数设置信号处理函数，具体的，从管道写端写入信号的名字
- 利用I/O复用系统监听管道读端文件描述符的可读事件
- 信息值传递给主循环，主循环再根据接收到的信号值执行目标信号对应的逻辑代码

###### **信号处理机制**

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBF4pFdWIo9AHPnib7HCeX9t4u3DhF2ywtNlamuVEDmd0IGDI3klPTJpPvjvric8U490RvzueCe7icTOg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 67%;" />

每个进程之中，都有存着一个表，里面存着每种信号所代表的含义，内核通过设置表项中每一个位来标识对应的信号类型。

- **信号的接收**

  ​		接收信号的任务是由内核代理的，当内核接收到信号后，会将其放到对应进程的信号队列中，同时向进程发送一个中断，使其陷入内核态。注意，此时信号还只是在队列中，对进程来说暂时是不知道有信号到来的。

- **信号的检测**

  - 进程从内核态返回到用户态前进行信号检测
  - 进程在内核态中，从睡眠状态被唤醒的时候进行信号检测
  - 进程陷入内核态后，有两种场景会对信号进行检测：
  - 当发现有新信号时，便会进入下一步，信号的处理。

- **信号的处理**

  - ( **内核** )信号处理函数是运行在用户态的，调用处理函数前，内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器（eip）将其指向信号处理函数。
  - ( **用户** )接下来进程返回到用户态中，执行相应的信号处理函数。
  - ( **内核** )信号处理函数执行完成后，还需要返回内核态，检查是否还有其它信号未处理。
  - ( **用户** )如果所有信号都处理完成，就会将内核栈恢复（从用户栈的备份拷贝回来），同时恢复指令寄存器（eip）将其指向中断前的运行位置，最后回到用户态继续执行进程。

至此，一个完整的信号处理流程便结束了，如果同时有多个信号到达，上面的处理流程会在第2步和第3步骤间重复进行。

**为什么管道写端要非阻塞？**

send是将信息发送给套接字缓冲区，如果缓冲区满了，则会阻塞，这时候会进一步增加信号处理函数的执行时间，为避免信号竞态现象发生，将其修改为非阻塞。

**没有对非阻塞返回值处理，如果阻塞是不是意味着这一次定时事件失效了？**

是的，但定时事件是非必须立即处理的事件，可以允许这样的情况发生。

**管道传递的是什么类型？switch-case的变量冲突？**

信号本身是整型数值，管道中传递的是ASCII码表中整型数值对应的字符。

switch的变量一般为字符或整型，当switch的变量为字符时，case中可以是字符，也可以是字符对应的ASCII码。

###### 定时器设计

项目中将连接资源、定时事件和超时时间封装为定时器类，具体的，

- 连接资源包括客户端套接字地址、文件描述符和定时器
- 定时事件为回调函数，将其封装起来由用户自定义，这里是删除非活动socket上的注册事件，并关闭
- 定时器超时时间 = 浏览器和服务器连接时刻 + 固定时间(TIMESLOT)，可以看出，定时器使用绝对时间作为超时值，这里alarm设置为5秒，连接超时为15秒。

定时事件，具体的，从内核事件表删除事件，关闭文件描述符，释放连接资源。

###### 定时器容器设计

项目中的定时器容器为带头尾结点的升序双向链表，具体的为每个连接创建一个定时器，将其添加到链表中，并按照超时时间升序排列。执行定时任务时，将到期的定时器从链表中删除。

从实现上看，主要涉及**双向链表的插入，删除操作，其中添加定时器的事件复杂度是O(n),删除定时器的事件复杂度是O(1)。**

升序双向链表主要逻辑如下，具体的，

- 创建头尾节点，其中头尾节点没有意义，仅仅统一方便调整

- add_timer函数，将目标定时器添加到链表中，添加时按照升序添加

- - 若当前链表中只有头尾节点，直接插入
  - 否则，将定时器按升序插入

- adjust_timer函数，当定时任务发生变化,调整对应定时器在链表中的位置

- - 客户端在设定时间内有数据收发,则当前时刻对该定时器重新设定时间，这里只是往后延长超时时间
  - 被调整的目标定时器在尾部，或定时器新的超时值仍然小于下一个定时器的超时，不用调整
  - 否则先将定时器从链表取出，重新插入链表

- del_timer函数将超时的定时器从链表中删除

- - 常规双向链表删除结点

###### 定时任务处理函数

使用统一事件源，SIGALRM信号每次被触发，主循环中调用一次定时任务处理函数，处理链表容器中到期的定时器。

具体的逻辑如下，

- 遍历定时器升序链表容器，从头结点开始依次处理每个定时器，直到遇到尚未到期的定时器
- 若当前时间小于定时器超时时间，跳出循环，即未找到到期的定时器
- 若当前时间大于定时器超时时间，即找到了到期的定时器，执行回调函数，然后将它从链表中删除，然后继续遍历

###### 如何使用定时器

- 浏览器与服务器连接时，创建该连接对应的定时器，并将该定时器添加到链表上
- 处理异常事件时，执行定时事件，服务器关闭连接，从链表上移除对应定时器
- 处理定时信号时，将定时标志设置为true
- 处理读事件时，若某连接上发生读事件，将对应定时器向后移动，否则，执行定时事件
- 处理写事件时，若服务器通过某连接给浏览器发送数据，将对应定时器向后移动，否则，执行定时事件

**有小伙伴问，连接资源中的address是不是有点鸡肋？**

确实如此，项目中虽然对该变量赋值，但并没有用到。类似的，可以对比HTTP类中address属性，只在日志输出中用到。

但不能说这个变量没有用，因为我们可以找到客户端连接的ip地址，用它来做一些业务，比如通过ip来判断是否异地登录等等。

#### 9. 日志系统

**`日志`**，由服务器自动创建，并记录运行状态，错误信息，访问数据的文件。

**`同步日志`**，日志写入函数与工作线程串行执行，由于涉及到I/O操作，当单条日志比较大的时候，同步模式会阻塞整个处理流程，服务器所能处理的并发能力将有所下降，尤其是在峰值的时候，写日志可能成为系统的瓶颈。

**`生产者-消费者模型`**，并发编程中的经典模型。以多线程为例，为了实现线程间数据同步，生产者线程与消费者线程共享一个缓冲区，其中生产者线程往缓冲区中push消息，消费者线程从缓冲区中pop消息。

**`阻塞队列`**，将生产者-消费者模型进行封装，使用循环数组实现队列，作为两者共享的缓冲区。

**`异步日志`**，将所写的日志内容先存入阻塞队列，写线程从阻塞队列中取出内容，写入日志。

**`单例模式`**，最简单也是被问到最多的设计模式之一，**保证一个类只创建一个实例，同时提供全局访问的方法。**

其中异步写入方式，将生产者-消费者模型封装为阻塞队列，创建一个写线程，工作线程将要写的内容push进队列，写线程从队列中取出内容，写入日志文件。

##### 单例模式

单例模式作为最常用的设计模式之一，保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。

实现思路：私有化它的构造函数，以防止外界创建单例类的对象；使用类的私有静态指针变量指向类的唯一实例，并用一个公有的静态方法获取该实例。

单例模式有两种实现方法，分别是懒汉和饿汉模式。顾名思义，懒汉模式，即非常懒，不用的时候不去初始化，所以在第一次被使用时才进行初始化；饿汉模式，即迫不及待，在程序运行时立即初始化。

###### **经典的线程安全懒汉模式**

单例模式的实现思路如前述所示，其中，经典的线程安全懒汉模式，使用**双检测锁模式**。 使用的时候需要加锁

**`为什么要用双检测，只检测一次不行吗？`**

如果只检测一次，在每次调用获取实例的方法时，都需要加锁，这将严重影响程序性能。双层检测可以有效避免这种情况，仅在第一次创建单例的时候加锁，其他时候都不再符合NULL == p的情况，直接返回已创建好的实例。

###### **局部静态变量之线程安全懒汉模式**

前面的双检测锁模式，写起来不太优雅，另一种更优雅的单例模式实现，使用函数内的局部静态对象，这种方法不用加锁和解锁操作。

**`这时候有人说了，这种方法不加锁会不会造成线程安全问题？`**

所以，如果使用C++11之前的标准，还是需要加锁，这里同样给出加锁的版本。

###### **饿汉模式**

饿汉模式不需要用锁，就可以实现线程安全。原因在于，在程序运行时就定义了对象，并对其初始化。之后，不管哪个线程调用成员函数getinstance()，都只不过是返回一个对象的指针而已。所以是线程安全的，不需要在获取实例的成员函数中加锁。

饿汉模式虽好，但其存在隐藏的问题，在于非静态对象（函数外的static对象）在不同编译单元中的初始化顺序是未定义的。如果在初始化完成之前调用getInstance() 方法会返回一个未定义的实例。

##### 条件变量

条件变量提供了一种线程间的通知机制，当某个共享数据达到某个值时,唤醒等待这个共享数据的线程。

**`使用前要加锁，为什么要加锁？`**

多线程访问，为了避免资源竞争，所以要加锁，使得每个线程互斥的访问公有资源。

**`pthread_cond_wait内部为什么要解锁？`**

如果while或者if判断的时候，满足执行条件，线程便会调用pthread_cond_wait阻塞自己，此时它还在持有锁，如果他不解锁，那么其他线程将会无法访问公有资源。

具体到pthread_cond_wait的内部实现，当pthread_cond_wait被调用线程阻塞的时候，pthread_cond_wait会自动释放互斥锁。

**`为什么要把调用线程放入条件变量的请求队列后再解锁？`**

线程是并发执行的，如果在把调用线程A放在等待队列之前，就释放了互斥锁，这就意味着其他线程比如线程B可以获得互斥锁去访问公有资源，这时候线程A所等待的条件改变了，但是它没有被放在等待队列上，导致A忽略了等待条件被满足的信号。

倘若在线程A调用pthread_cond_wait开始，到把A放在等待队列的过程中，都持有互斥锁，其他线程无法得到互斥锁，就不能改变公有资源。

**`为什么最后还要加锁？`**

将线程放在条件变量的请求队列后，将其解锁，此时等待被唤醒，若成功竞争到互斥锁，再次加锁。

**`为什么判断线程执行的条件用while而不是if？`**

一般来说，在多线程资源竞争的时候，在一个使用资源的线程里面（消费者）判断资源是否可用，不可用，便调用pthread_cond_wait，在另一个线程里面（生产者）如果判断资源可用的话，则调用pthread_cond_signal发送一个资源可用信号。

在wait成功之后，资源就一定可以被使用么？答案是否定的，如果同时有两个或者两个以上的线程正在等待此资源，wait返回后，资源可能已经被使用了。

再具体点，有可能多个线程都在等待这个资源可用的信号，信号发出后只有一个资源可用，但是有A，B两个线程都在等待，B比较速度快，获得互斥锁，然后加锁，消耗资源，然后解锁，之后A获得互斥锁，但A回去发现资源已经被使用了，它便有两个选择，一个是去访问不存在的资源，另一个就是继续等待，那么继续等待下去的条件就是使用while，要不然使用if的话pthread_cond_wait返回后，就会顺序执行下去。

所以，在这种情况下，应该使用while而不是if:

```c++
while(resource == FALSE)
    pthread_cond_wait(&cond, &mutex);
```

如果只有一个消费者，那么使用if是可以的。

##### **生产者-消费者模型**

生产者和消费者是互斥关系，两者对缓冲区访问互斥，同时生产者和消费者又是一个相互协作与同步的关系，只有生产者生产之后，消费者才能消费。

当队列为空时，从队列中获取元素的线程将会被挂起；当队列是满时，往队列里添加元素的线程将会挂起。

##### 日志类的定义与使用

###### 流程图与日志类定义

**流程图**

- 日志文件

- - 局部变量的懒汉模式获取实例
  - 生成日志文件，并判断同步和异步写入方式

- 同步

- - 判断是否分文件
  - 直接格式化输出内容，将信息写入日志文件

- 异步

- - 判断是否分文件
  - 格式化输出内容，将内容写入阻塞队列，创建一个写线程，从阻塞队列取出内容写入日志文件

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBEOjicsa8vpoLAlODicrC7AoM1h2eq9sDMdQY8TNYQoVckCRDd0m8SDH1myuB4gEJfejvznfZuJ3cpQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**生成日志文件 && 判断写入方式**

通过单例模式获取唯一的日志类，调用init方法，初始化生成日志文件，服务器启动按当前时刻创建日志，前缀为时间，后缀为自定义log文件名，并记录创建日志的时间day和行数count。

写入方式通过初始化时**是否设置队列大小**（表示在队列中可以放几条数据）来判断，若队列大小为0，则为同步，否则为异步。

###### **日志分级与分文件**

日志分级的实现大同小异，一般的会提供五种级别，具体的，

- Debug，调试代码时的输出，在系统实际运行时，一般不使用。
- Warn，这种警告与调试时终端的warning类似，同样是调试代码时使用。
- Info，报告系统当前的状态，当前执行的流程或接收的信息等。
- Error和Fatal，输出系统的错误信息。

上述的使用方法仅仅是个人理解，在开发中具体如何选择等级因人而异。项目中给出了除Fatal外的四种分级，实际使用了Debug，Info和Error三种。

超行、按天分文件逻辑，具体的，

- 日志写入前会判断当前day是否为创建日志的时间，行数是否超过最大行限制

- - 若为创建日志时间，写入日志，否则按当前时间创建新log，更新创建时间和行数
  - 若行数超过最大行限制，在当前日志的末尾加count/max_lines为后缀创建新log

将系统信息格式化后输出，具体为：格式化时间 + 格式化内容

#### 10. 数据库连接池

**什么是数据库连接池？**

池是一组资源的集合，这组资源在服务器启动之初就被完全创建好并初始化。通俗来说，池是资源的容器，本质上是对资源的复用。

顾名思义，连接池中的资源为一组数据库连接，由程序动态地对池中的连接进行使用，释放。

当系统开始处理客户请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配；当服务器处理完一个客户连接后,可以把相关的资源放回池中，无需执行系统调用释放资源。

**数据库访问的一般流程是什么？**

当系统需要访问数据库时，先系统创建数据库连接，完成数据库操作，然后系统断开数据库连接。

**为什么要创建连接池？**

从一般流程中可以看出，若系统需要频繁访问数据库，则需要频繁创建和断开数据库连接，而创建数据库连接是一个很耗时的操作，也容易对数据库造成安全隐患。

在程序初始化的时候，集中创建多个数据库连接，并把他们集中管理，供程序使用，可以保证较快的数据库读写速度，更加安全可靠。

池可以看做资源的容器，所以多种实现方法，比如数组、链表、队列等。这里，使用单例模式和链表创建数据库连接池，实现对数据库连接资源的复用。

项目中的数据库模块分为两部分，其一是数据库连接池的定义，其二是利用连接池完成登录和注册的校验功能。具体的，工作线程从数据库连接池取得一个连接，访问数据库中的数据，访问完毕后将连接交还连接池。

本篇将介绍数据库连接池的定义，具体的涉及到单例模式创建、连接池代码实现、RAII机制释放数据库连接。

**单例模式创建**，结合代码描述连接池的单例实现。

**连接池代码实现**，结合代码对连接池的外部访问接口进行详解。

**RAII机制释放数据库连接**，描述连接释放的封装逻辑。

###### 单例模式创建

使用局部静态变量懒汉模式创建连接池。

###### 连接池代码实现

连接池的定义中注释比较详细，这里仅对其实现进行解析。

连接池的功能主要有：初始化，获取连接、释放连接，销毁连接池。

**初始化**

值得注意的是，销毁连接池没有直接被外部调用，而是通过RAII机制来完成自动释放；使用信号量实现多线程争夺连接的同步机制，这里将信号量初始化为数据库的连接总数。

**获取、释放连接**

当线程数量大于数据库连接数量时，使用信号量进行同步，每次取出连接，信号量原子减1，释放连接原子加1，若连接池内没有连接了，则阻塞等待。

另外，由于多线程操作连接池，会造成竞争，这里使用互斥锁完成同步，具体的同步机制均使用lock.h中封装好的类。

**销毁连接池**

通过迭代器遍历连接池链表，关闭对应数据库连接，清空链表并重置空闲连接和现有连接数量。

###### RAII机制释放数据库连接

将数据库连接的获取与释放通过RAII机制封装，避免手动释放。

这里需要注意的是，在获取连接时，通过有参构造对传入的参数进行修改。其中数据库连接本身是指针类型，所以参数需要通过双指针才能对其进行修改。

不直接调用获取和释放连接的接口，将其封装起来，通过RAII机制进行获取和释放。

本篇将介绍同步实现注册登录功能，具体的涉及到流程图，载入数据库表，提取用户名和密码，注册登录流程与页面跳转的的代码实现。

**流程图**，描述服务器从报文中提取出用户名密码，并完成注册和登录校验后，实现页面跳转的逻辑。

**载入数据库表**，结合代码将数据库中的数据载入到服务器中。

**提取用户名和密码**，结合代码对报文进行解析，提取用户名和密码。

**注册登录流程**，结合代码对描述服务器进行注册和登录校验的流程。

**页面跳转**，结合代码对页面跳转机制进行详解。

#### 11. 同步实现注册登录

具体的，描述了GET和POST请求下的页面跳转流程。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6OkibcrXVmBF79BLANEZ6cQoucgxyIz8B0Mz7VGZVTv4MpQC7pLL2bZiaic7sAVz2lhyk8ibL95apWmSE8AfGxAx6A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

###### 载入数据库表

将数据库中的用户名和密码载入到服务器的map中来，map中的key为用户名，value为密码。

###### **提取用户名和密码**

服务器端解析浏览器的请求报文，当解析为POST请求时，cgi标志位设置为1，并将请求报文的消息体赋值给m_string，进而提取出用户名和密码。

###### 同步线程登录注册

通过m_url定位/所在位置，根据/后的第一个字符判断是登录还是注册校验。

- 2

- - 登录校验

- 3

- - 注册校验

根据校验结果，跳转对应页面。另外，对数据库进行操作时，需要通过锁来同步。

###### 页面跳转

通过m_url定位/所在位置，根据/后的第一个字符，使用分支语句实现页面跳转。具体的，

- 0

- - 跳转注册页面，GET

- 1

- - 跳转登录页面，GET

- 5

- - 显示图片页面，POST

- 6

- - 显示视频页面，POST

- 7

- - 显示关注页面，POST

#### 12. 踩坑

做项目过程中，肯定会遇到形形色色、大大小小的问题，但并不是所有问题都值得列出来探讨，这里仅列出个人认为有意义的问题。

具体的，包括大文件传输。

###### **大文件传输**

先看下之前的大文件传输，也就是游双书上的代码，发送数据只调用了writev函数，并对其返回值是否异常做了处理。

在实际测试中发现，当请求小文件，也就是调用一次writev函数就可以将数据全部发送出去的时候，不会报错，此时不会再次进入while循环。

一旦请求服务器文件较大文件时，需要多次调用writev函数，便会出现问题，不是文件显示不全，就是无法显示。

对数据传输过程分析后，定位到writev的m_iv结构体成员有问题，每次传输后不会自动偏移文件指针和传输长度，还会按照原有指针和原有长度发送数据。

根据前面的基础API分析，我们知道writev以顺序iov[0]，iov[1]至iov[iovcnt-1]从缓冲区中聚集输出数据。项目中，申请了2个iov，其中iov[0]为存储报文状态行的缓冲区，iov[1]指向资源文件指针。

对上述代码做了修改如下：

- 由于报文消息报头较小，第一次传输后，需要更新m_iv[1].iov_base和iov_len，m_iv[0].iov_len置成0，只传输文件，不用传输响应消息头
- 每次传输后都要更新下次传输的文件起始位置和长度

更新后，大文件传输得到了解决。

#### 13. 概念

##### (1) RAII机制

- RAII 的意思是 **资源获取即初始化**；将资源或者状态与对象的生命周期绑定，**实现资源或状态的安全管理**，例如智能指针。
- 因为C++语言机制保证了类对象创建时自动调用构造，超出作用域时自动调用析构函数，所以按照RAII机制**可以使用类来管理资源**，在构造函数中申请分配资源，在析构函数中释放资源，这样就可以将资源和对象的生命周期绑定，不用程序员显示的去调用释放资源的操作了。

##### (2) 封装的功能

- 类中主要是Linux下三种锁进行封装，将锁的创建与销毁函数封装在类的构造与析构函数中，实现RAII机制

- **将重复使用的代码封装为函数，减少代码的重复，使其更简洁**   (封装起来会使得使用时更加简洁)

##### (3) 静态成员

###### 静态成员变量

将类成员变量声明为static，则为静态成员变量，与一般的成员变量不同，无论建立多少对象，都只有一个静态成员变量的拷贝，静态成员变量属于一个类，所有对象共享。

静态变量在编译阶段就分配了空间，对象还没创建时就已经分配了空间，放到全局静态区。

- 静态成员变量

- - 最好是类内声明，类外初始化（以免类名访问静态成员访问不到）。
  - 无论公有，私有，静态成员都可以在类外定义，但私有成员仍有访问权限。
  - 非静态成员类外不能初始化。
  - 静态成员数据是共享的。

###### **静态成员函数**

将类成员函数声明为static，则为静态成员函数。

- 静态成员函数

- - 静态成员函数可以直接访问静态成员变量，不能直接访问普通成员变量，但可以通过参数传递的方式访问。
  - 普通成员函数可以访问普通成员变量，也可以访问静态成员变量。
  - 静态成员函数没有this指针。非静态数据成员为对象单独维护，但静态成员函数为共享函数，无法区分是哪个对象，因此不能直接访问普通变量成员，也没有this指针。

###### **pthread_create陷阱**

首先看一下该函数的函数原型。

```c++
1#include <pthread.h>
2int pthread_create (pthread_t *thread_tid,                 //返回新生成的线程的id
3                    const pthread_attr_t *attr,         //指向线程属性的指针,通常设置为NULL
4                    void * (*start_routine) (void *),   //处理线程函数的地址
5                    void *arg);                         //start_routine()中的参数
```

函数原型中的第三个参数，为函数指针，指向处理线程函数的地址。该函数，要求为静态函数。如果处理线程函数为类成员函数时，需要将其设置为**静态成员函数**。

###### this指针的锅

pthread_create的函数原型中第三个参数的类型为函数指针，指向的线程处理函数参数类型为`(void *)`,若线程函数为类成员函数，则this指针会作为默认的参数被传进函数中，从而和线程函数参数`(void*)`不能匹配，不能通过编译。

静态成员函数就没有这个问题，里面没有this指针。

##### **stat**

stat函数用于取得指定文件的文件属性，并将文件属性存储在结构体stat里，这里仅对其中用到的成员进行介绍。

```c++
 1#include <sys/types.h>
 2#include <sys/stat.h>
 3#include <unistd.h>
 4
 5//获取文件属性，存储在statbuf中
 6int stat(const char *pathname, struct stat *statbuf);
 7
 8struct stat 
 9{
10   mode_t    st_mode;        /* 文件类型和权限 */
11   off_t     st_size;        /* 文件大小，字节数*/
12};
```

##### **mmap**

用于将一个文件或其他对象映射到内存，提高文件的访问速度。

```c++
1void* mmap(void* start,size_t length,int prot,int flags,int fd,off_t offset);
2int munmap(void* start,size_t length);
```

- start：映射区的开始地址，设置为0时表示由系统决定映射区的起始地址

- length：映射区的长度

- prot：期望的内存保护标志，不能与文件的打开模式冲突

- - PROT_READ 表示页内容可以被读取

- flags：指定映射对象的类型，映射选项和映射页是否可以共享

- - MAP_PRIVATE 建立一个写入时拷贝的私有映射，内存区域的写入不会影响到原文件

- fd：有效的文件描述符，一般是由open()函数返回

- off_toffset：被映射对象内容的起点

##### **iovec**

定义了一个向量元素，通常，这个结构用作一个多元素的数组。

```c++
1struct iovec {
2    void      *iov_base;      /* starting address of buffer */
3    size_t    iov_len;        /* size of buffer */
4};
```

- iov_base指向数据的地址
- iov_len表示数据的长度

##### **writev**

writev函数用于在一次函数调用中写多个非连续缓冲区，有时也将这该函数称为聚集写。

```c++
1#include <sys/uio.h>
2ssize_t writev(int filedes, const struct iovec *iov, int iovcnt);
```

- filedes表示文件描述符
- iov为前述io向量机制结构体iovec
- iovcnt为结构体的个数

若成功则返回已写的字节数，若出错则返回-1。`writev`以顺序`iov[0]`，`iov[1]`至`iov[iovcnt-1]`从缓冲区中聚集输出数据。`writev`返回输出的字节总数，通常，它应等于所有缓冲区长度之和。

**特别注意：** 循环调用writev时，需要重新处理iovec中的指针和长度，该函数不会对这两个成员做任何处理。writev的返回值为已写的字节数，但这个返回值“实用性”并不高，因为参数传入的是iovec数组，计量单位是iovcnt，而不是字节数，我们仍然需要通过遍历iovec来计算新的基址，另外写入数据的“结束点”可能位于一个iovec的中间某个位置，因此需要调整临界iovec的io_base和io_len。

##### 流程图

浏览器端发出HTTP请求报文，服务器端接收该报文并调用`process_read`对其进行解析，根据解析结果`HTTP_CODE`，进入相应的逻辑和模块。

其中，服务器子线程完成报文的解析与响应；主线程监测读写事件，调用`read_once`和`http_conn::write`完成数据的读取与发送。

##### **fputs**

```
1#include <stdio.h>
2int fputs(const char *str, FILE *stream);
```

- str，一个数组，包含了要写入的以空字符终止的字符序列。
- stream，指向FILE对象的指针，该FILE对象标识了要被写入字符串的流。

###### **可变参数宏__VA_ARGS__**

__VA_ARGS__是一个可变参数的宏，定义时宏定义中参数列表的最后一个参数为省略号，在实际使用时会发现有时会加##，有时又不加。

```
1//最简单的定义
2#define my_print1(...)  printf(__VA_ARGS__)
3
4//搭配va_list的format使用
5#define my_print2(format, ...) printf(format, __VA_ARGS__)  
6#define my_print3(format, ...) printf(format, ##__VA_ARGS__)
```

__VA_ARGS__宏前面加上##的作用在于，当可变参数的个数为0时，这里printf参数列表中的的##会把前面多余的","去掉，否则会编译出错，建议使用后面这种，使得程序更加健壮。

###### **fflush**

```
1#include <stdio.h>
2int fflush(FILE *stream);
```

fflush()会强迫将缓冲区内的数据写回参数stream 指定的文件中，如果参数stream 为NULL，fflush()会将所有打开的文件数据更新。

在使用多个输出函数连续进行多次输出到控制台时，有可能下一个数据再上一个数据还没输出完毕，还在输出缓冲区中时，下一个printf就把另一个数据加入输出缓冲区，结果冲掉了原来的数据，出现输出错误。

在prinf()后加上fflush(stdout); 强制马上输出到控制台，可以避免出现上述错误。

#### 13. 面试题

包括项目介绍，线程池相关，并发模型相关，HTTP报文解析相关，定时器相关，日志相关，压测相关，综合能力等。

###### **项目介绍**

- 为什么要做这样一个项目？
- 介绍下你的项目

###### **线程池相关**

- 手写线程池
- 线程的同步机制有哪些？
- 线程池中的工作线程是一直等待吗？
- 你的线程池工作线程处理完一个任务后的状态是什么？
- 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？
- 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?

###### **并发模型相关**

- 简单说一下服务器使用的并发模型？
- reactor、proactor、主从reactor模型的区别？
- 你用了epoll，说一下为什么用epoll，还有其他复用方式吗？区别是什么？

###### **HTTP报文解析相关**

- 用了状态机啊，为什么要用状态机？
- 状态机的转移图画一下
- https协议为什么安全？
- https的ssl连接过程
- GET和POST的区别

###### **数据库登录注册相关**

- 登录说一下？
- 你这个保存状态了吗？如果要保存，你会怎么做？（cookie和session）
- 登录中的用户名和密码你是load到本地，然后使用map匹配的，如果有10亿数据，即使load到本地后hash，也是很耗时的，你要怎么优化？
- 用的mysql啊，redis了解吗？用过吗？

###### **定时器相关**

- 为什么要用定时器？
- 说一下定时器的工作原理
- 双向链表啊，删除和添加的时间复杂度说一下？还可以优化吗？
- 最小堆优化？说一下时间复杂度和工作原理

###### **日志相关**

- 说下你的日志系统的运行机制？
- 为什么要异步？和同步的区别是什么？
- 现在你要监控一台服务器的状态，输出监控日志，请问如何将该日志分发到不同的机器上？（消息队列）

###### **压测相关**

- 服务器并发量测试过吗？怎么测试的？
- webbench是什么？介绍一下原理
- 测试的时候有没有遇到问题？

###### **综合能力**

- 你的项目解决了哪些其他同类项目没有解决的问题？
- 说一下前端发送请求后，服务器处理的过程，中间涉及哪些协议？
